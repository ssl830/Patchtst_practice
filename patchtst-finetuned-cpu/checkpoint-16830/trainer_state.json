{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 30.0,
  "eval_steps": 50,
  "global_step": 16830,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017825311942959002,
      "grad_norm": 0.14711040258407593,
      "learning_rate": 9.994652406417114e-05,
      "loss": 0.1463,
      "step": 10
    },
    {
      "epoch": 0.035650623885918005,
      "grad_norm": 0.3527408838272095,
      "learning_rate": 9.98871063576946e-05,
      "loss": 0.1294,
      "step": 20
    },
    {
      "epoch": 0.053475935828877004,
      "grad_norm": 0.5952340364456177,
      "learning_rate": 9.982768865121806e-05,
      "loss": 0.1091,
      "step": 30
    },
    {
      "epoch": 0.07130124777183601,
      "grad_norm": 0.278926283121109,
      "learning_rate": 9.976827094474153e-05,
      "loss": 0.0995,
      "step": 40
    },
    {
      "epoch": 0.08912655971479501,
      "grad_norm": 1.4755562543869019,
      "learning_rate": 9.970885323826501e-05,
      "loss": 0.0914,
      "step": 50
    },
    {
      "epoch": 0.10695187165775401,
      "grad_norm": 0.7361375689506531,
      "learning_rate": 9.964943553178848e-05,
      "loss": 0.0885,
      "step": 60
    },
    {
      "epoch": 0.12477718360071301,
      "grad_norm": 0.990929126739502,
      "learning_rate": 9.959001782531195e-05,
      "loss": 0.0765,
      "step": 70
    },
    {
      "epoch": 0.14260249554367202,
      "grad_norm": 0.49017348885536194,
      "learning_rate": 9.953060011883542e-05,
      "loss": 0.0848,
      "step": 80
    },
    {
      "epoch": 0.16042780748663102,
      "grad_norm": 0.5366386771202087,
      "learning_rate": 9.947118241235888e-05,
      "loss": 0.0845,
      "step": 90
    },
    {
      "epoch": 0.17825311942959002,
      "grad_norm": 0.7269098162651062,
      "learning_rate": 9.941176470588236e-05,
      "loss": 0.0758,
      "step": 100
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.173458069562912,
      "learning_rate": 9.935234699940583e-05,
      "loss": 0.0786,
      "step": 110
    },
    {
      "epoch": 0.21390374331550802,
      "grad_norm": 0.9336792826652527,
      "learning_rate": 9.92929292929293e-05,
      "loss": 0.0753,
      "step": 120
    },
    {
      "epoch": 0.23172905525846701,
      "grad_norm": 1.0756771564483643,
      "learning_rate": 9.923351158645277e-05,
      "loss": 0.0847,
      "step": 130
    },
    {
      "epoch": 0.24955436720142601,
      "grad_norm": 1.9782638549804688,
      "learning_rate": 9.917409387997623e-05,
      "loss": 0.0761,
      "step": 140
    },
    {
      "epoch": 0.26737967914438504,
      "grad_norm": 0.09978954493999481,
      "learning_rate": 9.91146761734997e-05,
      "loss": 0.0688,
      "step": 150
    },
    {
      "epoch": 0.28520499108734404,
      "grad_norm": 0.912026047706604,
      "learning_rate": 9.905525846702318e-05,
      "loss": 0.0923,
      "step": 160
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 0.3528132140636444,
      "learning_rate": 9.899584076054664e-05,
      "loss": 0.0814,
      "step": 170
    },
    {
      "epoch": 0.32085561497326204,
      "grad_norm": 0.21167853474617004,
      "learning_rate": 9.893642305407012e-05,
      "loss": 0.0802,
      "step": 180
    },
    {
      "epoch": 0.33868092691622104,
      "grad_norm": 1.1703611612319946,
      "learning_rate": 9.887700534759359e-05,
      "loss": 0.0922,
      "step": 190
    },
    {
      "epoch": 0.35650623885918004,
      "grad_norm": 0.8881193399429321,
      "learning_rate": 9.881758764111705e-05,
      "loss": 0.0815,
      "step": 200
    },
    {
      "epoch": 0.37433155080213903,
      "grad_norm": 0.32655149698257446,
      "learning_rate": 9.875816993464053e-05,
      "loss": 0.0709,
      "step": 210
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.7111311554908752,
      "learning_rate": 9.869875222816399e-05,
      "loss": 0.0782,
      "step": 220
    },
    {
      "epoch": 0.40998217468805703,
      "grad_norm": 1.2682775259017944,
      "learning_rate": 9.863933452168747e-05,
      "loss": 0.0684,
      "step": 230
    },
    {
      "epoch": 0.42780748663101603,
      "grad_norm": 1.463706612586975,
      "learning_rate": 9.857991681521094e-05,
      "loss": 0.0823,
      "step": 240
    },
    {
      "epoch": 0.44563279857397503,
      "grad_norm": 1.1562186479568481,
      "learning_rate": 9.852049910873442e-05,
      "loss": 0.0798,
      "step": 250
    },
    {
      "epoch": 0.46345811051693403,
      "grad_norm": 0.3838249444961548,
      "learning_rate": 9.846108140225788e-05,
      "loss": 0.0806,
      "step": 260
    },
    {
      "epoch": 0.48128342245989303,
      "grad_norm": 1.1178425550460815,
      "learning_rate": 9.840166369578134e-05,
      "loss": 0.0811,
      "step": 270
    },
    {
      "epoch": 0.49910873440285203,
      "grad_norm": 0.4597634971141815,
      "learning_rate": 9.834224598930481e-05,
      "loss": 0.0796,
      "step": 280
    },
    {
      "epoch": 0.5169340463458111,
      "grad_norm": 0.36528077721595764,
      "learning_rate": 9.828282828282829e-05,
      "loss": 0.084,
      "step": 290
    },
    {
      "epoch": 0.5347593582887701,
      "grad_norm": 0.8431047797203064,
      "learning_rate": 9.822341057635176e-05,
      "loss": 0.0735,
      "step": 300
    },
    {
      "epoch": 0.5525846702317291,
      "grad_norm": 1.4878675937652588,
      "learning_rate": 9.816399286987523e-05,
      "loss": 0.0788,
      "step": 310
    },
    {
      "epoch": 0.5704099821746881,
      "grad_norm": 0.31555771827697754,
      "learning_rate": 9.810457516339869e-05,
      "loss": 0.0738,
      "step": 320
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.7716661691665649,
      "learning_rate": 9.804515745692216e-05,
      "loss": 0.0706,
      "step": 330
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 0.39548975229263306,
      "learning_rate": 9.798573975044564e-05,
      "loss": 0.0711,
      "step": 340
    },
    {
      "epoch": 0.6238859180035651,
      "grad_norm": 1.037772297859192,
      "learning_rate": 9.792632204396911e-05,
      "loss": 0.0817,
      "step": 350
    },
    {
      "epoch": 0.6417112299465241,
      "grad_norm": 0.5613212585449219,
      "learning_rate": 9.786690433749259e-05,
      "loss": 0.0851,
      "step": 360
    },
    {
      "epoch": 0.6595365418894831,
      "grad_norm": 0.8013123869895935,
      "learning_rate": 9.780748663101605e-05,
      "loss": 0.0786,
      "step": 370
    },
    {
      "epoch": 0.6773618538324421,
      "grad_norm": 1.9009459018707275,
      "learning_rate": 9.774806892453951e-05,
      "loss": 0.0871,
      "step": 380
    },
    {
      "epoch": 0.6951871657754011,
      "grad_norm": 1.2699426412582397,
      "learning_rate": 9.768865121806299e-05,
      "loss": 0.0714,
      "step": 390
    },
    {
      "epoch": 0.7130124777183601,
      "grad_norm": 2.7403767108917236,
      "learning_rate": 9.762923351158646e-05,
      "loss": 0.1007,
      "step": 400
    },
    {
      "epoch": 0.7308377896613191,
      "grad_norm": 1.577702283859253,
      "learning_rate": 9.756981580510994e-05,
      "loss": 0.0885,
      "step": 410
    },
    {
      "epoch": 0.7486631016042781,
      "grad_norm": 1.3277921676635742,
      "learning_rate": 9.75103980986334e-05,
      "loss": 0.0926,
      "step": 420
    },
    {
      "epoch": 0.7664884135472371,
      "grad_norm": 0.7187272310256958,
      "learning_rate": 9.745098039215686e-05,
      "loss": 0.0827,
      "step": 430
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.4360947906970978,
      "learning_rate": 9.739156268568033e-05,
      "loss": 0.0823,
      "step": 440
    },
    {
      "epoch": 0.8021390374331551,
      "grad_norm": 2.3538734912872314,
      "learning_rate": 9.733214497920381e-05,
      "loss": 0.0816,
      "step": 450
    },
    {
      "epoch": 0.8199643493761141,
      "grad_norm": 3.3608357906341553,
      "learning_rate": 9.727272727272728e-05,
      "loss": 0.085,
      "step": 460
    },
    {
      "epoch": 0.8377896613190731,
      "grad_norm": 0.6244567632675171,
      "learning_rate": 9.721330956625075e-05,
      "loss": 0.0748,
      "step": 470
    },
    {
      "epoch": 0.8556149732620321,
      "grad_norm": 0.8333702087402344,
      "learning_rate": 9.715389185977422e-05,
      "loss": 0.0836,
      "step": 480
    },
    {
      "epoch": 0.8734402852049911,
      "grad_norm": 1.2753477096557617,
      "learning_rate": 9.709447415329768e-05,
      "loss": 0.0754,
      "step": 490
    },
    {
      "epoch": 0.8912655971479501,
      "grad_norm": 0.36384254693984985,
      "learning_rate": 9.703505644682116e-05,
      "loss": 0.0846,
      "step": 500
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 1.0493072271347046,
      "learning_rate": 9.697563874034463e-05,
      "loss": 0.0767,
      "step": 510
    },
    {
      "epoch": 0.9269162210338681,
      "grad_norm": 0.7992426753044128,
      "learning_rate": 9.69162210338681e-05,
      "loss": 0.0724,
      "step": 520
    },
    {
      "epoch": 0.9447415329768271,
      "grad_norm": 0.247670978307724,
      "learning_rate": 9.685680332739157e-05,
      "loss": 0.0753,
      "step": 530
    },
    {
      "epoch": 0.9625668449197861,
      "grad_norm": 2.009204387664795,
      "learning_rate": 9.679738562091504e-05,
      "loss": 0.0749,
      "step": 540
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 1.7511528730392456,
      "learning_rate": 9.67379679144385e-05,
      "loss": 0.0721,
      "step": 550
    },
    {
      "epoch": 0.9982174688057041,
      "grad_norm": 2.273777484893799,
      "learning_rate": 9.667855020796198e-05,
      "loss": 0.0864,
      "step": 560
    },
    {
      "epoch": 1.0160427807486632,
      "grad_norm": 1.7869539260864258,
      "learning_rate": 9.661913250148544e-05,
      "loss": 0.0745,
      "step": 570
    },
    {
      "epoch": 1.0338680926916222,
      "grad_norm": 0.8745821714401245,
      "learning_rate": 9.655971479500892e-05,
      "loss": 0.0781,
      "step": 580
    },
    {
      "epoch": 1.0516934046345812,
      "grad_norm": 1.7363662719726562,
      "learning_rate": 9.650029708853239e-05,
      "loss": 0.0827,
      "step": 590
    },
    {
      "epoch": 1.0695187165775402,
      "grad_norm": 2.561957597732544,
      "learning_rate": 9.644087938205585e-05,
      "loss": 0.0787,
      "step": 600
    },
    {
      "epoch": 1.0873440285204992,
      "grad_norm": 0.8542084693908691,
      "learning_rate": 9.638146167557933e-05,
      "loss": 0.0658,
      "step": 610
    },
    {
      "epoch": 1.1051693404634582,
      "grad_norm": 2.488640308380127,
      "learning_rate": 9.632204396910279e-05,
      "loss": 0.063,
      "step": 620
    },
    {
      "epoch": 1.1229946524064172,
      "grad_norm": 2.7261948585510254,
      "learning_rate": 9.626262626262627e-05,
      "loss": 0.0825,
      "step": 630
    },
    {
      "epoch": 1.1408199643493762,
      "grad_norm": 0.9788848757743835,
      "learning_rate": 9.620320855614974e-05,
      "loss": 0.0686,
      "step": 640
    },
    {
      "epoch": 1.1586452762923352,
      "grad_norm": 2.2693629264831543,
      "learning_rate": 9.614379084967322e-05,
      "loss": 0.0706,
      "step": 650
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.3729914426803589,
      "learning_rate": 9.608437314319668e-05,
      "loss": 0.0684,
      "step": 660
    },
    {
      "epoch": 1.1942959001782532,
      "grad_norm": 3.251713275909424,
      "learning_rate": 9.602495543672014e-05,
      "loss": 0.072,
      "step": 670
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 2.6977179050445557,
      "learning_rate": 9.596553773024361e-05,
      "loss": 0.0718,
      "step": 680
    },
    {
      "epoch": 1.2299465240641712,
      "grad_norm": 0.4182545244693756,
      "learning_rate": 9.590612002376709e-05,
      "loss": 0.0816,
      "step": 690
    },
    {
      "epoch": 1.2477718360071302,
      "grad_norm": 0.5488259792327881,
      "learning_rate": 9.584670231729056e-05,
      "loss": 0.0797,
      "step": 700
    },
    {
      "epoch": 1.2655971479500892,
      "grad_norm": 0.74412602186203,
      "learning_rate": 9.578728461081404e-05,
      "loss": 0.077,
      "step": 710
    },
    {
      "epoch": 1.2834224598930482,
      "grad_norm": 0.6227920651435852,
      "learning_rate": 9.572786690433749e-05,
      "loss": 0.072,
      "step": 720
    },
    {
      "epoch": 1.3012477718360071,
      "grad_norm": 1.012686014175415,
      "learning_rate": 9.566844919786096e-05,
      "loss": 0.0757,
      "step": 730
    },
    {
      "epoch": 1.3190730837789661,
      "grad_norm": 1.0415199995040894,
      "learning_rate": 9.560903149138444e-05,
      "loss": 0.0719,
      "step": 740
    },
    {
      "epoch": 1.3368983957219251,
      "grad_norm": 2.4227986335754395,
      "learning_rate": 9.554961378490791e-05,
      "loss": 0.0814,
      "step": 750
    },
    {
      "epoch": 1.3547237076648841,
      "grad_norm": 0.5716338753700256,
      "learning_rate": 9.549019607843139e-05,
      "loss": 0.071,
      "step": 760
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.9655324816703796,
      "learning_rate": 9.543077837195485e-05,
      "loss": 0.073,
      "step": 770
    },
    {
      "epoch": 1.3903743315508021,
      "grad_norm": 1.1905720233917236,
      "learning_rate": 9.537136066547831e-05,
      "loss": 0.0851,
      "step": 780
    },
    {
      "epoch": 1.4081996434937611,
      "grad_norm": 1.4910694360733032,
      "learning_rate": 9.531194295900178e-05,
      "loss": 0.0791,
      "step": 790
    },
    {
      "epoch": 1.4260249554367201,
      "grad_norm": 0.6172429919242859,
      "learning_rate": 9.525252525252526e-05,
      "loss": 0.0727,
      "step": 800
    },
    {
      "epoch": 1.4438502673796791,
      "grad_norm": 0.9972111582756042,
      "learning_rate": 9.519310754604873e-05,
      "loss": 0.081,
      "step": 810
    },
    {
      "epoch": 1.4616755793226381,
      "grad_norm": 0.3080653250217438,
      "learning_rate": 9.51336898395722e-05,
      "loss": 0.078,
      "step": 820
    },
    {
      "epoch": 1.4795008912655971,
      "grad_norm": 0.4634961187839508,
      "learning_rate": 9.507427213309567e-05,
      "loss": 0.0624,
      "step": 830
    },
    {
      "epoch": 1.4973262032085561,
      "grad_norm": 0.6282482743263245,
      "learning_rate": 9.501485442661913e-05,
      "loss": 0.0753,
      "step": 840
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 2.6350913047790527,
      "learning_rate": 9.495543672014261e-05,
      "loss": 0.0692,
      "step": 850
    },
    {
      "epoch": 1.5329768270944741,
      "grad_norm": 0.5082456469535828,
      "learning_rate": 9.489601901366608e-05,
      "loss": 0.0736,
      "step": 860
    },
    {
      "epoch": 1.5508021390374331,
      "grad_norm": 1.3003425598144531,
      "learning_rate": 9.483660130718954e-05,
      "loss": 0.076,
      "step": 870
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 1.9438449144363403,
      "learning_rate": 9.477718360071302e-05,
      "loss": 0.0655,
      "step": 880
    },
    {
      "epoch": 1.5864527629233511,
      "grad_norm": 0.7823727130889893,
      "learning_rate": 9.471776589423648e-05,
      "loss": 0.0727,
      "step": 890
    },
    {
      "epoch": 1.6042780748663101,
      "grad_norm": 0.6357138752937317,
      "learning_rate": 9.465834818775996e-05,
      "loss": 0.0641,
      "step": 900
    },
    {
      "epoch": 1.6221033868092691,
      "grad_norm": 1.0096246004104614,
      "learning_rate": 9.459893048128343e-05,
      "loss": 0.0668,
      "step": 910
    },
    {
      "epoch": 1.6399286987522281,
      "grad_norm": 0.7335953712463379,
      "learning_rate": 9.453951277480689e-05,
      "loss": 0.0705,
      "step": 920
    },
    {
      "epoch": 1.6577540106951871,
      "grad_norm": 2.861361265182495,
      "learning_rate": 9.448009506833037e-05,
      "loss": 0.0681,
      "step": 930
    },
    {
      "epoch": 1.6755793226381461,
      "grad_norm": 1.0527374744415283,
      "learning_rate": 9.442067736185384e-05,
      "loss": 0.0842,
      "step": 940
    },
    {
      "epoch": 1.6934046345811051,
      "grad_norm": 0.4174957871437073,
      "learning_rate": 9.43612596553773e-05,
      "loss": 0.0745,
      "step": 950
    },
    {
      "epoch": 1.7112299465240641,
      "grad_norm": 2.9471635818481445,
      "learning_rate": 9.430184194890078e-05,
      "loss": 0.0844,
      "step": 960
    },
    {
      "epoch": 1.7290552584670231,
      "grad_norm": 1.2941744327545166,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.0669,
      "step": 970
    },
    {
      "epoch": 1.7468805704099821,
      "grad_norm": 2.1448373794555664,
      "learning_rate": 9.418300653594772e-05,
      "loss": 0.0832,
      "step": 980
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 1.6024606227874756,
      "learning_rate": 9.412358882947119e-05,
      "loss": 0.0612,
      "step": 990
    },
    {
      "epoch": 1.7825311942959001,
      "grad_norm": 1.5058337450027466,
      "learning_rate": 9.406417112299467e-05,
      "loss": 0.0568,
      "step": 1000
    },
    {
      "epoch": 1.8003565062388591,
      "grad_norm": 1.5203118324279785,
      "learning_rate": 9.400475341651813e-05,
      "loss": 0.0736,
      "step": 1010
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 1.5111110210418701,
      "learning_rate": 9.394533571004159e-05,
      "loss": 0.0688,
      "step": 1020
    },
    {
      "epoch": 1.8360071301247771,
      "grad_norm": 12.75805377960205,
      "learning_rate": 9.388591800356506e-05,
      "loss": 0.0822,
      "step": 1030
    },
    {
      "epoch": 1.8538324420677363,
      "grad_norm": 0.5004165768623352,
      "learning_rate": 9.382650029708854e-05,
      "loss": 0.0778,
      "step": 1040
    },
    {
      "epoch": 1.8716577540106951,
      "grad_norm": 0.5250139832496643,
      "learning_rate": 9.376708259061201e-05,
      "loss": 0.0667,
      "step": 1050
    },
    {
      "epoch": 1.8894830659536543,
      "grad_norm": 0.7455030083656311,
      "learning_rate": 9.370766488413548e-05,
      "loss": 0.072,
      "step": 1060
    },
    {
      "epoch": 1.9073083778966131,
      "grad_norm": 1.037361741065979,
      "learning_rate": 9.364824717765894e-05,
      "loss": 0.0737,
      "step": 1070
    },
    {
      "epoch": 1.9251336898395723,
      "grad_norm": 1.4048023223876953,
      "learning_rate": 9.358882947118241e-05,
      "loss": 0.0761,
      "step": 1080
    },
    {
      "epoch": 1.9429590017825311,
      "grad_norm": 1.3925009965896606,
      "learning_rate": 9.352941176470589e-05,
      "loss": 0.0708,
      "step": 1090
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.932715117931366,
      "learning_rate": 9.346999405822936e-05,
      "loss": 0.0654,
      "step": 1100
    },
    {
      "epoch": 1.9786096256684491,
      "grad_norm": 1.5759881734848022,
      "learning_rate": 9.341057635175284e-05,
      "loss": 0.0717,
      "step": 1110
    },
    {
      "epoch": 1.9964349376114083,
      "grad_norm": 0.42173853516578674,
      "learning_rate": 9.33511586452763e-05,
      "loss": 0.0794,
      "step": 1120
    },
    {
      "epoch": 2.014260249554367,
      "grad_norm": 2.181184768676758,
      "learning_rate": 9.329174093879976e-05,
      "loss": 0.0657,
      "step": 1130
    },
    {
      "epoch": 2.0320855614973263,
      "grad_norm": 0.4572852551937103,
      "learning_rate": 9.323232323232324e-05,
      "loss": 0.062,
      "step": 1140
    },
    {
      "epoch": 2.049910873440285,
      "grad_norm": 2.5196170806884766,
      "learning_rate": 9.317290552584671e-05,
      "loss": 0.0722,
      "step": 1150
    },
    {
      "epoch": 2.0677361853832443,
      "grad_norm": 2.86368727684021,
      "learning_rate": 9.311348781937019e-05,
      "loss": 0.0707,
      "step": 1160
    },
    {
      "epoch": 2.085561497326203,
      "grad_norm": 1.5067435503005981,
      "learning_rate": 9.305407011289365e-05,
      "loss": 0.069,
      "step": 1170
    },
    {
      "epoch": 2.1033868092691623,
      "grad_norm": 1.4405242204666138,
      "learning_rate": 9.299465240641711e-05,
      "loss": 0.0807,
      "step": 1180
    },
    {
      "epoch": 2.121212121212121,
      "grad_norm": 0.6638458967208862,
      "learning_rate": 9.293523469994058e-05,
      "loss": 0.0808,
      "step": 1190
    },
    {
      "epoch": 2.1390374331550803,
      "grad_norm": 2.045290946960449,
      "learning_rate": 9.287581699346406e-05,
      "loss": 0.0779,
      "step": 1200
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 2.2159128189086914,
      "learning_rate": 9.281639928698753e-05,
      "loss": 0.0697,
      "step": 1210
    },
    {
      "epoch": 2.1746880570409983,
      "grad_norm": 1.9856102466583252,
      "learning_rate": 9.2756981580511e-05,
      "loss": 0.08,
      "step": 1220
    },
    {
      "epoch": 2.192513368983957,
      "grad_norm": 1.3872166872024536,
      "learning_rate": 9.269756387403447e-05,
      "loss": 0.0742,
      "step": 1230
    },
    {
      "epoch": 2.2103386809269163,
      "grad_norm": 3.4401071071624756,
      "learning_rate": 9.263814616755793e-05,
      "loss": 0.0708,
      "step": 1240
    },
    {
      "epoch": 2.228163992869875,
      "grad_norm": 1.245591640472412,
      "learning_rate": 9.257872846108141e-05,
      "loss": 0.0736,
      "step": 1250
    },
    {
      "epoch": 2.2459893048128343,
      "grad_norm": 0.902249276638031,
      "learning_rate": 9.251931075460488e-05,
      "loss": 0.0749,
      "step": 1260
    },
    {
      "epoch": 2.263814616755793,
      "grad_norm": 0.35010814666748047,
      "learning_rate": 9.245989304812834e-05,
      "loss": 0.0673,
      "step": 1270
    },
    {
      "epoch": 2.2816399286987523,
      "grad_norm": 0.6905981302261353,
      "learning_rate": 9.240047534165182e-05,
      "loss": 0.0731,
      "step": 1280
    },
    {
      "epoch": 2.299465240641711,
      "grad_norm": 0.8821345567703247,
      "learning_rate": 9.23410576351753e-05,
      "loss": 0.0728,
      "step": 1290
    },
    {
      "epoch": 2.3172905525846703,
      "grad_norm": 1.3360180854797363,
      "learning_rate": 9.228163992869876e-05,
      "loss": 0.0773,
      "step": 1300
    },
    {
      "epoch": 2.335115864527629,
      "grad_norm": 0.5292288661003113,
      "learning_rate": 9.222222222222223e-05,
      "loss": 0.064,
      "step": 1310
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 2.1085147857666016,
      "learning_rate": 9.216280451574569e-05,
      "loss": 0.0698,
      "step": 1320
    },
    {
      "epoch": 2.370766488413547,
      "grad_norm": 2.825565814971924,
      "learning_rate": 9.210338680926917e-05,
      "loss": 0.0653,
      "step": 1330
    },
    {
      "epoch": 2.3885918003565063,
      "grad_norm": 0.540935218334198,
      "learning_rate": 9.204396910279264e-05,
      "loss": 0.0619,
      "step": 1340
    },
    {
      "epoch": 2.406417112299465,
      "grad_norm": 2.002366065979004,
      "learning_rate": 9.19845513963161e-05,
      "loss": 0.0711,
      "step": 1350
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 0.9194257855415344,
      "learning_rate": 9.192513368983958e-05,
      "loss": 0.0751,
      "step": 1360
    },
    {
      "epoch": 2.442067736185383,
      "grad_norm": 1.0692402124404907,
      "learning_rate": 9.186571598336304e-05,
      "loss": 0.0791,
      "step": 1370
    },
    {
      "epoch": 2.4598930481283423,
      "grad_norm": 0.4880763590335846,
      "learning_rate": 9.180629827688652e-05,
      "loss": 0.0696,
      "step": 1380
    },
    {
      "epoch": 2.477718360071301,
      "grad_norm": 1.0208271741867065,
      "learning_rate": 9.174688057040999e-05,
      "loss": 0.0557,
      "step": 1390
    },
    {
      "epoch": 2.4955436720142603,
      "grad_norm": 1.1482819318771362,
      "learning_rate": 9.168746286393347e-05,
      "loss": 0.0577,
      "step": 1400
    },
    {
      "epoch": 2.5133689839572195,
      "grad_norm": 1.437875509262085,
      "learning_rate": 9.162804515745693e-05,
      "loss": 0.0807,
      "step": 1410
    },
    {
      "epoch": 2.5311942959001783,
      "grad_norm": 0.965236485004425,
      "learning_rate": 9.156862745098039e-05,
      "loss": 0.0765,
      "step": 1420
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.8824598789215088,
      "learning_rate": 9.150920974450386e-05,
      "loss": 0.0663,
      "step": 1430
    },
    {
      "epoch": 2.5668449197860963,
      "grad_norm": 0.814509391784668,
      "learning_rate": 9.144979203802734e-05,
      "loss": 0.073,
      "step": 1440
    },
    {
      "epoch": 2.5846702317290555,
      "grad_norm": 0.9232579469680786,
      "learning_rate": 9.139037433155081e-05,
      "loss": 0.0648,
      "step": 1450
    },
    {
      "epoch": 2.6024955436720143,
      "grad_norm": 0.5117189288139343,
      "learning_rate": 9.133095662507428e-05,
      "loss": 0.066,
      "step": 1460
    },
    {
      "epoch": 2.620320855614973,
      "grad_norm": 1.178735613822937,
      "learning_rate": 9.127153891859774e-05,
      "loss": 0.0739,
      "step": 1470
    },
    {
      "epoch": 2.6381461675579323,
      "grad_norm": 3.1361260414123535,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.0671,
      "step": 1480
    },
    {
      "epoch": 2.6559714795008915,
      "grad_norm": 1.8379554748535156,
      "learning_rate": 9.115270350564469e-05,
      "loss": 0.0637,
      "step": 1490
    },
    {
      "epoch": 2.6737967914438503,
      "grad_norm": 1.3496004343032837,
      "learning_rate": 9.109328579916816e-05,
      "loss": 0.0678,
      "step": 1500
    },
    {
      "epoch": 2.691622103386809,
      "grad_norm": 1.8681542873382568,
      "learning_rate": 9.103386809269162e-05,
      "loss": 0.0683,
      "step": 1510
    },
    {
      "epoch": 2.7094474153297683,
      "grad_norm": 1.1856029033660889,
      "learning_rate": 9.09744503862151e-05,
      "loss": 0.0656,
      "step": 1520
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.7316603660583496,
      "learning_rate": 9.091503267973856e-05,
      "loss": 0.0702,
      "step": 1530
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.9197120666503906,
      "learning_rate": 9.085561497326204e-05,
      "loss": 0.0658,
      "step": 1540
    },
    {
      "epoch": 2.762923351158645,
      "grad_norm": 0.6787629127502441,
      "learning_rate": 9.079619726678551e-05,
      "loss": 0.066,
      "step": 1550
    },
    {
      "epoch": 2.7807486631016043,
      "grad_norm": 2.2698745727539062,
      "learning_rate": 9.073677956030897e-05,
      "loss": 0.0671,
      "step": 1560
    },
    {
      "epoch": 2.7985739750445635,
      "grad_norm": 1.7645494937896729,
      "learning_rate": 9.067736185383245e-05,
      "loss": 0.0711,
      "step": 1570
    },
    {
      "epoch": 2.8163992869875223,
      "grad_norm": 0.9534524083137512,
      "learning_rate": 9.061794414735592e-05,
      "loss": 0.0677,
      "step": 1580
    },
    {
      "epoch": 2.834224598930481,
      "grad_norm": 1.2714121341705322,
      "learning_rate": 9.055852644087938e-05,
      "loss": 0.0649,
      "step": 1590
    },
    {
      "epoch": 2.8520499108734403,
      "grad_norm": 1.4090484380722046,
      "learning_rate": 9.049910873440286e-05,
      "loss": 0.0626,
      "step": 1600
    },
    {
      "epoch": 2.8698752228163995,
      "grad_norm": 0.4346409738063812,
      "learning_rate": 9.043969102792632e-05,
      "loss": 0.072,
      "step": 1610
    },
    {
      "epoch": 2.8877005347593583,
      "grad_norm": 0.5631014704704285,
      "learning_rate": 9.03802733214498e-05,
      "loss": 0.0667,
      "step": 1620
    },
    {
      "epoch": 2.905525846702317,
      "grad_norm": 0.6097598075866699,
      "learning_rate": 9.032085561497327e-05,
      "loss": 0.0589,
      "step": 1630
    },
    {
      "epoch": 2.9233511586452763,
      "grad_norm": 0.5438442826271057,
      "learning_rate": 9.026143790849673e-05,
      "loss": 0.058,
      "step": 1640
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 1.0493528842926025,
      "learning_rate": 9.02020202020202e-05,
      "loss": 0.0679,
      "step": 1650
    },
    {
      "epoch": 2.9590017825311943,
      "grad_norm": 1.5613532066345215,
      "learning_rate": 9.014260249554367e-05,
      "loss": 0.0579,
      "step": 1660
    },
    {
      "epoch": 2.976827094474153,
      "grad_norm": 4.828672885894775,
      "learning_rate": 9.008318478906714e-05,
      "loss": 0.0694,
      "step": 1670
    },
    {
      "epoch": 2.9946524064171123,
      "grad_norm": 1.7604211568832397,
      "learning_rate": 9.002376708259062e-05,
      "loss": 0.0707,
      "step": 1680
    },
    {
      "epoch": 3.0124777183600715,
      "grad_norm": 0.6952521204948425,
      "learning_rate": 8.99643493761141e-05,
      "loss": 0.0611,
      "step": 1690
    },
    {
      "epoch": 3.0303030303030303,
      "grad_norm": 0.6906588673591614,
      "learning_rate": 8.990493166963755e-05,
      "loss": 0.0637,
      "step": 1700
    },
    {
      "epoch": 3.0481283422459895,
      "grad_norm": 0.5038368105888367,
      "learning_rate": 8.984551396316102e-05,
      "loss": 0.064,
      "step": 1710
    },
    {
      "epoch": 3.0659536541889483,
      "grad_norm": 1.0654709339141846,
      "learning_rate": 8.978609625668449e-05,
      "loss": 0.0697,
      "step": 1720
    },
    {
      "epoch": 3.0837789661319075,
      "grad_norm": 0.4976261556148529,
      "learning_rate": 8.972667855020797e-05,
      "loss": 0.066,
      "step": 1730
    },
    {
      "epoch": 3.1016042780748663,
      "grad_norm": 0.7342442870140076,
      "learning_rate": 8.966726084373144e-05,
      "loss": 0.0638,
      "step": 1740
    },
    {
      "epoch": 3.1194295900178255,
      "grad_norm": 1.5856959819793701,
      "learning_rate": 8.96078431372549e-05,
      "loss": 0.0639,
      "step": 1750
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 2.1853156089782715,
      "learning_rate": 8.954842543077836e-05,
      "loss": 0.072,
      "step": 1760
    },
    {
      "epoch": 3.1550802139037435,
      "grad_norm": 1.826242446899414,
      "learning_rate": 8.948900772430184e-05,
      "loss": 0.0661,
      "step": 1770
    },
    {
      "epoch": 3.1729055258467023,
      "grad_norm": 0.6079400181770325,
      "learning_rate": 8.942959001782531e-05,
      "loss": 0.0664,
      "step": 1780
    },
    {
      "epoch": 3.1907308377896615,
      "grad_norm": 0.9453466534614563,
      "learning_rate": 8.937017231134879e-05,
      "loss": 0.0638,
      "step": 1790
    },
    {
      "epoch": 3.2085561497326203,
      "grad_norm": 0.9523444175720215,
      "learning_rate": 8.931075460487226e-05,
      "loss": 0.0586,
      "step": 1800
    },
    {
      "epoch": 3.2263814616755795,
      "grad_norm": 0.38264960050582886,
      "learning_rate": 8.925133689839573e-05,
      "loss": 0.0718,
      "step": 1810
    },
    {
      "epoch": 3.2442067736185383,
      "grad_norm": 1.1238354444503784,
      "learning_rate": 8.919191919191919e-05,
      "loss": 0.0713,
      "step": 1820
    },
    {
      "epoch": 3.2620320855614975,
      "grad_norm": 1.6050833463668823,
      "learning_rate": 8.913250148544266e-05,
      "loss": 0.066,
      "step": 1830
    },
    {
      "epoch": 3.2798573975044563,
      "grad_norm": 1.0205708742141724,
      "learning_rate": 8.907308377896614e-05,
      "loss": 0.0681,
      "step": 1840
    },
    {
      "epoch": 3.2976827094474155,
      "grad_norm": 0.834623396396637,
      "learning_rate": 8.901366607248961e-05,
      "loss": 0.0653,
      "step": 1850
    },
    {
      "epoch": 3.3155080213903743,
      "grad_norm": 1.0445221662521362,
      "learning_rate": 8.895424836601307e-05,
      "loss": 0.071,
      "step": 1860
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.35648754239082336,
      "learning_rate": 8.889483065953655e-05,
      "loss": 0.0694,
      "step": 1870
    },
    {
      "epoch": 3.3511586452762923,
      "grad_norm": 0.6237878799438477,
      "learning_rate": 8.883541295306001e-05,
      "loss": 0.0739,
      "step": 1880
    },
    {
      "epoch": 3.3689839572192515,
      "grad_norm": 1.426221489906311,
      "learning_rate": 8.877599524658349e-05,
      "loss": 0.0622,
      "step": 1890
    },
    {
      "epoch": 3.3868092691622103,
      "grad_norm": 0.7093082666397095,
      "learning_rate": 8.871657754010696e-05,
      "loss": 0.0545,
      "step": 1900
    },
    {
      "epoch": 3.4046345811051695,
      "grad_norm": 0.9330978989601135,
      "learning_rate": 8.865715983363042e-05,
      "loss": 0.0562,
      "step": 1910
    },
    {
      "epoch": 3.4224598930481283,
      "grad_norm": 1.2807163000106812,
      "learning_rate": 8.85977421271539e-05,
      "loss": 0.0596,
      "step": 1920
    },
    {
      "epoch": 3.4402852049910875,
      "grad_norm": 1.8441739082336426,
      "learning_rate": 8.853832442067736e-05,
      "loss": 0.0618,
      "step": 1930
    },
    {
      "epoch": 3.4581105169340463,
      "grad_norm": 1.1254298686981201,
      "learning_rate": 8.847890671420083e-05,
      "loss": 0.061,
      "step": 1940
    },
    {
      "epoch": 3.4759358288770055,
      "grad_norm": 1.0188450813293457,
      "learning_rate": 8.841948900772431e-05,
      "loss": 0.0732,
      "step": 1950
    },
    {
      "epoch": 3.4937611408199643,
      "grad_norm": 1.1059114933013916,
      "learning_rate": 8.836007130124777e-05,
      "loss": 0.064,
      "step": 1960
    },
    {
      "epoch": 3.5115864527629235,
      "grad_norm": 0.6519009470939636,
      "learning_rate": 8.830065359477125e-05,
      "loss": 0.0627,
      "step": 1970
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 1.2396538257598877,
      "learning_rate": 8.824123588829472e-05,
      "loss": 0.0609,
      "step": 1980
    },
    {
      "epoch": 3.5472370766488415,
      "grad_norm": 1.200365662574768,
      "learning_rate": 8.818181818181818e-05,
      "loss": 0.062,
      "step": 1990
    },
    {
      "epoch": 3.5650623885918002,
      "grad_norm": 0.35184788703918457,
      "learning_rate": 8.812240047534166e-05,
      "loss": 0.0562,
      "step": 2000
    },
    {
      "epoch": 3.5828877005347595,
      "grad_norm": 7.043722152709961,
      "learning_rate": 8.806298276886512e-05,
      "loss": 0.0696,
      "step": 2010
    },
    {
      "epoch": 3.6007130124777182,
      "grad_norm": 1.3685215711593628,
      "learning_rate": 8.80035650623886e-05,
      "loss": 0.069,
      "step": 2020
    },
    {
      "epoch": 3.6185383244206775,
      "grad_norm": 1.9428130388259888,
      "learning_rate": 8.794414735591207e-05,
      "loss": 0.0714,
      "step": 2030
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 1.2051527500152588,
      "learning_rate": 8.788472964943553e-05,
      "loss": 0.0617,
      "step": 2040
    },
    {
      "epoch": 3.6541889483065955,
      "grad_norm": 1.477576494216919,
      "learning_rate": 8.7825311942959e-05,
      "loss": 0.0636,
      "step": 2050
    },
    {
      "epoch": 3.6720142602495542,
      "grad_norm": 2.014460325241089,
      "learning_rate": 8.776589423648247e-05,
      "loss": 0.0598,
      "step": 2060
    },
    {
      "epoch": 3.6898395721925135,
      "grad_norm": 0.5892982482910156,
      "learning_rate": 8.770647653000594e-05,
      "loss": 0.0564,
      "step": 2070
    },
    {
      "epoch": 3.7076648841354722,
      "grad_norm": 0.953137218952179,
      "learning_rate": 8.764705882352942e-05,
      "loss": 0.0536,
      "step": 2080
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 0.5525073409080505,
      "learning_rate": 8.758764111705289e-05,
      "loss": 0.0647,
      "step": 2090
    },
    {
      "epoch": 3.7433155080213902,
      "grad_norm": 1.6218563318252563,
      "learning_rate": 8.752822341057635e-05,
      "loss": 0.0597,
      "step": 2100
    },
    {
      "epoch": 3.7611408199643495,
      "grad_norm": 1.7975802421569824,
      "learning_rate": 8.746880570409982e-05,
      "loss": 0.0666,
      "step": 2110
    },
    {
      "epoch": 3.7789661319073082,
      "grad_norm": 4.19077730178833,
      "learning_rate": 8.740938799762329e-05,
      "loss": 0.0646,
      "step": 2120
    },
    {
      "epoch": 3.7967914438502675,
      "grad_norm": 1.8483229875564575,
      "learning_rate": 8.734997029114677e-05,
      "loss": 0.0601,
      "step": 2130
    },
    {
      "epoch": 3.8146167557932262,
      "grad_norm": 1.3599950075149536,
      "learning_rate": 8.729055258467024e-05,
      "loss": 0.0571,
      "step": 2140
    },
    {
      "epoch": 3.8324420677361855,
      "grad_norm": 1.1742033958435059,
      "learning_rate": 8.723113487819372e-05,
      "loss": 0.0544,
      "step": 2150
    },
    {
      "epoch": 3.8502673796791442,
      "grad_norm": 0.8453285694122314,
      "learning_rate": 8.717171717171718e-05,
      "loss": 0.0573,
      "step": 2160
    },
    {
      "epoch": 3.8680926916221035,
      "grad_norm": 0.9102671146392822,
      "learning_rate": 8.711229946524064e-05,
      "loss": 0.0639,
      "step": 2170
    },
    {
      "epoch": 3.8859180035650622,
      "grad_norm": 1.014635682106018,
      "learning_rate": 8.705288175876411e-05,
      "loss": 0.061,
      "step": 2180
    },
    {
      "epoch": 3.9037433155080214,
      "grad_norm": 0.6864395141601562,
      "learning_rate": 8.699346405228759e-05,
      "loss": 0.0604,
      "step": 2190
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 0.6095160841941833,
      "learning_rate": 8.693404634581106e-05,
      "loss": 0.0578,
      "step": 2200
    },
    {
      "epoch": 3.9393939393939394,
      "grad_norm": 0.4957096576690674,
      "learning_rate": 8.687462863933453e-05,
      "loss": 0.0715,
      "step": 2210
    },
    {
      "epoch": 3.9572192513368982,
      "grad_norm": 0.8311710953712463,
      "learning_rate": 8.681521093285799e-05,
      "loss": 0.0637,
      "step": 2220
    },
    {
      "epoch": 3.9750445632798574,
      "grad_norm": 1.557852864265442,
      "learning_rate": 8.675579322638146e-05,
      "loss": 0.0585,
      "step": 2230
    },
    {
      "epoch": 3.9928698752228167,
      "grad_norm": 1.7503389120101929,
      "learning_rate": 8.669637551990494e-05,
      "loss": 0.0612,
      "step": 2240
    },
    {
      "epoch": 4.010695187165775,
      "grad_norm": 0.6101937294006348,
      "learning_rate": 8.663695781342841e-05,
      "loss": 0.0509,
      "step": 2250
    },
    {
      "epoch": 4.028520499108734,
      "grad_norm": 1.3375802040100098,
      "learning_rate": 8.657754010695187e-05,
      "loss": 0.0708,
      "step": 2260
    },
    {
      "epoch": 4.046345811051693,
      "grad_norm": 3.5676987171173096,
      "learning_rate": 8.651812240047535e-05,
      "loss": 0.0623,
      "step": 2270
    },
    {
      "epoch": 4.064171122994653,
      "grad_norm": 0.5429566502571106,
      "learning_rate": 8.645870469399881e-05,
      "loss": 0.0658,
      "step": 2280
    },
    {
      "epoch": 4.081996434937611,
      "grad_norm": 2.8583261966705322,
      "learning_rate": 8.639928698752229e-05,
      "loss": 0.0668,
      "step": 2290
    },
    {
      "epoch": 4.09982174688057,
      "grad_norm": 0.5681296586990356,
      "learning_rate": 8.633986928104576e-05,
      "loss": 0.0578,
      "step": 2300
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 1.181878924369812,
      "learning_rate": 8.628045157456922e-05,
      "loss": 0.053,
      "step": 2310
    },
    {
      "epoch": 4.135472370766489,
      "grad_norm": 1.021420955657959,
      "learning_rate": 8.62210338680927e-05,
      "loss": 0.0659,
      "step": 2320
    },
    {
      "epoch": 4.153297682709447,
      "grad_norm": 1.0264395475387573,
      "learning_rate": 8.616161616161616e-05,
      "loss": 0.0603,
      "step": 2330
    },
    {
      "epoch": 4.171122994652406,
      "grad_norm": 0.8977153897285461,
      "learning_rate": 8.610219845513963e-05,
      "loss": 0.0556,
      "step": 2340
    },
    {
      "epoch": 4.188948306595365,
      "grad_norm": 0.33243250846862793,
      "learning_rate": 8.604278074866311e-05,
      "loss": 0.0638,
      "step": 2350
    },
    {
      "epoch": 4.206773618538325,
      "grad_norm": 0.8196575045585632,
      "learning_rate": 8.598336304218657e-05,
      "loss": 0.0624,
      "step": 2360
    },
    {
      "epoch": 4.224598930481283,
      "grad_norm": 1.0883055925369263,
      "learning_rate": 8.592394533571005e-05,
      "loss": 0.0535,
      "step": 2370
    },
    {
      "epoch": 4.242424242424242,
      "grad_norm": 0.9340024590492249,
      "learning_rate": 8.586452762923352e-05,
      "loss": 0.058,
      "step": 2380
    },
    {
      "epoch": 4.260249554367201,
      "grad_norm": 0.8797187805175781,
      "learning_rate": 8.580510992275698e-05,
      "loss": 0.0673,
      "step": 2390
    },
    {
      "epoch": 4.278074866310161,
      "grad_norm": 0.6596794724464417,
      "learning_rate": 8.574569221628046e-05,
      "loss": 0.0716,
      "step": 2400
    },
    {
      "epoch": 4.295900178253119,
      "grad_norm": 0.6465442776679993,
      "learning_rate": 8.568627450980392e-05,
      "loss": 0.0621,
      "step": 2410
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.49065664410591125,
      "learning_rate": 8.56268568033274e-05,
      "loss": 0.0619,
      "step": 2420
    },
    {
      "epoch": 4.331550802139038,
      "grad_norm": 1.0376794338226318,
      "learning_rate": 8.556743909685087e-05,
      "loss": 0.0616,
      "step": 2430
    },
    {
      "epoch": 4.349376114081997,
      "grad_norm": 0.875720739364624,
      "learning_rate": 8.550802139037434e-05,
      "loss": 0.0579,
      "step": 2440
    },
    {
      "epoch": 4.367201426024955,
      "grad_norm": 0.5708189010620117,
      "learning_rate": 8.54486036838978e-05,
      "loss": 0.0471,
      "step": 2450
    },
    {
      "epoch": 4.385026737967914,
      "grad_norm": 0.7402949333190918,
      "learning_rate": 8.538918597742127e-05,
      "loss": 0.0555,
      "step": 2460
    },
    {
      "epoch": 4.402852049910873,
      "grad_norm": 0.4136907458305359,
      "learning_rate": 8.532976827094474e-05,
      "loss": 0.0558,
      "step": 2470
    },
    {
      "epoch": 4.420677361853833,
      "grad_norm": 1.1820915937423706,
      "learning_rate": 8.527035056446822e-05,
      "loss": 0.0559,
      "step": 2480
    },
    {
      "epoch": 4.438502673796791,
      "grad_norm": 0.6573120951652527,
      "learning_rate": 8.521093285799169e-05,
      "loss": 0.0514,
      "step": 2490
    },
    {
      "epoch": 4.45632798573975,
      "grad_norm": 0.8318570256233215,
      "learning_rate": 8.515151515151515e-05,
      "loss": 0.0643,
      "step": 2500
    },
    {
      "epoch": 4.47415329768271,
      "grad_norm": 1.4172722101211548,
      "learning_rate": 8.509209744503862e-05,
      "loss": 0.0561,
      "step": 2510
    },
    {
      "epoch": 4.491978609625669,
      "grad_norm": 0.8317193984985352,
      "learning_rate": 8.503267973856209e-05,
      "loss": 0.0546,
      "step": 2520
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 0.44899046421051025,
      "learning_rate": 8.497326203208557e-05,
      "loss": 0.0522,
      "step": 2530
    },
    {
      "epoch": 4.527629233511586,
      "grad_norm": 1.620803952217102,
      "learning_rate": 8.491384432560904e-05,
      "loss": 0.0536,
      "step": 2540
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 3.465134859085083,
      "learning_rate": 8.485442661913252e-05,
      "loss": 0.0581,
      "step": 2550
    },
    {
      "epoch": 4.563279857397505,
      "grad_norm": 0.6784157752990723,
      "learning_rate": 8.479500891265598e-05,
      "loss": 0.0671,
      "step": 2560
    },
    {
      "epoch": 4.581105169340463,
      "grad_norm": 0.7070002555847168,
      "learning_rate": 8.473559120617944e-05,
      "loss": 0.0584,
      "step": 2570
    },
    {
      "epoch": 4.598930481283422,
      "grad_norm": 0.7986026406288147,
      "learning_rate": 8.467617349970291e-05,
      "loss": 0.0559,
      "step": 2580
    },
    {
      "epoch": 4.616755793226382,
      "grad_norm": 1.4002889394760132,
      "learning_rate": 8.461675579322639e-05,
      "loss": 0.063,
      "step": 2590
    },
    {
      "epoch": 4.634581105169341,
      "grad_norm": 0.7304086089134216,
      "learning_rate": 8.455733808674986e-05,
      "loss": 0.0507,
      "step": 2600
    },
    {
      "epoch": 4.652406417112299,
      "grad_norm": 0.8890425562858582,
      "learning_rate": 8.449792038027332e-05,
      "loss": 0.0527,
      "step": 2610
    },
    {
      "epoch": 4.670231729055258,
      "grad_norm": 1.4899518489837646,
      "learning_rate": 8.443850267379679e-05,
      "loss": 0.0545,
      "step": 2620
    },
    {
      "epoch": 4.688057040998218,
      "grad_norm": 1.2941815853118896,
      "learning_rate": 8.437908496732026e-05,
      "loss": 0.0571,
      "step": 2630
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.5082619190216064,
      "learning_rate": 8.431966726084374e-05,
      "loss": 0.058,
      "step": 2640
    },
    {
      "epoch": 4.723707664884135,
      "grad_norm": 1.8917230367660522,
      "learning_rate": 8.426024955436721e-05,
      "loss": 0.0555,
      "step": 2650
    },
    {
      "epoch": 4.741532976827094,
      "grad_norm": 1.1905033588409424,
      "learning_rate": 8.420083184789067e-05,
      "loss": 0.057,
      "step": 2660
    },
    {
      "epoch": 4.759358288770054,
      "grad_norm": 0.6105369329452515,
      "learning_rate": 8.414141414141415e-05,
      "loss": 0.0615,
      "step": 2670
    },
    {
      "epoch": 4.777183600713013,
      "grad_norm": 1.4007596969604492,
      "learning_rate": 8.408199643493761e-05,
      "loss": 0.0674,
      "step": 2680
    },
    {
      "epoch": 4.795008912655971,
      "grad_norm": 0.37711626291275024,
      "learning_rate": 8.402257872846108e-05,
      "loss": 0.0523,
      "step": 2690
    },
    {
      "epoch": 4.81283422459893,
      "grad_norm": 1.7970499992370605,
      "learning_rate": 8.396316102198456e-05,
      "loss": 0.055,
      "step": 2700
    },
    {
      "epoch": 4.83065953654189,
      "grad_norm": 0.4936138689517975,
      "learning_rate": 8.390374331550802e-05,
      "loss": 0.0532,
      "step": 2710
    },
    {
      "epoch": 4.848484848484849,
      "grad_norm": 1.0479092597961426,
      "learning_rate": 8.38443256090315e-05,
      "loss": 0.0589,
      "step": 2720
    },
    {
      "epoch": 4.866310160427807,
      "grad_norm": 0.5636249780654907,
      "learning_rate": 8.378490790255497e-05,
      "loss": 0.053,
      "step": 2730
    },
    {
      "epoch": 4.884135472370766,
      "grad_norm": 0.7015014290809631,
      "learning_rate": 8.372549019607843e-05,
      "loss": 0.0494,
      "step": 2740
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 2.95884108543396,
      "learning_rate": 8.366607248960191e-05,
      "loss": 0.0551,
      "step": 2750
    },
    {
      "epoch": 4.919786096256685,
      "grad_norm": 1.3219596147537231,
      "learning_rate": 8.360665478312537e-05,
      "loss": 0.059,
      "step": 2760
    },
    {
      "epoch": 4.937611408199643,
      "grad_norm": 1.6689331531524658,
      "learning_rate": 8.354723707664884e-05,
      "loss": 0.056,
      "step": 2770
    },
    {
      "epoch": 4.955436720142602,
      "grad_norm": 0.6394161581993103,
      "learning_rate": 8.348781937017232e-05,
      "loss": 0.0526,
      "step": 2780
    },
    {
      "epoch": 4.973262032085562,
      "grad_norm": 1.319082260131836,
      "learning_rate": 8.342840166369578e-05,
      "loss": 0.0507,
      "step": 2790
    },
    {
      "epoch": 4.991087344028521,
      "grad_norm": 0.993428111076355,
      "learning_rate": 8.336898395721926e-05,
      "loss": 0.0537,
      "step": 2800
    },
    {
      "epoch": 5.008912655971479,
      "grad_norm": 1.007253885269165,
      "learning_rate": 8.330956625074272e-05,
      "loss": 0.0573,
      "step": 2810
    },
    {
      "epoch": 5.026737967914438,
      "grad_norm": 0.6087019443511963,
      "learning_rate": 8.325014854426619e-05,
      "loss": 0.0539,
      "step": 2820
    },
    {
      "epoch": 5.044563279857398,
      "grad_norm": 1.8955847024917603,
      "learning_rate": 8.319073083778967e-05,
      "loss": 0.061,
      "step": 2830
    },
    {
      "epoch": 5.062388591800357,
      "grad_norm": 0.6863400936126709,
      "learning_rate": 8.313131313131314e-05,
      "loss": 0.0519,
      "step": 2840
    },
    {
      "epoch": 5.080213903743315,
      "grad_norm": 0.4306629002094269,
      "learning_rate": 8.30718954248366e-05,
      "loss": 0.0477,
      "step": 2850
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 1.0252282619476318,
      "learning_rate": 8.301247771836007e-05,
      "loss": 0.0529,
      "step": 2860
    },
    {
      "epoch": 5.115864527629234,
      "grad_norm": 0.7829915881156921,
      "learning_rate": 8.295306001188354e-05,
      "loss": 0.05,
      "step": 2870
    },
    {
      "epoch": 5.133689839572193,
      "grad_norm": 1.08614182472229,
      "learning_rate": 8.289364230540702e-05,
      "loss": 0.0476,
      "step": 2880
    },
    {
      "epoch": 5.151515151515151,
      "grad_norm": 1.543867588043213,
      "learning_rate": 8.283422459893049e-05,
      "loss": 0.0546,
      "step": 2890
    },
    {
      "epoch": 5.16934046345811,
      "grad_norm": 2.7765402793884277,
      "learning_rate": 8.277480689245397e-05,
      "loss": 0.0485,
      "step": 2900
    },
    {
      "epoch": 5.18716577540107,
      "grad_norm": 0.7612731456756592,
      "learning_rate": 8.271538918597741e-05,
      "loss": 0.048,
      "step": 2910
    },
    {
      "epoch": 5.204991087344029,
      "grad_norm": 0.3054793179035187,
      "learning_rate": 8.265597147950089e-05,
      "loss": 0.054,
      "step": 2920
    },
    {
      "epoch": 5.222816399286987,
      "grad_norm": 0.7589402794837952,
      "learning_rate": 8.259655377302436e-05,
      "loss": 0.0547,
      "step": 2930
    },
    {
      "epoch": 5.240641711229946,
      "grad_norm": 1.1461857557296753,
      "learning_rate": 8.253713606654784e-05,
      "loss": 0.0552,
      "step": 2940
    },
    {
      "epoch": 5.258467023172906,
      "grad_norm": 0.5019901394844055,
      "learning_rate": 8.247771836007131e-05,
      "loss": 0.0431,
      "step": 2950
    },
    {
      "epoch": 5.276292335115865,
      "grad_norm": 0.8923454880714417,
      "learning_rate": 8.241830065359478e-05,
      "loss": 0.0479,
      "step": 2960
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.5981969833374023,
      "learning_rate": 8.235888294711824e-05,
      "loss": 0.0456,
      "step": 2970
    },
    {
      "epoch": 5.311942959001782,
      "grad_norm": 0.7315544486045837,
      "learning_rate": 8.229946524064171e-05,
      "loss": 0.0582,
      "step": 2980
    },
    {
      "epoch": 5.329768270944742,
      "grad_norm": 1.538528323173523,
      "learning_rate": 8.224004753416519e-05,
      "loss": 0.0532,
      "step": 2990
    },
    {
      "epoch": 5.347593582887701,
      "grad_norm": 1.6684305667877197,
      "learning_rate": 8.218062982768866e-05,
      "loss": 0.0546,
      "step": 3000
    },
    {
      "epoch": 5.365418894830659,
      "grad_norm": 4.341624736785889,
      "learning_rate": 8.212121212121212e-05,
      "loss": 0.0553,
      "step": 3010
    },
    {
      "epoch": 5.383244206773618,
      "grad_norm": 0.708806574344635,
      "learning_rate": 8.20617944147356e-05,
      "loss": 0.0593,
      "step": 3020
    },
    {
      "epoch": 5.401069518716578,
      "grad_norm": 3.5497448444366455,
      "learning_rate": 8.200237670825906e-05,
      "loss": 0.0569,
      "step": 3030
    },
    {
      "epoch": 5.418894830659537,
      "grad_norm": 1.6413613557815552,
      "learning_rate": 8.194295900178254e-05,
      "loss": 0.0599,
      "step": 3040
    },
    {
      "epoch": 5.436720142602495,
      "grad_norm": 3.561091899871826,
      "learning_rate": 8.188354129530601e-05,
      "loss": 0.0483,
      "step": 3050
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 0.6708098649978638,
      "learning_rate": 8.182412358882947e-05,
      "loss": 0.0648,
      "step": 3060
    },
    {
      "epoch": 5.472370766488414,
      "grad_norm": 1.5544123649597168,
      "learning_rate": 8.176470588235295e-05,
      "loss": 0.055,
      "step": 3070
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.7802398800849915,
      "learning_rate": 8.170528817587641e-05,
      "loss": 0.057,
      "step": 3080
    },
    {
      "epoch": 5.508021390374331,
      "grad_norm": 1.1319084167480469,
      "learning_rate": 8.164587046939988e-05,
      "loss": 0.05,
      "step": 3090
    },
    {
      "epoch": 5.52584670231729,
      "grad_norm": 1.9799696207046509,
      "learning_rate": 8.158645276292336e-05,
      "loss": 0.0533,
      "step": 3100
    },
    {
      "epoch": 5.54367201426025,
      "grad_norm": 1.0435510873794556,
      "learning_rate": 8.152703505644682e-05,
      "loss": 0.0481,
      "step": 3110
    },
    {
      "epoch": 5.561497326203209,
      "grad_norm": 2.122065305709839,
      "learning_rate": 8.14676173499703e-05,
      "loss": 0.0535,
      "step": 3120
    },
    {
      "epoch": 5.579322638146167,
      "grad_norm": 1.872450351715088,
      "learning_rate": 8.140819964349377e-05,
      "loss": 0.0539,
      "step": 3130
    },
    {
      "epoch": 5.597147950089127,
      "grad_norm": 1.5376172065734863,
      "learning_rate": 8.134878193701723e-05,
      "loss": 0.0444,
      "step": 3140
    },
    {
      "epoch": 5.614973262032086,
      "grad_norm": 1.0319745540618896,
      "learning_rate": 8.128936423054071e-05,
      "loss": 0.056,
      "step": 3150
    },
    {
      "epoch": 5.632798573975045,
      "grad_norm": 1.2081286907196045,
      "learning_rate": 8.122994652406417e-05,
      "loss": 0.0481,
      "step": 3160
    },
    {
      "epoch": 5.650623885918003,
      "grad_norm": 2.321730136871338,
      "learning_rate": 8.117052881758764e-05,
      "loss": 0.0484,
      "step": 3170
    },
    {
      "epoch": 5.668449197860962,
      "grad_norm": 1.396385669708252,
      "learning_rate": 8.111111111111112e-05,
      "loss": 0.0573,
      "step": 3180
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 0.9917169213294983,
      "learning_rate": 8.10516934046346e-05,
      "loss": 0.0533,
      "step": 3190
    },
    {
      "epoch": 5.704099821746881,
      "grad_norm": 1.8567875623703003,
      "learning_rate": 8.099227569815806e-05,
      "loss": 0.0579,
      "step": 3200
    },
    {
      "epoch": 5.721925133689839,
      "grad_norm": 0.5206671953201294,
      "learning_rate": 8.093285799168152e-05,
      "loss": 0.0519,
      "step": 3210
    },
    {
      "epoch": 5.739750445632799,
      "grad_norm": 0.8169992566108704,
      "learning_rate": 8.087344028520499e-05,
      "loss": 0.0488,
      "step": 3220
    },
    {
      "epoch": 5.757575757575758,
      "grad_norm": 1.9980978965759277,
      "learning_rate": 8.081402257872847e-05,
      "loss": 0.0494,
      "step": 3230
    },
    {
      "epoch": 5.775401069518717,
      "grad_norm": 0.6814966201782227,
      "learning_rate": 8.075460487225194e-05,
      "loss": 0.0465,
      "step": 3240
    },
    {
      "epoch": 5.793226381461675,
      "grad_norm": 0.5509792566299438,
      "learning_rate": 8.06951871657754e-05,
      "loss": 0.0486,
      "step": 3250
    },
    {
      "epoch": 5.811051693404634,
      "grad_norm": 0.7268503308296204,
      "learning_rate": 8.063576945929887e-05,
      "loss": 0.0552,
      "step": 3260
    },
    {
      "epoch": 5.828877005347594,
      "grad_norm": 0.6056103706359863,
      "learning_rate": 8.057635175282234e-05,
      "loss": 0.0458,
      "step": 3270
    },
    {
      "epoch": 5.846702317290553,
      "grad_norm": 0.9086019396781921,
      "learning_rate": 8.051693404634582e-05,
      "loss": 0.0532,
      "step": 3280
    },
    {
      "epoch": 5.864527629233511,
      "grad_norm": 1.7330830097198486,
      "learning_rate": 8.045751633986929e-05,
      "loss": 0.0562,
      "step": 3290
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.7884342074394226,
      "learning_rate": 8.039809863339277e-05,
      "loss": 0.051,
      "step": 3300
    },
    {
      "epoch": 5.90017825311943,
      "grad_norm": 1.4000599384307861,
      "learning_rate": 8.033868092691623e-05,
      "loss": 0.0531,
      "step": 3310
    },
    {
      "epoch": 5.918003565062389,
      "grad_norm": 2.257129669189453,
      "learning_rate": 8.027926322043969e-05,
      "loss": 0.0503,
      "step": 3320
    },
    {
      "epoch": 5.935828877005347,
      "grad_norm": 0.5960944294929504,
      "learning_rate": 8.021984551396316e-05,
      "loss": 0.0453,
      "step": 3330
    },
    {
      "epoch": 5.953654188948306,
      "grad_norm": 1.0039831399917603,
      "learning_rate": 8.016042780748664e-05,
      "loss": 0.0494,
      "step": 3340
    },
    {
      "epoch": 5.971479500891266,
      "grad_norm": 0.8132453560829163,
      "learning_rate": 8.010101010101011e-05,
      "loss": 0.0447,
      "step": 3350
    },
    {
      "epoch": 5.989304812834225,
      "grad_norm": 1.3995805978775024,
      "learning_rate": 8.004159239453358e-05,
      "loss": 0.0468,
      "step": 3360
    },
    {
      "epoch": 6.007130124777183,
      "grad_norm": 0.49182063341140747,
      "learning_rate": 7.998217468805704e-05,
      "loss": 0.0464,
      "step": 3370
    },
    {
      "epoch": 6.024955436720143,
      "grad_norm": 1.2616479396820068,
      "learning_rate": 7.992275698158051e-05,
      "loss": 0.0457,
      "step": 3380
    },
    {
      "epoch": 6.042780748663102,
      "grad_norm": 0.7297670245170593,
      "learning_rate": 7.986333927510399e-05,
      "loss": 0.0468,
      "step": 3390
    },
    {
      "epoch": 6.0606060606060606,
      "grad_norm": 2.2107174396514893,
      "learning_rate": 7.980392156862746e-05,
      "loss": 0.0481,
      "step": 3400
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 1.554622769355774,
      "learning_rate": 7.974450386215092e-05,
      "loss": 0.046,
      "step": 3410
    },
    {
      "epoch": 6.096256684491979,
      "grad_norm": 0.5894461870193481,
      "learning_rate": 7.96850861556744e-05,
      "loss": 0.0536,
      "step": 3420
    },
    {
      "epoch": 6.114081996434938,
      "grad_norm": 0.9935722947120667,
      "learning_rate": 7.962566844919786e-05,
      "loss": 0.0594,
      "step": 3430
    },
    {
      "epoch": 6.1319073083778965,
      "grad_norm": 5.852229595184326,
      "learning_rate": 7.956625074272134e-05,
      "loss": 0.0539,
      "step": 3440
    },
    {
      "epoch": 6.149732620320855,
      "grad_norm": 1.447226881980896,
      "learning_rate": 7.950683303624481e-05,
      "loss": 0.0546,
      "step": 3450
    },
    {
      "epoch": 6.167557932263815,
      "grad_norm": 1.0073084831237793,
      "learning_rate": 7.944741532976827e-05,
      "loss": 0.0492,
      "step": 3460
    },
    {
      "epoch": 6.185383244206774,
      "grad_norm": 2.220529317855835,
      "learning_rate": 7.938799762329175e-05,
      "loss": 0.0543,
      "step": 3470
    },
    {
      "epoch": 6.2032085561497325,
      "grad_norm": 1.2495144605636597,
      "learning_rate": 7.932857991681522e-05,
      "loss": 0.0477,
      "step": 3480
    },
    {
      "epoch": 6.221033868092691,
      "grad_norm": 0.8224812746047974,
      "learning_rate": 7.926916221033868e-05,
      "loss": 0.0485,
      "step": 3490
    },
    {
      "epoch": 6.238859180035651,
      "grad_norm": 0.888089120388031,
      "learning_rate": 7.920974450386216e-05,
      "loss": 0.0508,
      "step": 3500
    },
    {
      "epoch": 6.25668449197861,
      "grad_norm": 1.1647589206695557,
      "learning_rate": 7.915032679738562e-05,
      "loss": 0.0493,
      "step": 3510
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 0.8622950911521912,
      "learning_rate": 7.90909090909091e-05,
      "loss": 0.0442,
      "step": 3520
    },
    {
      "epoch": 6.292335115864527,
      "grad_norm": 0.815393328666687,
      "learning_rate": 7.903149138443257e-05,
      "loss": 0.0447,
      "step": 3530
    },
    {
      "epoch": 6.310160427807487,
      "grad_norm": 3.173572540283203,
      "learning_rate": 7.897207367795603e-05,
      "loss": 0.0503,
      "step": 3540
    },
    {
      "epoch": 6.327985739750446,
      "grad_norm": 0.9195547699928284,
      "learning_rate": 7.89126559714795e-05,
      "loss": 0.0479,
      "step": 3550
    },
    {
      "epoch": 6.3458110516934045,
      "grad_norm": 0.7735000848770142,
      "learning_rate": 7.885323826500297e-05,
      "loss": 0.0454,
      "step": 3560
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 0.5120176672935486,
      "learning_rate": 7.879382055852644e-05,
      "loss": 0.0429,
      "step": 3570
    },
    {
      "epoch": 6.381461675579323,
      "grad_norm": 0.5262742638587952,
      "learning_rate": 7.873440285204992e-05,
      "loss": 0.0516,
      "step": 3580
    },
    {
      "epoch": 6.399286987522282,
      "grad_norm": 1.4371391534805298,
      "learning_rate": 7.86749851455734e-05,
      "loss": 0.0482,
      "step": 3590
    },
    {
      "epoch": 6.4171122994652405,
      "grad_norm": 0.8589189648628235,
      "learning_rate": 7.861556743909685e-05,
      "loss": 0.0473,
      "step": 3600
    },
    {
      "epoch": 6.434937611408199,
      "grad_norm": 0.7181195020675659,
      "learning_rate": 7.855614973262032e-05,
      "loss": 0.0466,
      "step": 3610
    },
    {
      "epoch": 6.452762923351159,
      "grad_norm": 0.7607886791229248,
      "learning_rate": 7.849673202614379e-05,
      "loss": 0.0515,
      "step": 3620
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 1.2802996635437012,
      "learning_rate": 7.843731431966727e-05,
      "loss": 0.0452,
      "step": 3630
    },
    {
      "epoch": 6.4884135472370765,
      "grad_norm": 1.8918176889419556,
      "learning_rate": 7.837789661319074e-05,
      "loss": 0.0507,
      "step": 3640
    },
    {
      "epoch": 6.506238859180035,
      "grad_norm": 0.8850845694541931,
      "learning_rate": 7.831847890671422e-05,
      "loss": 0.0454,
      "step": 3650
    },
    {
      "epoch": 6.524064171122995,
      "grad_norm": 0.7841576337814331,
      "learning_rate": 7.825906120023766e-05,
      "loss": 0.048,
      "step": 3660
    },
    {
      "epoch": 6.541889483065954,
      "grad_norm": 1.2054799795150757,
      "learning_rate": 7.819964349376114e-05,
      "loss": 0.0441,
      "step": 3670
    },
    {
      "epoch": 6.5597147950089125,
      "grad_norm": 0.9949442744255066,
      "learning_rate": 7.814022578728461e-05,
      "loss": 0.046,
      "step": 3680
    },
    {
      "epoch": 6.577540106951871,
      "grad_norm": 0.5590649247169495,
      "learning_rate": 7.808080808080809e-05,
      "loss": 0.0428,
      "step": 3690
    },
    {
      "epoch": 6.595365418894831,
      "grad_norm": 1.0724657773971558,
      "learning_rate": 7.802139037433156e-05,
      "loss": 0.0433,
      "step": 3700
    },
    {
      "epoch": 6.61319073083779,
      "grad_norm": 1.1790790557861328,
      "learning_rate": 7.796197266785503e-05,
      "loss": 0.0437,
      "step": 3710
    },
    {
      "epoch": 6.6310160427807485,
      "grad_norm": 1.2133890390396118,
      "learning_rate": 7.790255496137849e-05,
      "loss": 0.0484,
      "step": 3720
    },
    {
      "epoch": 6.648841354723707,
      "grad_norm": 0.5990787744522095,
      "learning_rate": 7.784313725490196e-05,
      "loss": 0.0433,
      "step": 3730
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.7374064326286316,
      "learning_rate": 7.778371954842544e-05,
      "loss": 0.0448,
      "step": 3740
    },
    {
      "epoch": 6.684491978609626,
      "grad_norm": 0.9099808931350708,
      "learning_rate": 7.772430184194891e-05,
      "loss": 0.0422,
      "step": 3750
    },
    {
      "epoch": 6.7023172905525845,
      "grad_norm": 0.939452052116394,
      "learning_rate": 7.766488413547237e-05,
      "loss": 0.0452,
      "step": 3760
    },
    {
      "epoch": 6.720142602495543,
      "grad_norm": 0.48237696290016174,
      "learning_rate": 7.760546642899585e-05,
      "loss": 0.0443,
      "step": 3770
    },
    {
      "epoch": 6.737967914438503,
      "grad_norm": 0.4776487350463867,
      "learning_rate": 7.754604872251931e-05,
      "loss": 0.042,
      "step": 3780
    },
    {
      "epoch": 6.755793226381462,
      "grad_norm": 1.0438333749771118,
      "learning_rate": 7.748663101604279e-05,
      "loss": 0.0438,
      "step": 3790
    },
    {
      "epoch": 6.7736185383244205,
      "grad_norm": 0.7110241055488586,
      "learning_rate": 7.742721330956626e-05,
      "loss": 0.0441,
      "step": 3800
    },
    {
      "epoch": 6.791443850267379,
      "grad_norm": 0.6911357641220093,
      "learning_rate": 7.736779560308972e-05,
      "loss": 0.043,
      "step": 3810
    },
    {
      "epoch": 6.809269162210339,
      "grad_norm": 1.4629875421524048,
      "learning_rate": 7.73083778966132e-05,
      "loss": 0.0464,
      "step": 3820
    },
    {
      "epoch": 6.827094474153298,
      "grad_norm": 1.572828769683838,
      "learning_rate": 7.724896019013666e-05,
      "loss": 0.0441,
      "step": 3830
    },
    {
      "epoch": 6.8449197860962565,
      "grad_norm": 0.9196571111679077,
      "learning_rate": 7.718954248366013e-05,
      "loss": 0.0422,
      "step": 3840
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.8873728513717651,
      "learning_rate": 7.71301247771836e-05,
      "loss": 0.0469,
      "step": 3850
    },
    {
      "epoch": 6.880570409982175,
      "grad_norm": 1.8509087562561035,
      "learning_rate": 7.707070707070707e-05,
      "loss": 0.0418,
      "step": 3860
    },
    {
      "epoch": 6.898395721925134,
      "grad_norm": 1.0537450313568115,
      "learning_rate": 7.701128936423055e-05,
      "loss": 0.0446,
      "step": 3870
    },
    {
      "epoch": 6.9162210338680925,
      "grad_norm": 1.4335471391677856,
      "learning_rate": 7.695187165775402e-05,
      "loss": 0.0448,
      "step": 3880
    },
    {
      "epoch": 6.934046345811051,
      "grad_norm": 0.8721545934677124,
      "learning_rate": 7.689245395127748e-05,
      "loss": 0.0431,
      "step": 3890
    },
    {
      "epoch": 6.951871657754011,
      "grad_norm": 0.5593133568763733,
      "learning_rate": 7.683303624480094e-05,
      "loss": 0.0428,
      "step": 3900
    },
    {
      "epoch": 6.96969696969697,
      "grad_norm": 1.1588711738586426,
      "learning_rate": 7.677361853832442e-05,
      "loss": 0.0439,
      "step": 3910
    },
    {
      "epoch": 6.9875222816399285,
      "grad_norm": 0.47965702414512634,
      "learning_rate": 7.67142008318479e-05,
      "loss": 0.0443,
      "step": 3920
    },
    {
      "epoch": 7.005347593582887,
      "grad_norm": 0.678777277469635,
      "learning_rate": 7.665478312537137e-05,
      "loss": 0.0454,
      "step": 3930
    },
    {
      "epoch": 7.023172905525847,
      "grad_norm": 1.4737602472305298,
      "learning_rate": 7.659536541889484e-05,
      "loss": 0.0432,
      "step": 3940
    },
    {
      "epoch": 7.040998217468806,
      "grad_norm": 1.0541340112686157,
      "learning_rate": 7.653594771241829e-05,
      "loss": 0.045,
      "step": 3950
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 1.321838617324829,
      "learning_rate": 7.647653000594177e-05,
      "loss": 0.0419,
      "step": 3960
    },
    {
      "epoch": 7.076648841354723,
      "grad_norm": 1.1308090686798096,
      "learning_rate": 7.641711229946524e-05,
      "loss": 0.0456,
      "step": 3970
    },
    {
      "epoch": 7.094474153297683,
      "grad_norm": 1.0371246337890625,
      "learning_rate": 7.635769459298872e-05,
      "loss": 0.0458,
      "step": 3980
    },
    {
      "epoch": 7.112299465240642,
      "grad_norm": 1.0981614589691162,
      "learning_rate": 7.629827688651219e-05,
      "loss": 0.039,
      "step": 3990
    },
    {
      "epoch": 7.1301247771836005,
      "grad_norm": 0.618800163269043,
      "learning_rate": 7.623885918003565e-05,
      "loss": 0.0404,
      "step": 4000
    },
    {
      "epoch": 7.14795008912656,
      "grad_norm": 0.782446026802063,
      "learning_rate": 7.617944147355912e-05,
      "loss": 0.0419,
      "step": 4010
    },
    {
      "epoch": 7.165775401069519,
      "grad_norm": 0.9127863645553589,
      "learning_rate": 7.612002376708259e-05,
      "loss": 0.0381,
      "step": 4020
    },
    {
      "epoch": 7.183600713012478,
      "grad_norm": 0.5317316055297852,
      "learning_rate": 7.606060606060607e-05,
      "loss": 0.0412,
      "step": 4030
    },
    {
      "epoch": 7.2014260249554365,
      "grad_norm": 1.1235264539718628,
      "learning_rate": 7.600118835412954e-05,
      "loss": 0.0454,
      "step": 4040
    },
    {
      "epoch": 7.219251336898395,
      "grad_norm": 1.3334192037582397,
      "learning_rate": 7.5941770647653e-05,
      "loss": 0.0429,
      "step": 4050
    },
    {
      "epoch": 7.237076648841355,
      "grad_norm": 2.584158182144165,
      "learning_rate": 7.588235294117648e-05,
      "loss": 0.0441,
      "step": 4060
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.90842604637146,
      "learning_rate": 7.582293523469994e-05,
      "loss": 0.0426,
      "step": 4070
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.7179129123687744,
      "learning_rate": 7.576351752822341e-05,
      "loss": 0.0463,
      "step": 4080
    },
    {
      "epoch": 7.290552584670232,
      "grad_norm": 1.2002137899398804,
      "learning_rate": 7.570409982174689e-05,
      "loss": 0.0448,
      "step": 4090
    },
    {
      "epoch": 7.308377896613191,
      "grad_norm": 0.6291958093643188,
      "learning_rate": 7.564468211527035e-05,
      "loss": 0.0453,
      "step": 4100
    },
    {
      "epoch": 7.32620320855615,
      "grad_norm": 0.808883786201477,
      "learning_rate": 7.558526440879383e-05,
      "loss": 0.0431,
      "step": 4110
    },
    {
      "epoch": 7.3440285204991085,
      "grad_norm": 1.6663707494735718,
      "learning_rate": 7.552584670231729e-05,
      "loss": 0.0402,
      "step": 4120
    },
    {
      "epoch": 7.361853832442068,
      "grad_norm": 1.7471553087234497,
      "learning_rate": 7.546642899584076e-05,
      "loss": 0.0451,
      "step": 4130
    },
    {
      "epoch": 7.379679144385027,
      "grad_norm": 1.2844817638397217,
      "learning_rate": 7.540701128936424e-05,
      "loss": 0.0434,
      "step": 4140
    },
    {
      "epoch": 7.397504456327986,
      "grad_norm": 0.6806156635284424,
      "learning_rate": 7.53475935828877e-05,
      "loss": 0.0405,
      "step": 4150
    },
    {
      "epoch": 7.4153297682709445,
      "grad_norm": 1.0027319192886353,
      "learning_rate": 7.528817587641117e-05,
      "loss": 0.0392,
      "step": 4160
    },
    {
      "epoch": 7.433155080213904,
      "grad_norm": 1.1021031141281128,
      "learning_rate": 7.522875816993465e-05,
      "loss": 0.0416,
      "step": 4170
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 5.264302730560303,
      "learning_rate": 7.516934046345811e-05,
      "loss": 0.0463,
      "step": 4180
    },
    {
      "epoch": 7.468805704099822,
      "grad_norm": 0.7822070717811584,
      "learning_rate": 7.510992275698159e-05,
      "loss": 0.0422,
      "step": 4190
    },
    {
      "epoch": 7.4866310160427805,
      "grad_norm": 1.1338914632797241,
      "learning_rate": 7.505050505050505e-05,
      "loss": 0.041,
      "step": 4200
    },
    {
      "epoch": 7.50445632798574,
      "grad_norm": 1.0610392093658447,
      "learning_rate": 7.499108734402852e-05,
      "loss": 0.0392,
      "step": 4210
    },
    {
      "epoch": 7.522281639928699,
      "grad_norm": 0.8867064714431763,
      "learning_rate": 7.4931669637552e-05,
      "loss": 0.0414,
      "step": 4220
    },
    {
      "epoch": 7.540106951871658,
      "grad_norm": 0.7819309830665588,
      "learning_rate": 7.487225193107547e-05,
      "loss": 0.0439,
      "step": 4230
    },
    {
      "epoch": 7.5579322638146165,
      "grad_norm": 0.8326765894889832,
      "learning_rate": 7.481283422459893e-05,
      "loss": 0.0478,
      "step": 4240
    },
    {
      "epoch": 7.575757575757576,
      "grad_norm": 0.903736412525177,
      "learning_rate": 7.47534165181224e-05,
      "loss": 0.0402,
      "step": 4250
    },
    {
      "epoch": 7.593582887700535,
      "grad_norm": 1.0707035064697266,
      "learning_rate": 7.469399881164587e-05,
      "loss": 0.0451,
      "step": 4260
    },
    {
      "epoch": 7.611408199643494,
      "grad_norm": 0.9390480518341064,
      "learning_rate": 7.463458110516935e-05,
      "loss": 0.0415,
      "step": 4270
    },
    {
      "epoch": 7.6292335115864525,
      "grad_norm": 0.7003017663955688,
      "learning_rate": 7.457516339869282e-05,
      "loss": 0.0419,
      "step": 4280
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 1.456987738609314,
      "learning_rate": 7.451574569221628e-05,
      "loss": 0.0458,
      "step": 4290
    },
    {
      "epoch": 7.664884135472371,
      "grad_norm": 2.673182725906372,
      "learning_rate": 7.445632798573974e-05,
      "loss": 0.0482,
      "step": 4300
    },
    {
      "epoch": 7.68270944741533,
      "grad_norm": 1.2903239727020264,
      "learning_rate": 7.439691027926322e-05,
      "loss": 0.041,
      "step": 4310
    },
    {
      "epoch": 7.7005347593582885,
      "grad_norm": 2.3147408962249756,
      "learning_rate": 7.43374925727867e-05,
      "loss": 0.0383,
      "step": 4320
    },
    {
      "epoch": 7.718360071301248,
      "grad_norm": 1.5049490928649902,
      "learning_rate": 7.427807486631017e-05,
      "loss": 0.042,
      "step": 4330
    },
    {
      "epoch": 7.736185383244207,
      "grad_norm": 1.2443453073501587,
      "learning_rate": 7.421865715983364e-05,
      "loss": 0.04,
      "step": 4340
    },
    {
      "epoch": 7.754010695187166,
      "grad_norm": 0.847618579864502,
      "learning_rate": 7.41592394533571e-05,
      "loss": 0.0458,
      "step": 4350
    },
    {
      "epoch": 7.7718360071301245,
      "grad_norm": 1.6541181802749634,
      "learning_rate": 7.409982174688057e-05,
      "loss": 0.0383,
      "step": 4360
    },
    {
      "epoch": 7.789661319073084,
      "grad_norm": 0.9835382103919983,
      "learning_rate": 7.404040404040404e-05,
      "loss": 0.0419,
      "step": 4370
    },
    {
      "epoch": 7.807486631016043,
      "grad_norm": 4.402220249176025,
      "learning_rate": 7.398098633392752e-05,
      "loss": 0.0415,
      "step": 4380
    },
    {
      "epoch": 7.825311942959002,
      "grad_norm": 0.9534523487091064,
      "learning_rate": 7.392156862745099e-05,
      "loss": 0.0375,
      "step": 4390
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 1.4756953716278076,
      "learning_rate": 7.386215092097445e-05,
      "loss": 0.0432,
      "step": 4400
    },
    {
      "epoch": 7.86096256684492,
      "grad_norm": 1.8595316410064697,
      "learning_rate": 7.380273321449792e-05,
      "loss": 0.0407,
      "step": 4410
    },
    {
      "epoch": 7.878787878787879,
      "grad_norm": 3.685641288757324,
      "learning_rate": 7.374331550802139e-05,
      "loss": 0.0417,
      "step": 4420
    },
    {
      "epoch": 7.896613190730838,
      "grad_norm": 1.3666054010391235,
      "learning_rate": 7.368389780154487e-05,
      "loss": 0.0425,
      "step": 4430
    },
    {
      "epoch": 7.9144385026737964,
      "grad_norm": 2.4604949951171875,
      "learning_rate": 7.362448009506834e-05,
      "loss": 0.0415,
      "step": 4440
    },
    {
      "epoch": 7.932263814616756,
      "grad_norm": 1.8605409860610962,
      "learning_rate": 7.35650623885918e-05,
      "loss": 0.0386,
      "step": 4450
    },
    {
      "epoch": 7.950089126559715,
      "grad_norm": 0.6580275893211365,
      "learning_rate": 7.350564468211528e-05,
      "loss": 0.0395,
      "step": 4460
    },
    {
      "epoch": 7.967914438502674,
      "grad_norm": 0.83819580078125,
      "learning_rate": 7.344622697563874e-05,
      "loss": 0.0388,
      "step": 4470
    },
    {
      "epoch": 7.9857397504456324,
      "grad_norm": 0.4390745162963867,
      "learning_rate": 7.338680926916221e-05,
      "loss": 0.0408,
      "step": 4480
    },
    {
      "epoch": 8.003565062388592,
      "grad_norm": 1.6005388498306274,
      "learning_rate": 7.332739156268569e-05,
      "loss": 0.0403,
      "step": 4490
    },
    {
      "epoch": 8.02139037433155,
      "grad_norm": 0.6632890105247498,
      "learning_rate": 7.326797385620915e-05,
      "loss": 0.0411,
      "step": 4500
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 0.6070115566253662,
      "learning_rate": 7.320855614973262e-05,
      "loss": 0.0381,
      "step": 4510
    },
    {
      "epoch": 8.057040998217468,
      "grad_norm": 2.0481836795806885,
      "learning_rate": 7.31491384432561e-05,
      "loss": 0.0445,
      "step": 4520
    },
    {
      "epoch": 8.074866310160427,
      "grad_norm": 0.8742078542709351,
      "learning_rate": 7.308972073677956e-05,
      "loss": 0.0415,
      "step": 4530
    },
    {
      "epoch": 8.092691622103386,
      "grad_norm": 1.5608336925506592,
      "learning_rate": 7.303030303030304e-05,
      "loss": 0.0411,
      "step": 4540
    },
    {
      "epoch": 8.110516934046347,
      "grad_norm": 0.863524854183197,
      "learning_rate": 7.29708853238265e-05,
      "loss": 0.0403,
      "step": 4550
    },
    {
      "epoch": 8.128342245989305,
      "grad_norm": 1.4550902843475342,
      "learning_rate": 7.291146761734997e-05,
      "loss": 0.0384,
      "step": 4560
    },
    {
      "epoch": 8.146167557932264,
      "grad_norm": 0.9053926467895508,
      "learning_rate": 7.285204991087345e-05,
      "loss": 0.0396,
      "step": 4570
    },
    {
      "epoch": 8.163992869875223,
      "grad_norm": 0.7116764783859253,
      "learning_rate": 7.279263220439691e-05,
      "loss": 0.0386,
      "step": 4580
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 0.9869557619094849,
      "learning_rate": 7.273321449792038e-05,
      "loss": 0.0374,
      "step": 4590
    },
    {
      "epoch": 8.19964349376114,
      "grad_norm": 1.129679799079895,
      "learning_rate": 7.267379679144385e-05,
      "loss": 0.0383,
      "step": 4600
    },
    {
      "epoch": 8.2174688057041,
      "grad_norm": 1.7605695724487305,
      "learning_rate": 7.261437908496732e-05,
      "loss": 0.0379,
      "step": 4610
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.7092321515083313,
      "learning_rate": 7.25549613784908e-05,
      "loss": 0.037,
      "step": 4620
    },
    {
      "epoch": 8.253119429590019,
      "grad_norm": 0.8720685839653015,
      "learning_rate": 7.249554367201427e-05,
      "loss": 0.039,
      "step": 4630
    },
    {
      "epoch": 8.270944741532977,
      "grad_norm": 0.6888159513473511,
      "learning_rate": 7.243612596553773e-05,
      "loss": 0.0373,
      "step": 4640
    },
    {
      "epoch": 8.288770053475936,
      "grad_norm": 0.7530292868614197,
      "learning_rate": 7.23767082590612e-05,
      "loss": 0.0428,
      "step": 4650
    },
    {
      "epoch": 8.306595365418895,
      "grad_norm": 1.4127739667892456,
      "learning_rate": 7.231729055258467e-05,
      "loss": 0.0382,
      "step": 4660
    },
    {
      "epoch": 8.324420677361854,
      "grad_norm": 1.4628782272338867,
      "learning_rate": 7.225787284610814e-05,
      "loss": 0.0373,
      "step": 4670
    },
    {
      "epoch": 8.342245989304812,
      "grad_norm": 0.6539931893348694,
      "learning_rate": 7.219845513963162e-05,
      "loss": 0.0342,
      "step": 4680
    },
    {
      "epoch": 8.360071301247771,
      "grad_norm": 0.6356730461120605,
      "learning_rate": 7.213903743315508e-05,
      "loss": 0.0385,
      "step": 4690
    },
    {
      "epoch": 8.37789661319073,
      "grad_norm": 0.44121795892715454,
      "learning_rate": 7.207961972667854e-05,
      "loss": 0.0397,
      "step": 4700
    },
    {
      "epoch": 8.39572192513369,
      "grad_norm": 1.025550365447998,
      "learning_rate": 7.202020202020202e-05,
      "loss": 0.0366,
      "step": 4710
    },
    {
      "epoch": 8.41354723707665,
      "grad_norm": 0.9126920700073242,
      "learning_rate": 7.196078431372549e-05,
      "loss": 0.0381,
      "step": 4720
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.9641658067703247,
      "learning_rate": 7.190136660724897e-05,
      "loss": 0.04,
      "step": 4730
    },
    {
      "epoch": 8.449197860962567,
      "grad_norm": 0.9067308306694031,
      "learning_rate": 7.184194890077244e-05,
      "loss": 0.0384,
      "step": 4740
    },
    {
      "epoch": 8.467023172905526,
      "grad_norm": 0.7889310717582703,
      "learning_rate": 7.17825311942959e-05,
      "loss": 0.0375,
      "step": 4750
    },
    {
      "epoch": 8.484848484848484,
      "grad_norm": 1.463216781616211,
      "learning_rate": 7.172311348781937e-05,
      "loss": 0.0389,
      "step": 4760
    },
    {
      "epoch": 8.502673796791443,
      "grad_norm": 0.46413454413414,
      "learning_rate": 7.166369578134284e-05,
      "loss": 0.0393,
      "step": 4770
    },
    {
      "epoch": 8.520499108734402,
      "grad_norm": 0.7113362550735474,
      "learning_rate": 7.160427807486632e-05,
      "loss": 0.0407,
      "step": 4780
    },
    {
      "epoch": 8.538324420677363,
      "grad_norm": 1.4317275285720825,
      "learning_rate": 7.154486036838979e-05,
      "loss": 0.0391,
      "step": 4790
    },
    {
      "epoch": 8.556149732620321,
      "grad_norm": 0.6940510869026184,
      "learning_rate": 7.148544266191325e-05,
      "loss": 0.0358,
      "step": 4800
    },
    {
      "epoch": 8.57397504456328,
      "grad_norm": 0.7553936243057251,
      "learning_rate": 7.142602495543673e-05,
      "loss": 0.0375,
      "step": 4810
    },
    {
      "epoch": 8.591800356506239,
      "grad_norm": 1.8008041381835938,
      "learning_rate": 7.136660724896019e-05,
      "loss": 0.0367,
      "step": 4820
    },
    {
      "epoch": 8.609625668449198,
      "grad_norm": 0.5158032774925232,
      "learning_rate": 7.130718954248366e-05,
      "loss": 0.0371,
      "step": 4830
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 1.2622345685958862,
      "learning_rate": 7.124777183600714e-05,
      "loss": 0.0443,
      "step": 4840
    },
    {
      "epoch": 8.645276292335115,
      "grad_norm": 0.8704358339309692,
      "learning_rate": 7.11883541295306e-05,
      "loss": 0.0389,
      "step": 4850
    },
    {
      "epoch": 8.663101604278076,
      "grad_norm": 0.9998002052307129,
      "learning_rate": 7.112893642305408e-05,
      "loss": 0.0392,
      "step": 4860
    },
    {
      "epoch": 8.680926916221035,
      "grad_norm": 0.6707625985145569,
      "learning_rate": 7.106951871657754e-05,
      "loss": 0.039,
      "step": 4870
    },
    {
      "epoch": 8.698752228163993,
      "grad_norm": 1.832031488418579,
      "learning_rate": 7.101010101010101e-05,
      "loss": 0.04,
      "step": 4880
    },
    {
      "epoch": 8.716577540106952,
      "grad_norm": 2.3484127521514893,
      "learning_rate": 7.095068330362449e-05,
      "loss": 0.0383,
      "step": 4890
    },
    {
      "epoch": 8.73440285204991,
      "grad_norm": 1.071409821510315,
      "learning_rate": 7.089126559714795e-05,
      "loss": 0.0384,
      "step": 4900
    },
    {
      "epoch": 8.75222816399287,
      "grad_norm": 0.7871209383010864,
      "learning_rate": 7.083184789067142e-05,
      "loss": 0.0363,
      "step": 4910
    },
    {
      "epoch": 8.770053475935828,
      "grad_norm": 0.8252333998680115,
      "learning_rate": 7.07724301841949e-05,
      "loss": 0.0383,
      "step": 4920
    },
    {
      "epoch": 8.787878787878787,
      "grad_norm": 0.5956084132194519,
      "learning_rate": 7.071301247771836e-05,
      "loss": 0.0399,
      "step": 4930
    },
    {
      "epoch": 8.805704099821746,
      "grad_norm": 0.8998730778694153,
      "learning_rate": 7.065359477124184e-05,
      "loss": 0.0367,
      "step": 4940
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 1.6155022382736206,
      "learning_rate": 7.05941770647653e-05,
      "loss": 0.039,
      "step": 4950
    },
    {
      "epoch": 8.841354723707665,
      "grad_norm": 0.863136887550354,
      "learning_rate": 7.053475935828877e-05,
      "loss": 0.0366,
      "step": 4960
    },
    {
      "epoch": 8.859180035650624,
      "grad_norm": 1.2317328453063965,
      "learning_rate": 7.047534165181225e-05,
      "loss": 0.0411,
      "step": 4970
    },
    {
      "epoch": 8.877005347593583,
      "grad_norm": 0.6693596839904785,
      "learning_rate": 7.041592394533571e-05,
      "loss": 0.0371,
      "step": 4980
    },
    {
      "epoch": 8.894830659536542,
      "grad_norm": 0.8227933049201965,
      "learning_rate": 7.035650623885918e-05,
      "loss": 0.0371,
      "step": 4990
    },
    {
      "epoch": 8.9126559714795,
      "grad_norm": 0.8960633873939514,
      "learning_rate": 7.029708853238265e-05,
      "loss": 0.0388,
      "step": 5000
    },
    {
      "epoch": 8.93048128342246,
      "grad_norm": 1.2189180850982666,
      "learning_rate": 7.023767082590612e-05,
      "loss": 0.0383,
      "step": 5010
    },
    {
      "epoch": 8.94830659536542,
      "grad_norm": 1.0312025547027588,
      "learning_rate": 7.01782531194296e-05,
      "loss": 0.0351,
      "step": 5020
    },
    {
      "epoch": 8.966131907308379,
      "grad_norm": 1.6700544357299805,
      "learning_rate": 7.011883541295307e-05,
      "loss": 0.0397,
      "step": 5030
    },
    {
      "epoch": 8.983957219251337,
      "grad_norm": 0.9725128412246704,
      "learning_rate": 7.005941770647653e-05,
      "loss": 0.0422,
      "step": 5040
    },
    {
      "epoch": 9.001782531194296,
      "grad_norm": 1.2440693378448486,
      "learning_rate": 7e-05,
      "loss": 0.04,
      "step": 5050
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 0.763187825679779,
      "learning_rate": 6.994058229352347e-05,
      "loss": 0.0335,
      "step": 5060
    },
    {
      "epoch": 9.037433155080214,
      "grad_norm": 0.7980675101280212,
      "learning_rate": 6.988116458704694e-05,
      "loss": 0.0363,
      "step": 5070
    },
    {
      "epoch": 9.055258467023172,
      "grad_norm": 0.9456865191459656,
      "learning_rate": 6.982174688057042e-05,
      "loss": 0.038,
      "step": 5080
    },
    {
      "epoch": 9.073083778966131,
      "grad_norm": 0.9396268725395203,
      "learning_rate": 6.97623291740939e-05,
      "loss": 0.0407,
      "step": 5090
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.8776322603225708,
      "learning_rate": 6.970291146761736e-05,
      "loss": 0.0391,
      "step": 5100
    },
    {
      "epoch": 9.10873440285205,
      "grad_norm": 1.2492502927780151,
      "learning_rate": 6.964349376114082e-05,
      "loss": 0.0359,
      "step": 5110
    },
    {
      "epoch": 9.12655971479501,
      "grad_norm": 1.434173345565796,
      "learning_rate": 6.958407605466429e-05,
      "loss": 0.0423,
      "step": 5120
    },
    {
      "epoch": 9.144385026737968,
      "grad_norm": 0.9595146775245667,
      "learning_rate": 6.952465834818777e-05,
      "loss": 0.0398,
      "step": 5130
    },
    {
      "epoch": 9.162210338680927,
      "grad_norm": 1.187713861465454,
      "learning_rate": 6.946524064171124e-05,
      "loss": 0.042,
      "step": 5140
    },
    {
      "epoch": 9.180035650623886,
      "grad_norm": 0.7042272686958313,
      "learning_rate": 6.94058229352347e-05,
      "loss": 0.0388,
      "step": 5150
    },
    {
      "epoch": 9.197860962566844,
      "grad_norm": 1.2225481271743774,
      "learning_rate": 6.934640522875817e-05,
      "loss": 0.0367,
      "step": 5160
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 0.5020163655281067,
      "learning_rate": 6.928698752228164e-05,
      "loss": 0.0368,
      "step": 5170
    },
    {
      "epoch": 9.233511586452764,
      "grad_norm": 0.47611069679260254,
      "learning_rate": 6.922756981580512e-05,
      "loss": 0.0371,
      "step": 5180
    },
    {
      "epoch": 9.251336898395722,
      "grad_norm": 1.8809056282043457,
      "learning_rate": 6.916815210932859e-05,
      "loss": 0.0395,
      "step": 5190
    },
    {
      "epoch": 9.269162210338681,
      "grad_norm": 0.6609638929367065,
      "learning_rate": 6.910873440285205e-05,
      "loss": 0.0361,
      "step": 5200
    },
    {
      "epoch": 9.28698752228164,
      "grad_norm": 1.3217188119888306,
      "learning_rate": 6.904931669637553e-05,
      "loss": 0.0391,
      "step": 5210
    },
    {
      "epoch": 9.304812834224599,
      "grad_norm": 0.7136265635490417,
      "learning_rate": 6.898989898989899e-05,
      "loss": 0.0363,
      "step": 5220
    },
    {
      "epoch": 9.322638146167558,
      "grad_norm": 1.1203137636184692,
      "learning_rate": 6.893048128342246e-05,
      "loss": 0.037,
      "step": 5230
    },
    {
      "epoch": 9.340463458110516,
      "grad_norm": 1.878625750541687,
      "learning_rate": 6.887106357694594e-05,
      "loss": 0.039,
      "step": 5240
    },
    {
      "epoch": 9.358288770053475,
      "grad_norm": 0.585499107837677,
      "learning_rate": 6.88116458704694e-05,
      "loss": 0.0374,
      "step": 5250
    },
    {
      "epoch": 9.376114081996436,
      "grad_norm": 1.261323094367981,
      "learning_rate": 6.875222816399288e-05,
      "loss": 0.0415,
      "step": 5260
    },
    {
      "epoch": 9.393939393939394,
      "grad_norm": 1.4962002038955688,
      "learning_rate": 6.869281045751634e-05,
      "loss": 0.0383,
      "step": 5270
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 0.8543033599853516,
      "learning_rate": 6.863339275103981e-05,
      "loss": 0.0387,
      "step": 5280
    },
    {
      "epoch": 9.429590017825312,
      "grad_norm": 0.9954984784126282,
      "learning_rate": 6.857397504456329e-05,
      "loss": 0.0353,
      "step": 5290
    },
    {
      "epoch": 9.44741532976827,
      "grad_norm": 1.2225399017333984,
      "learning_rate": 6.851455733808675e-05,
      "loss": 0.0379,
      "step": 5300
    },
    {
      "epoch": 9.46524064171123,
      "grad_norm": 0.7074599266052246,
      "learning_rate": 6.845513963161022e-05,
      "loss": 0.0367,
      "step": 5310
    },
    {
      "epoch": 9.483065953654188,
      "grad_norm": 0.7299046516418457,
      "learning_rate": 6.83957219251337e-05,
      "loss": 0.0358,
      "step": 5320
    },
    {
      "epoch": 9.500891265597147,
      "grad_norm": 1.1497575044631958,
      "learning_rate": 6.833630421865716e-05,
      "loss": 0.0366,
      "step": 5330
    },
    {
      "epoch": 9.518716577540108,
      "grad_norm": 1.1313120126724243,
      "learning_rate": 6.827688651218064e-05,
      "loss": 0.0412,
      "step": 5340
    },
    {
      "epoch": 9.536541889483066,
      "grad_norm": 1.005018711090088,
      "learning_rate": 6.82174688057041e-05,
      "loss": 0.0372,
      "step": 5350
    },
    {
      "epoch": 9.554367201426025,
      "grad_norm": 1.1109727621078491,
      "learning_rate": 6.815805109922757e-05,
      "loss": 0.0389,
      "step": 5360
    },
    {
      "epoch": 9.572192513368984,
      "grad_norm": 1.8568955659866333,
      "learning_rate": 6.809863339275105e-05,
      "loss": 0.0358,
      "step": 5370
    },
    {
      "epoch": 9.590017825311943,
      "grad_norm": 0.629688560962677,
      "learning_rate": 6.803921568627452e-05,
      "loss": 0.0324,
      "step": 5380
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 2.231597900390625,
      "learning_rate": 6.797979797979798e-05,
      "loss": 0.0408,
      "step": 5390
    },
    {
      "epoch": 9.62566844919786,
      "grad_norm": 0.5511758327484131,
      "learning_rate": 6.792038027332144e-05,
      "loss": 0.0331,
      "step": 5400
    },
    {
      "epoch": 9.643493761140821,
      "grad_norm": 1.0508943796157837,
      "learning_rate": 6.786096256684492e-05,
      "loss": 0.0404,
      "step": 5410
    },
    {
      "epoch": 9.66131907308378,
      "grad_norm": 0.4508923888206482,
      "learning_rate": 6.78015448603684e-05,
      "loss": 0.0343,
      "step": 5420
    },
    {
      "epoch": 9.679144385026738,
      "grad_norm": 0.9951087236404419,
      "learning_rate": 6.774212715389187e-05,
      "loss": 0.0357,
      "step": 5430
    },
    {
      "epoch": 9.696969696969697,
      "grad_norm": 0.5920832753181458,
      "learning_rate": 6.768270944741533e-05,
      "loss": 0.0343,
      "step": 5440
    },
    {
      "epoch": 9.714795008912656,
      "grad_norm": 1.5817114114761353,
      "learning_rate": 6.762329174093879e-05,
      "loss": 0.0358,
      "step": 5450
    },
    {
      "epoch": 9.732620320855615,
      "grad_norm": 0.5972646474838257,
      "learning_rate": 6.756387403446227e-05,
      "loss": 0.0376,
      "step": 5460
    },
    {
      "epoch": 9.750445632798574,
      "grad_norm": 0.8343141078948975,
      "learning_rate": 6.750445632798574e-05,
      "loss": 0.035,
      "step": 5470
    },
    {
      "epoch": 9.768270944741532,
      "grad_norm": 0.6834016442298889,
      "learning_rate": 6.744503862150922e-05,
      "loss": 0.0366,
      "step": 5480
    },
    {
      "epoch": 9.786096256684491,
      "grad_norm": 1.1595606803894043,
      "learning_rate": 6.73856209150327e-05,
      "loss": 0.0347,
      "step": 5490
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 1.126739263534546,
      "learning_rate": 6.732620320855615e-05,
      "loss": 0.0384,
      "step": 5500
    },
    {
      "epoch": 9.82174688057041,
      "grad_norm": 0.9209764003753662,
      "learning_rate": 6.726678550207962e-05,
      "loss": 0.0339,
      "step": 5510
    },
    {
      "epoch": 9.83957219251337,
      "grad_norm": 1.137749433517456,
      "learning_rate": 6.720736779560309e-05,
      "loss": 0.0356,
      "step": 5520
    },
    {
      "epoch": 9.857397504456328,
      "grad_norm": 0.48597514629364014,
      "learning_rate": 6.714795008912657e-05,
      "loss": 0.0319,
      "step": 5530
    },
    {
      "epoch": 9.875222816399287,
      "grad_norm": 2.3133785724639893,
      "learning_rate": 6.708853238265004e-05,
      "loss": 0.036,
      "step": 5540
    },
    {
      "epoch": 9.893048128342246,
      "grad_norm": 1.764565110206604,
      "learning_rate": 6.70291146761735e-05,
      "loss": 0.0355,
      "step": 5550
    },
    {
      "epoch": 9.910873440285204,
      "grad_norm": 1.1574259996414185,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.0363,
      "step": 5560
    },
    {
      "epoch": 9.928698752228165,
      "grad_norm": 0.9462488293647766,
      "learning_rate": 6.691027926322044e-05,
      "loss": 0.0354,
      "step": 5570
    },
    {
      "epoch": 9.946524064171124,
      "grad_norm": 1.0727638006210327,
      "learning_rate": 6.685086155674391e-05,
      "loss": 0.0354,
      "step": 5580
    },
    {
      "epoch": 9.964349376114082,
      "grad_norm": 0.681814968585968,
      "learning_rate": 6.679144385026739e-05,
      "loss": 0.0355,
      "step": 5590
    },
    {
      "epoch": 9.982174688057041,
      "grad_norm": 0.6267300248146057,
      "learning_rate": 6.673202614379085e-05,
      "loss": 0.0386,
      "step": 5600
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.1415514945983887,
      "learning_rate": 6.667260843731433e-05,
      "loss": 0.0358,
      "step": 5610
    },
    {
      "epoch": 10.017825311942959,
      "grad_norm": 0.3410188555717468,
      "learning_rate": 6.661319073083779e-05,
      "loss": 0.0356,
      "step": 5620
    },
    {
      "epoch": 10.035650623885918,
      "grad_norm": 1.345199704170227,
      "learning_rate": 6.655377302436126e-05,
      "loss": 0.0362,
      "step": 5630
    },
    {
      "epoch": 10.053475935828876,
      "grad_norm": 0.9269921779632568,
      "learning_rate": 6.649435531788474e-05,
      "loss": 0.0368,
      "step": 5640
    },
    {
      "epoch": 10.071301247771837,
      "grad_norm": 0.5878034234046936,
      "learning_rate": 6.64349376114082e-05,
      "loss": 0.0361,
      "step": 5650
    },
    {
      "epoch": 10.089126559714796,
      "grad_norm": 0.9140339493751526,
      "learning_rate": 6.637551990493167e-05,
      "loss": 0.0365,
      "step": 5660
    },
    {
      "epoch": 10.106951871657754,
      "grad_norm": 0.7072272300720215,
      "learning_rate": 6.631610219845515e-05,
      "loss": 0.0353,
      "step": 5670
    },
    {
      "epoch": 10.124777183600713,
      "grad_norm": 1.0074738264083862,
      "learning_rate": 6.625668449197861e-05,
      "loss": 0.0339,
      "step": 5680
    },
    {
      "epoch": 10.142602495543672,
      "grad_norm": 0.8957120180130005,
      "learning_rate": 6.619726678550209e-05,
      "loss": 0.0333,
      "step": 5690
    },
    {
      "epoch": 10.16042780748663,
      "grad_norm": 0.532263994216919,
      "learning_rate": 6.613784907902555e-05,
      "loss": 0.0341,
      "step": 5700
    },
    {
      "epoch": 10.17825311942959,
      "grad_norm": 1.372038722038269,
      "learning_rate": 6.607843137254902e-05,
      "loss": 0.0363,
      "step": 5710
    },
    {
      "epoch": 10.196078431372548,
      "grad_norm": 0.4648137092590332,
      "learning_rate": 6.60190136660725e-05,
      "loss": 0.0357,
      "step": 5720
    },
    {
      "epoch": 10.213903743315509,
      "grad_norm": 1.1417639255523682,
      "learning_rate": 6.595959595959596e-05,
      "loss": 0.0335,
      "step": 5730
    },
    {
      "epoch": 10.231729055258468,
      "grad_norm": 1.6230933666229248,
      "learning_rate": 6.590017825311943e-05,
      "loss": 0.035,
      "step": 5740
    },
    {
      "epoch": 10.249554367201426,
      "grad_norm": 1.4146397113800049,
      "learning_rate": 6.58407605466429e-05,
      "loss": 0.0373,
      "step": 5750
    },
    {
      "epoch": 10.267379679144385,
      "grad_norm": 0.5584716200828552,
      "learning_rate": 6.578134284016637e-05,
      "loss": 0.038,
      "step": 5760
    },
    {
      "epoch": 10.285204991087344,
      "grad_norm": 1.644636631011963,
      "learning_rate": 6.572192513368985e-05,
      "loss": 0.0383,
      "step": 5770
    },
    {
      "epoch": 10.303030303030303,
      "grad_norm": 0.7779479622840881,
      "learning_rate": 6.566250742721332e-05,
      "loss": 0.0362,
      "step": 5780
    },
    {
      "epoch": 10.320855614973262,
      "grad_norm": 1.1200810670852661,
      "learning_rate": 6.560308972073678e-05,
      "loss": 0.032,
      "step": 5790
    },
    {
      "epoch": 10.33868092691622,
      "grad_norm": 0.6537533402442932,
      "learning_rate": 6.554367201426024e-05,
      "loss": 0.0349,
      "step": 5800
    },
    {
      "epoch": 10.35650623885918,
      "grad_norm": 1.1951632499694824,
      "learning_rate": 6.548425430778372e-05,
      "loss": 0.0345,
      "step": 5810
    },
    {
      "epoch": 10.37433155080214,
      "grad_norm": 0.8032473921775818,
      "learning_rate": 6.54248366013072e-05,
      "loss": 0.037,
      "step": 5820
    },
    {
      "epoch": 10.392156862745098,
      "grad_norm": 1.0389961004257202,
      "learning_rate": 6.536541889483067e-05,
      "loss": 0.0363,
      "step": 5830
    },
    {
      "epoch": 10.409982174688057,
      "grad_norm": 1.0332237482070923,
      "learning_rate": 6.530600118835414e-05,
      "loss": 0.0357,
      "step": 5840
    },
    {
      "epoch": 10.427807486631016,
      "grad_norm": 0.628801703453064,
      "learning_rate": 6.524658348187759e-05,
      "loss": 0.033,
      "step": 5850
    },
    {
      "epoch": 10.445632798573975,
      "grad_norm": 1.4089500904083252,
      "learning_rate": 6.518716577540107e-05,
      "loss": 0.0326,
      "step": 5860
    },
    {
      "epoch": 10.463458110516934,
      "grad_norm": 0.5124130845069885,
      "learning_rate": 6.512774806892454e-05,
      "loss": 0.0349,
      "step": 5870
    },
    {
      "epoch": 10.481283422459892,
      "grad_norm": 0.6104451417922974,
      "learning_rate": 6.506833036244802e-05,
      "loss": 0.036,
      "step": 5880
    },
    {
      "epoch": 10.499108734402853,
      "grad_norm": 0.8706966638565063,
      "learning_rate": 6.500891265597149e-05,
      "loss": 0.0346,
      "step": 5890
    },
    {
      "epoch": 10.516934046345812,
      "grad_norm": 1.0100005865097046,
      "learning_rate": 6.494949494949495e-05,
      "loss": 0.0349,
      "step": 5900
    },
    {
      "epoch": 10.53475935828877,
      "grad_norm": 0.9508150219917297,
      "learning_rate": 6.489007724301842e-05,
      "loss": 0.032,
      "step": 5910
    },
    {
      "epoch": 10.55258467023173,
      "grad_norm": 0.8442018628120422,
      "learning_rate": 6.483065953654189e-05,
      "loss": 0.0334,
      "step": 5920
    },
    {
      "epoch": 10.570409982174688,
      "grad_norm": 1.1664559841156006,
      "learning_rate": 6.477124183006537e-05,
      "loss": 0.0344,
      "step": 5930
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 1.9402108192443848,
      "learning_rate": 6.471182412358884e-05,
      "loss": 0.0342,
      "step": 5940
    },
    {
      "epoch": 10.606060606060606,
      "grad_norm": 2.606741189956665,
      "learning_rate": 6.46524064171123e-05,
      "loss": 0.0373,
      "step": 5950
    },
    {
      "epoch": 10.623885918003564,
      "grad_norm": 0.8265124559402466,
      "learning_rate": 6.459298871063578e-05,
      "loss": 0.0333,
      "step": 5960
    },
    {
      "epoch": 10.641711229946525,
      "grad_norm": 1.664665699005127,
      "learning_rate": 6.453357100415924e-05,
      "loss": 0.0335,
      "step": 5970
    },
    {
      "epoch": 10.659536541889484,
      "grad_norm": 0.8781164288520813,
      "learning_rate": 6.447415329768271e-05,
      "loss": 0.0323,
      "step": 5980
    },
    {
      "epoch": 10.677361853832442,
      "grad_norm": 2.9827828407287598,
      "learning_rate": 6.441473559120619e-05,
      "loss": 0.0348,
      "step": 5990
    },
    {
      "epoch": 10.695187165775401,
      "grad_norm": 1.1923025846481323,
      "learning_rate": 6.435531788472965e-05,
      "loss": 0.0357,
      "step": 6000
    },
    {
      "epoch": 10.71301247771836,
      "grad_norm": 1.1755369901657104,
      "learning_rate": 6.429590017825313e-05,
      "loss": 0.0349,
      "step": 6010
    },
    {
      "epoch": 10.730837789661319,
      "grad_norm": 0.6395583748817444,
      "learning_rate": 6.423648247177659e-05,
      "loss": 0.0344,
      "step": 6020
    },
    {
      "epoch": 10.748663101604278,
      "grad_norm": 0.8245745301246643,
      "learning_rate": 6.417706476530006e-05,
      "loss": 0.0316,
      "step": 6030
    },
    {
      "epoch": 10.766488413547236,
      "grad_norm": 0.45694366097450256,
      "learning_rate": 6.411764705882354e-05,
      "loss": 0.0311,
      "step": 6040
    },
    {
      "epoch": 10.784313725490197,
      "grad_norm": 0.5761566162109375,
      "learning_rate": 6.4058229352347e-05,
      "loss": 0.0334,
      "step": 6050
    },
    {
      "epoch": 10.802139037433156,
      "grad_norm": 0.7958033084869385,
      "learning_rate": 6.399881164587047e-05,
      "loss": 0.0315,
      "step": 6060
    },
    {
      "epoch": 10.819964349376114,
      "grad_norm": 0.6954141855239868,
      "learning_rate": 6.393939393939395e-05,
      "loss": 0.031,
      "step": 6070
    },
    {
      "epoch": 10.837789661319073,
      "grad_norm": 1.5355809926986694,
      "learning_rate": 6.387997623291741e-05,
      "loss": 0.0342,
      "step": 6080
    },
    {
      "epoch": 10.855614973262032,
      "grad_norm": 0.5100164413452148,
      "learning_rate": 6.382055852644089e-05,
      "loss": 0.0338,
      "step": 6090
    },
    {
      "epoch": 10.87344028520499,
      "grad_norm": 1.1708664894104004,
      "learning_rate": 6.376114081996435e-05,
      "loss": 0.0332,
      "step": 6100
    },
    {
      "epoch": 10.89126559714795,
      "grad_norm": 0.505254328250885,
      "learning_rate": 6.370172311348782e-05,
      "loss": 0.0341,
      "step": 6110
    },
    {
      "epoch": 10.909090909090908,
      "grad_norm": 0.64285808801651,
      "learning_rate": 6.36423054070113e-05,
      "loss": 0.0368,
      "step": 6120
    },
    {
      "epoch": 10.926916221033869,
      "grad_norm": 1.1435502767562866,
      "learning_rate": 6.358288770053477e-05,
      "loss": 0.0326,
      "step": 6130
    },
    {
      "epoch": 10.944741532976828,
      "grad_norm": 1.3037855625152588,
      "learning_rate": 6.352346999405823e-05,
      "loss": 0.0331,
      "step": 6140
    },
    {
      "epoch": 10.962566844919786,
      "grad_norm": 1.347715973854065,
      "learning_rate": 6.34640522875817e-05,
      "loss": 0.0337,
      "step": 6150
    },
    {
      "epoch": 10.980392156862745,
      "grad_norm": 1.4622663259506226,
      "learning_rate": 6.340463458110517e-05,
      "loss": 0.0352,
      "step": 6160
    },
    {
      "epoch": 10.998217468805704,
      "grad_norm": 1.3217546939849854,
      "learning_rate": 6.334521687462865e-05,
      "loss": 0.0331,
      "step": 6170
    },
    {
      "epoch": 11.016042780748663,
      "grad_norm": 1.8989996910095215,
      "learning_rate": 6.328579916815212e-05,
      "loss": 0.0309,
      "step": 6180
    },
    {
      "epoch": 11.033868092691621,
      "grad_norm": 0.9119356274604797,
      "learning_rate": 6.322638146167558e-05,
      "loss": 0.0313,
      "step": 6190
    },
    {
      "epoch": 11.05169340463458,
      "grad_norm": 0.8256882429122925,
      "learning_rate": 6.316696375519904e-05,
      "loss": 0.0324,
      "step": 6200
    },
    {
      "epoch": 11.06951871657754,
      "grad_norm": 0.40213704109191895,
      "learning_rate": 6.310754604872252e-05,
      "loss": 0.0322,
      "step": 6210
    },
    {
      "epoch": 11.0873440285205,
      "grad_norm": 2.113327980041504,
      "learning_rate": 6.3048128342246e-05,
      "loss": 0.0336,
      "step": 6220
    },
    {
      "epoch": 11.105169340463458,
      "grad_norm": 1.2307894229888916,
      "learning_rate": 6.298871063576947e-05,
      "loss": 0.0299,
      "step": 6230
    },
    {
      "epoch": 11.122994652406417,
      "grad_norm": 1.1514089107513428,
      "learning_rate": 6.292929292929294e-05,
      "loss": 0.0329,
      "step": 6240
    },
    {
      "epoch": 11.140819964349376,
      "grad_norm": 0.578597366809845,
      "learning_rate": 6.28698752228164e-05,
      "loss": 0.0345,
      "step": 6250
    },
    {
      "epoch": 11.158645276292335,
      "grad_norm": 0.9717470407485962,
      "learning_rate": 6.281045751633987e-05,
      "loss": 0.032,
      "step": 6260
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 0.5482330322265625,
      "learning_rate": 6.275103980986334e-05,
      "loss": 0.0323,
      "step": 6270
    },
    {
      "epoch": 11.194295900178252,
      "grad_norm": 0.9976170659065247,
      "learning_rate": 6.269162210338682e-05,
      "loss": 0.0337,
      "step": 6280
    },
    {
      "epoch": 11.212121212121213,
      "grad_norm": 1.1253634691238403,
      "learning_rate": 6.263220439691028e-05,
      "loss": 0.0317,
      "step": 6290
    },
    {
      "epoch": 11.229946524064172,
      "grad_norm": 1.040910243988037,
      "learning_rate": 6.257278669043375e-05,
      "loss": 0.0308,
      "step": 6300
    },
    {
      "epoch": 11.24777183600713,
      "grad_norm": 1.557248830795288,
      "learning_rate": 6.251336898395722e-05,
      "loss": 0.0316,
      "step": 6310
    },
    {
      "epoch": 11.26559714795009,
      "grad_norm": 0.7097151875495911,
      "learning_rate": 6.245395127748069e-05,
      "loss": 0.0333,
      "step": 6320
    },
    {
      "epoch": 11.283422459893048,
      "grad_norm": 0.5974169969558716,
      "learning_rate": 6.239453357100417e-05,
      "loss": 0.0341,
      "step": 6330
    },
    {
      "epoch": 11.301247771836007,
      "grad_norm": 1.324495553970337,
      "learning_rate": 6.233511586452763e-05,
      "loss": 0.0331,
      "step": 6340
    },
    {
      "epoch": 11.319073083778965,
      "grad_norm": 0.8087818622589111,
      "learning_rate": 6.22756981580511e-05,
      "loss": 0.0338,
      "step": 6350
    },
    {
      "epoch": 11.336898395721924,
      "grad_norm": 0.8919538855552673,
      "learning_rate": 6.221628045157458e-05,
      "loss": 0.0322,
      "step": 6360
    },
    {
      "epoch": 11.354723707664885,
      "grad_norm": 1.5059181451797485,
      "learning_rate": 6.215686274509804e-05,
      "loss": 0.033,
      "step": 6370
    },
    {
      "epoch": 11.372549019607844,
      "grad_norm": 0.9971737861633301,
      "learning_rate": 6.209744503862151e-05,
      "loss": 0.0313,
      "step": 6380
    },
    {
      "epoch": 11.390374331550802,
      "grad_norm": 0.8689287900924683,
      "learning_rate": 6.203802733214497e-05,
      "loss": 0.0303,
      "step": 6390
    },
    {
      "epoch": 11.408199643493761,
      "grad_norm": 0.6877992153167725,
      "learning_rate": 6.197860962566845e-05,
      "loss": 0.031,
      "step": 6400
    },
    {
      "epoch": 11.42602495543672,
      "grad_norm": 0.9374362230300903,
      "learning_rate": 6.191919191919192e-05,
      "loss": 0.0309,
      "step": 6410
    },
    {
      "epoch": 11.443850267379679,
      "grad_norm": 0.9526681900024414,
      "learning_rate": 6.18597742127154e-05,
      "loss": 0.0324,
      "step": 6420
    },
    {
      "epoch": 11.461675579322637,
      "grad_norm": 1.0921578407287598,
      "learning_rate": 6.180035650623886e-05,
      "loss": 0.0359,
      "step": 6430
    },
    {
      "epoch": 11.479500891265598,
      "grad_norm": 0.7886708974838257,
      "learning_rate": 6.174093879976232e-05,
      "loss": 0.0307,
      "step": 6440
    },
    {
      "epoch": 11.497326203208557,
      "grad_norm": 0.5625978112220764,
      "learning_rate": 6.16815210932858e-05,
      "loss": 0.0336,
      "step": 6450
    },
    {
      "epoch": 11.515151515151516,
      "grad_norm": 1.1453555822372437,
      "learning_rate": 6.162210338680927e-05,
      "loss": 0.0302,
      "step": 6460
    },
    {
      "epoch": 11.532976827094474,
      "grad_norm": 1.212343692779541,
      "learning_rate": 6.156268568033275e-05,
      "loss": 0.0319,
      "step": 6470
    },
    {
      "epoch": 11.550802139037433,
      "grad_norm": 0.6654501557350159,
      "learning_rate": 6.150326797385621e-05,
      "loss": 0.0328,
      "step": 6480
    },
    {
      "epoch": 11.568627450980392,
      "grad_norm": 1.9513449668884277,
      "learning_rate": 6.144385026737967e-05,
      "loss": 0.0323,
      "step": 6490
    },
    {
      "epoch": 11.58645276292335,
      "grad_norm": 0.8115867972373962,
      "learning_rate": 6.138443256090315e-05,
      "loss": 0.0327,
      "step": 6500
    },
    {
      "epoch": 11.60427807486631,
      "grad_norm": 1.4385071992874146,
      "learning_rate": 6.132501485442662e-05,
      "loss": 0.0329,
      "step": 6510
    },
    {
      "epoch": 11.622103386809268,
      "grad_norm": 0.4352489411830902,
      "learning_rate": 6.12655971479501e-05,
      "loss": 0.0313,
      "step": 6520
    },
    {
      "epoch": 11.639928698752229,
      "grad_norm": 1.5273271799087524,
      "learning_rate": 6.120617944147357e-05,
      "loss": 0.0335,
      "step": 6530
    },
    {
      "epoch": 11.657754010695188,
      "grad_norm": 0.8801183104515076,
      "learning_rate": 6.114676173499703e-05,
      "loss": 0.0308,
      "step": 6540
    },
    {
      "epoch": 11.675579322638146,
      "grad_norm": 0.8258956074714661,
      "learning_rate": 6.10873440285205e-05,
      "loss": 0.033,
      "step": 6550
    },
    {
      "epoch": 11.693404634581105,
      "grad_norm": 1.1074739694595337,
      "learning_rate": 6.102792632204397e-05,
      "loss": 0.0327,
      "step": 6560
    },
    {
      "epoch": 11.711229946524064,
      "grad_norm": 0.6482132077217102,
      "learning_rate": 6.0968508615567445e-05,
      "loss": 0.0326,
      "step": 6570
    },
    {
      "epoch": 11.729055258467023,
      "grad_norm": 0.7235182523727417,
      "learning_rate": 6.090909090909091e-05,
      "loss": 0.0333,
      "step": 6580
    },
    {
      "epoch": 11.746880570409981,
      "grad_norm": 0.7274712920188904,
      "learning_rate": 6.0849673202614375e-05,
      "loss": 0.031,
      "step": 6590
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 0.7308871746063232,
      "learning_rate": 6.079025549613785e-05,
      "loss": 0.0315,
      "step": 6600
    },
    {
      "epoch": 11.7825311942959,
      "grad_norm": 0.8125917911529541,
      "learning_rate": 6.073083778966132e-05,
      "loss": 0.0311,
      "step": 6610
    },
    {
      "epoch": 11.80035650623886,
      "grad_norm": 1.2136728763580322,
      "learning_rate": 6.067142008318479e-05,
      "loss": 0.0317,
      "step": 6620
    },
    {
      "epoch": 11.818181818181818,
      "grad_norm": 0.4298255145549774,
      "learning_rate": 6.061200237670827e-05,
      "loss": 0.0315,
      "step": 6630
    },
    {
      "epoch": 11.836007130124777,
      "grad_norm": 1.5158859491348267,
      "learning_rate": 6.055258467023173e-05,
      "loss": 0.0331,
      "step": 6640
    },
    {
      "epoch": 11.853832442067736,
      "grad_norm": 0.6372511386871338,
      "learning_rate": 6.04931669637552e-05,
      "loss": 0.0308,
      "step": 6650
    },
    {
      "epoch": 11.871657754010695,
      "grad_norm": 0.5712776780128479,
      "learning_rate": 6.043374925727867e-05,
      "loss": 0.0346,
      "step": 6660
    },
    {
      "epoch": 11.889483065953653,
      "grad_norm": 0.8540253043174744,
      "learning_rate": 6.037433155080214e-05,
      "loss": 0.0318,
      "step": 6670
    },
    {
      "epoch": 11.907308377896614,
      "grad_norm": 1.0665194988250732,
      "learning_rate": 6.0314913844325616e-05,
      "loss": 0.0349,
      "step": 6680
    },
    {
      "epoch": 11.925133689839573,
      "grad_norm": 1.5027849674224854,
      "learning_rate": 6.025549613784908e-05,
      "loss": 0.0336,
      "step": 6690
    },
    {
      "epoch": 11.942959001782532,
      "grad_norm": 0.4466232657432556,
      "learning_rate": 6.0196078431372546e-05,
      "loss": 0.0341,
      "step": 6700
    },
    {
      "epoch": 11.96078431372549,
      "grad_norm": 0.9829168319702148,
      "learning_rate": 6.013666072489602e-05,
      "loss": 0.0314,
      "step": 6710
    },
    {
      "epoch": 11.97860962566845,
      "grad_norm": 1.9202027320861816,
      "learning_rate": 6.0077243018419496e-05,
      "loss": 0.0323,
      "step": 6720
    },
    {
      "epoch": 11.996434937611408,
      "grad_norm": 0.46795180439949036,
      "learning_rate": 6.0017825311942964e-05,
      "loss": 0.033,
      "step": 6730
    },
    {
      "epoch": 12.014260249554367,
      "grad_norm": 0.44410741329193115,
      "learning_rate": 5.9958407605466426e-05,
      "loss": 0.0331,
      "step": 6740
    },
    {
      "epoch": 12.032085561497325,
      "grad_norm": 0.8277490735054016,
      "learning_rate": 5.98989898989899e-05,
      "loss": 0.0312,
      "step": 6750
    },
    {
      "epoch": 12.049910873440286,
      "grad_norm": 0.39661428332328796,
      "learning_rate": 5.983957219251337e-05,
      "loss": 0.0328,
      "step": 6760
    },
    {
      "epoch": 12.067736185383245,
      "grad_norm": 0.757249116897583,
      "learning_rate": 5.9780154486036844e-05,
      "loss": 0.0311,
      "step": 6770
    },
    {
      "epoch": 12.085561497326204,
      "grad_norm": 1.3880904912948608,
      "learning_rate": 5.972073677956031e-05,
      "loss": 0.0304,
      "step": 6780
    },
    {
      "epoch": 12.103386809269162,
      "grad_norm": 1.123962640762329,
      "learning_rate": 5.9661319073083774e-05,
      "loss": 0.0321,
      "step": 6790
    },
    {
      "epoch": 12.121212121212121,
      "grad_norm": 0.8439579010009766,
      "learning_rate": 5.960190136660725e-05,
      "loss": 0.0331,
      "step": 6800
    },
    {
      "epoch": 12.13903743315508,
      "grad_norm": 1.0300376415252686,
      "learning_rate": 5.9542483660130724e-05,
      "loss": 0.0305,
      "step": 6810
    },
    {
      "epoch": 12.156862745098039,
      "grad_norm": 0.5931544899940491,
      "learning_rate": 5.948306595365419e-05,
      "loss": 0.0319,
      "step": 6820
    },
    {
      "epoch": 12.174688057040997,
      "grad_norm": 0.5597521662712097,
      "learning_rate": 5.942364824717767e-05,
      "loss": 0.0314,
      "step": 6830
    },
    {
      "epoch": 12.192513368983958,
      "grad_norm": 0.5987480878829956,
      "learning_rate": 5.936423054070113e-05,
      "loss": 0.0292,
      "step": 6840
    },
    {
      "epoch": 12.210338680926917,
      "grad_norm": 0.7673749923706055,
      "learning_rate": 5.93048128342246e-05,
      "loss": 0.032,
      "step": 6850
    },
    {
      "epoch": 12.228163992869876,
      "grad_norm": 1.071250081062317,
      "learning_rate": 5.924539512774807e-05,
      "loss": 0.0321,
      "step": 6860
    },
    {
      "epoch": 12.245989304812834,
      "grad_norm": 1.0903791189193726,
      "learning_rate": 5.918597742127154e-05,
      "loss": 0.0329,
      "step": 6870
    },
    {
      "epoch": 12.263814616755793,
      "grad_norm": 1.1696605682373047,
      "learning_rate": 5.9126559714795016e-05,
      "loss": 0.0314,
      "step": 6880
    },
    {
      "epoch": 12.281639928698752,
      "grad_norm": 1.8981084823608398,
      "learning_rate": 5.906714200831848e-05,
      "loss": 0.0315,
      "step": 6890
    },
    {
      "epoch": 12.29946524064171,
      "grad_norm": 0.4827171266078949,
      "learning_rate": 5.9007724301841946e-05,
      "loss": 0.0319,
      "step": 6900
    },
    {
      "epoch": 12.31729055258467,
      "grad_norm": 7.141317844390869,
      "learning_rate": 5.894830659536542e-05,
      "loss": 0.0332,
      "step": 6910
    },
    {
      "epoch": 12.33511586452763,
      "grad_norm": 1.0593634843826294,
      "learning_rate": 5.8888888888888896e-05,
      "loss": 0.0327,
      "step": 6920
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 0.40477892756462097,
      "learning_rate": 5.8829471182412364e-05,
      "loss": 0.0319,
      "step": 6930
    },
    {
      "epoch": 12.370766488413548,
      "grad_norm": 0.6368297338485718,
      "learning_rate": 5.8770053475935826e-05,
      "loss": 0.0315,
      "step": 6940
    },
    {
      "epoch": 12.388591800356506,
      "grad_norm": 1.5123927593231201,
      "learning_rate": 5.87106357694593e-05,
      "loss": 0.031,
      "step": 6950
    },
    {
      "epoch": 12.406417112299465,
      "grad_norm": 0.8173614144325256,
      "learning_rate": 5.865121806298277e-05,
      "loss": 0.0317,
      "step": 6960
    },
    {
      "epoch": 12.424242424242424,
      "grad_norm": 0.7810312509536743,
      "learning_rate": 5.8591800356506244e-05,
      "loss": 0.033,
      "step": 6970
    },
    {
      "epoch": 12.442067736185383,
      "grad_norm": 0.9806250929832458,
      "learning_rate": 5.853238265002971e-05,
      "loss": 0.0315,
      "step": 6980
    },
    {
      "epoch": 12.459893048128341,
      "grad_norm": 0.4415654242038727,
      "learning_rate": 5.8472964943553174e-05,
      "loss": 0.0304,
      "step": 6990
    },
    {
      "epoch": 12.477718360071302,
      "grad_norm": 0.6578551530838013,
      "learning_rate": 5.841354723707665e-05,
      "loss": 0.0322,
      "step": 7000
    },
    {
      "epoch": 12.49554367201426,
      "grad_norm": 0.6388345956802368,
      "learning_rate": 5.8354129530600124e-05,
      "loss": 0.0307,
      "step": 7010
    },
    {
      "epoch": 12.51336898395722,
      "grad_norm": 0.9284079670906067,
      "learning_rate": 5.829471182412359e-05,
      "loss": 0.0309,
      "step": 7020
    },
    {
      "epoch": 12.531194295900178,
      "grad_norm": 1.4750349521636963,
      "learning_rate": 5.823529411764707e-05,
      "loss": 0.0299,
      "step": 7030
    },
    {
      "epoch": 12.549019607843137,
      "grad_norm": 0.6581206917762756,
      "learning_rate": 5.817587641117053e-05,
      "loss": 0.0294,
      "step": 7040
    },
    {
      "epoch": 12.566844919786096,
      "grad_norm": 0.8645361065864563,
      "learning_rate": 5.8116458704694e-05,
      "loss": 0.0343,
      "step": 7050
    },
    {
      "epoch": 12.584670231729055,
      "grad_norm": 0.45584991574287415,
      "learning_rate": 5.805704099821747e-05,
      "loss": 0.0323,
      "step": 7060
    },
    {
      "epoch": 12.602495543672013,
      "grad_norm": 0.8177371621131897,
      "learning_rate": 5.799762329174094e-05,
      "loss": 0.0303,
      "step": 7070
    },
    {
      "epoch": 12.620320855614974,
      "grad_norm": 0.819122314453125,
      "learning_rate": 5.7938205585264415e-05,
      "loss": 0.0315,
      "step": 7080
    },
    {
      "epoch": 12.638146167557933,
      "grad_norm": 1.5583345890045166,
      "learning_rate": 5.787878787878788e-05,
      "loss": 0.0303,
      "step": 7090
    },
    {
      "epoch": 12.655971479500892,
      "grad_norm": 0.7189263105392456,
      "learning_rate": 5.781937017231135e-05,
      "loss": 0.0295,
      "step": 7100
    },
    {
      "epoch": 12.67379679144385,
      "grad_norm": 0.6074221730232239,
      "learning_rate": 5.775995246583482e-05,
      "loss": 0.0308,
      "step": 7110
    },
    {
      "epoch": 12.691622103386809,
      "grad_norm": 0.6552563309669495,
      "learning_rate": 5.7700534759358295e-05,
      "loss": 0.0312,
      "step": 7120
    },
    {
      "epoch": 12.709447415329768,
      "grad_norm": 0.888641893863678,
      "learning_rate": 5.7641117052881764e-05,
      "loss": 0.0309,
      "step": 7130
    },
    {
      "epoch": 12.727272727272727,
      "grad_norm": 1.0971530675888062,
      "learning_rate": 5.7581699346405225e-05,
      "loss": 0.0317,
      "step": 7140
    },
    {
      "epoch": 12.745098039215687,
      "grad_norm": 1.0137423276901245,
      "learning_rate": 5.75222816399287e-05,
      "loss": 0.0332,
      "step": 7150
    },
    {
      "epoch": 12.762923351158646,
      "grad_norm": 0.4261450171470642,
      "learning_rate": 5.746286393345217e-05,
      "loss": 0.0294,
      "step": 7160
    },
    {
      "epoch": 12.780748663101605,
      "grad_norm": 0.7413285374641418,
      "learning_rate": 5.7403446226975644e-05,
      "loss": 0.0312,
      "step": 7170
    },
    {
      "epoch": 12.798573975044564,
      "grad_norm": 0.5750056505203247,
      "learning_rate": 5.734402852049912e-05,
      "loss": 0.0285,
      "step": 7180
    },
    {
      "epoch": 12.816399286987522,
      "grad_norm": 0.8506306409835815,
      "learning_rate": 5.7284610814022573e-05,
      "loss": 0.0298,
      "step": 7190
    },
    {
      "epoch": 12.834224598930481,
      "grad_norm": 1.6192368268966675,
      "learning_rate": 5.722519310754605e-05,
      "loss": 0.0305,
      "step": 7200
    },
    {
      "epoch": 12.85204991087344,
      "grad_norm": 0.704902172088623,
      "learning_rate": 5.7165775401069524e-05,
      "loss": 0.029,
      "step": 7210
    },
    {
      "epoch": 12.869875222816399,
      "grad_norm": 0.8697908520698547,
      "learning_rate": 5.710635769459299e-05,
      "loss": 0.0318,
      "step": 7220
    },
    {
      "epoch": 12.887700534759357,
      "grad_norm": 0.7696578502655029,
      "learning_rate": 5.704693998811647e-05,
      "loss": 0.0306,
      "step": 7230
    },
    {
      "epoch": 12.905525846702318,
      "grad_norm": 0.7294285893440247,
      "learning_rate": 5.698752228163993e-05,
      "loss": 0.0288,
      "step": 7240
    },
    {
      "epoch": 12.923351158645277,
      "grad_norm": 0.8717653155326843,
      "learning_rate": 5.69281045751634e-05,
      "loss": 0.031,
      "step": 7250
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 0.5885206460952759,
      "learning_rate": 5.686868686868687e-05,
      "loss": 0.0299,
      "step": 7260
    },
    {
      "epoch": 12.959001782531194,
      "grad_norm": 1.037485122680664,
      "learning_rate": 5.680926916221034e-05,
      "loss": 0.0319,
      "step": 7270
    },
    {
      "epoch": 12.976827094474153,
      "grad_norm": 1.080336570739746,
      "learning_rate": 5.6749851455733815e-05,
      "loss": 0.0284,
      "step": 7280
    },
    {
      "epoch": 12.994652406417112,
      "grad_norm": 0.7292784452438354,
      "learning_rate": 5.669043374925728e-05,
      "loss": 0.0311,
      "step": 7290
    },
    {
      "epoch": 13.01247771836007,
      "grad_norm": 1.0590486526489258,
      "learning_rate": 5.663101604278075e-05,
      "loss": 0.0294,
      "step": 7300
    },
    {
      "epoch": 13.030303030303031,
      "grad_norm": 0.5111613869667053,
      "learning_rate": 5.657159833630422e-05,
      "loss": 0.0313,
      "step": 7310
    },
    {
      "epoch": 13.04812834224599,
      "grad_norm": 1.2102948427200317,
      "learning_rate": 5.6512180629827695e-05,
      "loss": 0.03,
      "step": 7320
    },
    {
      "epoch": 13.065953654188949,
      "grad_norm": 0.7216916084289551,
      "learning_rate": 5.645276292335116e-05,
      "loss": 0.0282,
      "step": 7330
    },
    {
      "epoch": 13.083778966131907,
      "grad_norm": 0.5528075098991394,
      "learning_rate": 5.6393345216874625e-05,
      "loss": 0.0314,
      "step": 7340
    },
    {
      "epoch": 13.101604278074866,
      "grad_norm": 0.50066077709198,
      "learning_rate": 5.63339275103981e-05,
      "loss": 0.0289,
      "step": 7350
    },
    {
      "epoch": 13.119429590017825,
      "grad_norm": 1.478576898574829,
      "learning_rate": 5.627450980392157e-05,
      "loss": 0.0297,
      "step": 7360
    },
    {
      "epoch": 13.137254901960784,
      "grad_norm": 0.715806782245636,
      "learning_rate": 5.621509209744504e-05,
      "loss": 0.0297,
      "step": 7370
    },
    {
      "epoch": 13.155080213903743,
      "grad_norm": 0.7315666675567627,
      "learning_rate": 5.615567439096852e-05,
      "loss": 0.0275,
      "step": 7380
    },
    {
      "epoch": 13.172905525846703,
      "grad_norm": 0.7816293835639954,
      "learning_rate": 5.609625668449198e-05,
      "loss": 0.0293,
      "step": 7390
    },
    {
      "epoch": 13.190730837789662,
      "grad_norm": 0.8453638553619385,
      "learning_rate": 5.603683897801545e-05,
      "loss": 0.0291,
      "step": 7400
    },
    {
      "epoch": 13.20855614973262,
      "grad_norm": 0.8067950010299683,
      "learning_rate": 5.597742127153892e-05,
      "loss": 0.0306,
      "step": 7410
    },
    {
      "epoch": 13.22638146167558,
      "grad_norm": 0.37656885385513306,
      "learning_rate": 5.591800356506239e-05,
      "loss": 0.0287,
      "step": 7420
    },
    {
      "epoch": 13.244206773618538,
      "grad_norm": 1.1370012760162354,
      "learning_rate": 5.5858585858585867e-05,
      "loss": 0.0311,
      "step": 7430
    },
    {
      "epoch": 13.262032085561497,
      "grad_norm": 0.5722132325172424,
      "learning_rate": 5.579916815210933e-05,
      "loss": 0.0316,
      "step": 7440
    },
    {
      "epoch": 13.279857397504456,
      "grad_norm": 0.38793763518333435,
      "learning_rate": 5.5739750445632796e-05,
      "loss": 0.0312,
      "step": 7450
    },
    {
      "epoch": 13.297682709447415,
      "grad_norm": 1.5226836204528809,
      "learning_rate": 5.568033273915627e-05,
      "loss": 0.0314,
      "step": 7460
    },
    {
      "epoch": 13.315508021390375,
      "grad_norm": 1.020857334136963,
      "learning_rate": 5.5620915032679746e-05,
      "loss": 0.0304,
      "step": 7470
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.794987142086029,
      "learning_rate": 5.5561497326203215e-05,
      "loss": 0.0299,
      "step": 7480
    },
    {
      "epoch": 13.351158645276293,
      "grad_norm": 0.8688892126083374,
      "learning_rate": 5.5502079619726676e-05,
      "loss": 0.0303,
      "step": 7490
    },
    {
      "epoch": 13.368983957219251,
      "grad_norm": 1.388632893562317,
      "learning_rate": 5.544266191325015e-05,
      "loss": 0.0303,
      "step": 7500
    },
    {
      "epoch": 13.38680926916221,
      "grad_norm": 0.8249629735946655,
      "learning_rate": 5.538324420677362e-05,
      "loss": 0.0305,
      "step": 7510
    },
    {
      "epoch": 13.404634581105169,
      "grad_norm": 0.4956330358982086,
      "learning_rate": 5.5323826500297095e-05,
      "loss": 0.0312,
      "step": 7520
    },
    {
      "epoch": 13.422459893048128,
      "grad_norm": 0.6566820740699768,
      "learning_rate": 5.526440879382056e-05,
      "loss": 0.029,
      "step": 7530
    },
    {
      "epoch": 13.440285204991087,
      "grad_norm": 0.9815472364425659,
      "learning_rate": 5.5204991087344025e-05,
      "loss": 0.029,
      "step": 7540
    },
    {
      "epoch": 13.458110516934047,
      "grad_norm": 0.9021039605140686,
      "learning_rate": 5.51455733808675e-05,
      "loss": 0.0307,
      "step": 7550
    },
    {
      "epoch": 13.475935828877006,
      "grad_norm": 0.501440703868866,
      "learning_rate": 5.508615567439097e-05,
      "loss": 0.0294,
      "step": 7560
    },
    {
      "epoch": 13.493761140819965,
      "grad_norm": 0.5552279353141785,
      "learning_rate": 5.502673796791444e-05,
      "loss": 0.0308,
      "step": 7570
    },
    {
      "epoch": 13.511586452762923,
      "grad_norm": 0.9660727977752686,
      "learning_rate": 5.496732026143792e-05,
      "loss": 0.0277,
      "step": 7580
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 0.9424383044242859,
      "learning_rate": 5.490790255496138e-05,
      "loss": 0.0309,
      "step": 7590
    },
    {
      "epoch": 13.547237076648841,
      "grad_norm": 0.7745004296302795,
      "learning_rate": 5.484848484848485e-05,
      "loss": 0.0312,
      "step": 7600
    },
    {
      "epoch": 13.5650623885918,
      "grad_norm": 0.43437498807907104,
      "learning_rate": 5.478906714200832e-05,
      "loss": 0.0291,
      "step": 7610
    },
    {
      "epoch": 13.582887700534759,
      "grad_norm": 0.7845872044563293,
      "learning_rate": 5.472964943553179e-05,
      "loss": 0.0286,
      "step": 7620
    },
    {
      "epoch": 13.60071301247772,
      "grad_norm": 0.8304678797721863,
      "learning_rate": 5.4670231729055266e-05,
      "loss": 0.0299,
      "step": 7630
    },
    {
      "epoch": 13.618538324420678,
      "grad_norm": 0.7552484273910522,
      "learning_rate": 5.461081402257873e-05,
      "loss": 0.0291,
      "step": 7640
    },
    {
      "epoch": 13.636363636363637,
      "grad_norm": 0.8727213144302368,
      "learning_rate": 5.4551396316102196e-05,
      "loss": 0.0288,
      "step": 7650
    },
    {
      "epoch": 13.654188948306595,
      "grad_norm": 0.7210443019866943,
      "learning_rate": 5.449197860962567e-05,
      "loss": 0.0295,
      "step": 7660
    },
    {
      "epoch": 13.672014260249554,
      "grad_norm": 0.5425326824188232,
      "learning_rate": 5.4432560903149146e-05,
      "loss": 0.0271,
      "step": 7670
    },
    {
      "epoch": 13.689839572192513,
      "grad_norm": 0.4654993414878845,
      "learning_rate": 5.4373143196672614e-05,
      "loss": 0.0289,
      "step": 7680
    },
    {
      "epoch": 13.707664884135472,
      "grad_norm": 0.7677962779998779,
      "learning_rate": 5.4313725490196076e-05,
      "loss": 0.0309,
      "step": 7690
    },
    {
      "epoch": 13.72549019607843,
      "grad_norm": 0.7632262706756592,
      "learning_rate": 5.425430778371955e-05,
      "loss": 0.0293,
      "step": 7700
    },
    {
      "epoch": 13.743315508021391,
      "grad_norm": 0.8128527402877808,
      "learning_rate": 5.419489007724302e-05,
      "loss": 0.0298,
      "step": 7710
    },
    {
      "epoch": 13.76114081996435,
      "grad_norm": 1.0065659284591675,
      "learning_rate": 5.4135472370766494e-05,
      "loss": 0.0289,
      "step": 7720
    },
    {
      "epoch": 13.778966131907309,
      "grad_norm": 0.6441785097122192,
      "learning_rate": 5.407605466428996e-05,
      "loss": 0.0302,
      "step": 7730
    },
    {
      "epoch": 13.796791443850267,
      "grad_norm": 0.6127110123634338,
      "learning_rate": 5.4016636957813424e-05,
      "loss": 0.0298,
      "step": 7740
    },
    {
      "epoch": 13.814616755793226,
      "grad_norm": 1.112027883529663,
      "learning_rate": 5.39572192513369e-05,
      "loss": 0.0289,
      "step": 7750
    },
    {
      "epoch": 13.832442067736185,
      "grad_norm": 0.5789859294891357,
      "learning_rate": 5.3897801544860374e-05,
      "loss": 0.0299,
      "step": 7760
    },
    {
      "epoch": 13.850267379679144,
      "grad_norm": 0.5349467396736145,
      "learning_rate": 5.383838383838384e-05,
      "loss": 0.0304,
      "step": 7770
    },
    {
      "epoch": 13.868092691622103,
      "grad_norm": 0.4280056655406952,
      "learning_rate": 5.377896613190732e-05,
      "loss": 0.0304,
      "step": 7780
    },
    {
      "epoch": 13.885918003565063,
      "grad_norm": 0.6353553533554077,
      "learning_rate": 5.371954842543078e-05,
      "loss": 0.0312,
      "step": 7790
    },
    {
      "epoch": 13.903743315508022,
      "grad_norm": 0.7155984044075012,
      "learning_rate": 5.366013071895425e-05,
      "loss": 0.0286,
      "step": 7800
    },
    {
      "epoch": 13.92156862745098,
      "grad_norm": 0.7519047856330872,
      "learning_rate": 5.360071301247772e-05,
      "loss": 0.0312,
      "step": 7810
    },
    {
      "epoch": 13.93939393939394,
      "grad_norm": 0.5028905272483826,
      "learning_rate": 5.354129530600119e-05,
      "loss": 0.0317,
      "step": 7820
    },
    {
      "epoch": 13.957219251336898,
      "grad_norm": 0.4556068181991577,
      "learning_rate": 5.3481877599524666e-05,
      "loss": 0.0282,
      "step": 7830
    },
    {
      "epoch": 13.975044563279857,
      "grad_norm": 0.52047199010849,
      "learning_rate": 5.342245989304813e-05,
      "loss": 0.0279,
      "step": 7840
    },
    {
      "epoch": 13.992869875222816,
      "grad_norm": 0.7022458910942078,
      "learning_rate": 5.33630421865716e-05,
      "loss": 0.0309,
      "step": 7850
    },
    {
      "epoch": 14.010695187165775,
      "grad_norm": 1.0289674997329712,
      "learning_rate": 5.330362448009507e-05,
      "loss": 0.0315,
      "step": 7860
    },
    {
      "epoch": 14.028520499108735,
      "grad_norm": 0.8749725222587585,
      "learning_rate": 5.3244206773618546e-05,
      "loss": 0.0285,
      "step": 7870
    },
    {
      "epoch": 14.046345811051694,
      "grad_norm": 0.7696431875228882,
      "learning_rate": 5.3184789067142014e-05,
      "loss": 0.0284,
      "step": 7880
    },
    {
      "epoch": 14.064171122994653,
      "grad_norm": 0.638634443283081,
      "learning_rate": 5.3125371360665476e-05,
      "loss": 0.0281,
      "step": 7890
    },
    {
      "epoch": 14.081996434937611,
      "grad_norm": 0.9667591452598572,
      "learning_rate": 5.306595365418895e-05,
      "loss": 0.0286,
      "step": 7900
    },
    {
      "epoch": 14.09982174688057,
      "grad_norm": 0.9367659091949463,
      "learning_rate": 5.300653594771242e-05,
      "loss": 0.0298,
      "step": 7910
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 0.739196240901947,
      "learning_rate": 5.2947118241235894e-05,
      "loss": 0.0284,
      "step": 7920
    },
    {
      "epoch": 14.135472370766488,
      "grad_norm": 0.8628988265991211,
      "learning_rate": 5.288770053475937e-05,
      "loss": 0.0272,
      "step": 7930
    },
    {
      "epoch": 14.153297682709447,
      "grad_norm": 0.8918744325637817,
      "learning_rate": 5.2828282828282824e-05,
      "loss": 0.0274,
      "step": 7940
    },
    {
      "epoch": 14.171122994652407,
      "grad_norm": 0.787842869758606,
      "learning_rate": 5.27688651218063e-05,
      "loss": 0.0283,
      "step": 7950
    },
    {
      "epoch": 14.188948306595366,
      "grad_norm": 0.6982545256614685,
      "learning_rate": 5.2709447415329774e-05,
      "loss": 0.0289,
      "step": 7960
    },
    {
      "epoch": 14.206773618538325,
      "grad_norm": 0.637910008430481,
      "learning_rate": 5.265002970885324e-05,
      "loss": 0.0289,
      "step": 7970
    },
    {
      "epoch": 14.224598930481283,
      "grad_norm": 1.2921710014343262,
      "learning_rate": 5.259061200237672e-05,
      "loss": 0.0275,
      "step": 7980
    },
    {
      "epoch": 14.242424242424242,
      "grad_norm": 0.5210149884223938,
      "learning_rate": 5.253119429590018e-05,
      "loss": 0.0267,
      "step": 7990
    },
    {
      "epoch": 14.260249554367201,
      "grad_norm": 0.3441008925437927,
      "learning_rate": 5.247177658942365e-05,
      "loss": 0.027,
      "step": 8000
    },
    {
      "epoch": 14.27807486631016,
      "grad_norm": 0.73154217004776,
      "learning_rate": 5.241235888294712e-05,
      "loss": 0.028,
      "step": 8010
    },
    {
      "epoch": 14.29590017825312,
      "grad_norm": 0.6087384223937988,
      "learning_rate": 5.235294117647059e-05,
      "loss": 0.0262,
      "step": 8020
    },
    {
      "epoch": 14.313725490196079,
      "grad_norm": 0.6388477683067322,
      "learning_rate": 5.2293523469994065e-05,
      "loss": 0.0266,
      "step": 8030
    },
    {
      "epoch": 14.331550802139038,
      "grad_norm": 0.5492219924926758,
      "learning_rate": 5.223410576351753e-05,
      "loss": 0.0283,
      "step": 8040
    },
    {
      "epoch": 14.349376114081997,
      "grad_norm": 0.5444672107696533,
      "learning_rate": 5.2174688057041e-05,
      "loss": 0.0277,
      "step": 8050
    },
    {
      "epoch": 14.367201426024955,
      "grad_norm": 0.7142344117164612,
      "learning_rate": 5.211527035056447e-05,
      "loss": 0.0279,
      "step": 8060
    },
    {
      "epoch": 14.385026737967914,
      "grad_norm": 0.3539251685142517,
      "learning_rate": 5.2055852644087945e-05,
      "loss": 0.0285,
      "step": 8070
    },
    {
      "epoch": 14.402852049910873,
      "grad_norm": 1.109551191329956,
      "learning_rate": 5.1996434937611414e-05,
      "loss": 0.0317,
      "step": 8080
    },
    {
      "epoch": 14.420677361853832,
      "grad_norm": 0.6912109851837158,
      "learning_rate": 5.1937017231134875e-05,
      "loss": 0.0272,
      "step": 8090
    },
    {
      "epoch": 14.43850267379679,
      "grad_norm": 0.5782079696655273,
      "learning_rate": 5.187759952465835e-05,
      "loss": 0.0284,
      "step": 8100
    },
    {
      "epoch": 14.456327985739751,
      "grad_norm": 1.5110797882080078,
      "learning_rate": 5.181818181818182e-05,
      "loss": 0.0292,
      "step": 8110
    },
    {
      "epoch": 14.47415329768271,
      "grad_norm": 1.017837643623352,
      "learning_rate": 5.1758764111705294e-05,
      "loss": 0.0279,
      "step": 8120
    },
    {
      "epoch": 14.491978609625669,
      "grad_norm": 0.7753919959068298,
      "learning_rate": 5.169934640522877e-05,
      "loss": 0.0272,
      "step": 8130
    },
    {
      "epoch": 14.509803921568627,
      "grad_norm": 1.5314249992370605,
      "learning_rate": 5.163992869875223e-05,
      "loss": 0.0291,
      "step": 8140
    },
    {
      "epoch": 14.527629233511586,
      "grad_norm": 0.3579899072647095,
      "learning_rate": 5.15805109922757e-05,
      "loss": 0.0274,
      "step": 8150
    },
    {
      "epoch": 14.545454545454545,
      "grad_norm": 0.6274968981742859,
      "learning_rate": 5.1521093285799174e-05,
      "loss": 0.028,
      "step": 8160
    },
    {
      "epoch": 14.563279857397504,
      "grad_norm": 1.0218932628631592,
      "learning_rate": 5.146167557932264e-05,
      "loss": 0.0283,
      "step": 8170
    },
    {
      "epoch": 14.581105169340464,
      "grad_norm": 0.4126880466938019,
      "learning_rate": 5.140225787284612e-05,
      "loss": 0.0276,
      "step": 8180
    },
    {
      "epoch": 14.598930481283423,
      "grad_norm": 0.7657918930053711,
      "learning_rate": 5.134284016636958e-05,
      "loss": 0.0277,
      "step": 8190
    },
    {
      "epoch": 14.616755793226382,
      "grad_norm": 0.4112887680530548,
      "learning_rate": 5.128342245989305e-05,
      "loss": 0.0292,
      "step": 8200
    },
    {
      "epoch": 14.63458110516934,
      "grad_norm": 0.5548937916755676,
      "learning_rate": 5.122400475341652e-05,
      "loss": 0.0284,
      "step": 8210
    },
    {
      "epoch": 14.6524064171123,
      "grad_norm": 1.0096925497055054,
      "learning_rate": 5.116458704694e-05,
      "loss": 0.0275,
      "step": 8220
    },
    {
      "epoch": 14.670231729055258,
      "grad_norm": 0.8412864208221436,
      "learning_rate": 5.1105169340463465e-05,
      "loss": 0.0295,
      "step": 8230
    },
    {
      "epoch": 14.688057040998217,
      "grad_norm": 0.543394923210144,
      "learning_rate": 5.104575163398693e-05,
      "loss": 0.0288,
      "step": 8240
    },
    {
      "epoch": 14.705882352941176,
      "grad_norm": 0.879971981048584,
      "learning_rate": 5.09863339275104e-05,
      "loss": 0.0272,
      "step": 8250
    },
    {
      "epoch": 14.723707664884136,
      "grad_norm": 0.420045405626297,
      "learning_rate": 5.092691622103387e-05,
      "loss": 0.0281,
      "step": 8260
    },
    {
      "epoch": 14.741532976827095,
      "grad_norm": 0.33749425411224365,
      "learning_rate": 5.0867498514557345e-05,
      "loss": 0.0274,
      "step": 8270
    },
    {
      "epoch": 14.759358288770054,
      "grad_norm": 0.629364013671875,
      "learning_rate": 5.080808080808081e-05,
      "loss": 0.0289,
      "step": 8280
    },
    {
      "epoch": 14.777183600713013,
      "grad_norm": 1.1248416900634766,
      "learning_rate": 5.0748663101604275e-05,
      "loss": 0.0296,
      "step": 8290
    },
    {
      "epoch": 14.795008912655971,
      "grad_norm": 0.6380856037139893,
      "learning_rate": 5.068924539512775e-05,
      "loss": 0.0282,
      "step": 8300
    },
    {
      "epoch": 14.81283422459893,
      "grad_norm": 0.42258819937705994,
      "learning_rate": 5.062982768865122e-05,
      "loss": 0.0284,
      "step": 8310
    },
    {
      "epoch": 14.830659536541889,
      "grad_norm": 0.9350581765174866,
      "learning_rate": 5.057040998217469e-05,
      "loss": 0.0286,
      "step": 8320
    },
    {
      "epoch": 14.848484848484848,
      "grad_norm": 0.7147319912910461,
      "learning_rate": 5.051099227569817e-05,
      "loss": 0.0282,
      "step": 8330
    },
    {
      "epoch": 14.866310160427808,
      "grad_norm": 0.7518104910850525,
      "learning_rate": 5.045157456922163e-05,
      "loss": 0.0306,
      "step": 8340
    },
    {
      "epoch": 14.884135472370767,
      "grad_norm": 0.8328044414520264,
      "learning_rate": 5.03921568627451e-05,
      "loss": 0.0285,
      "step": 8350
    },
    {
      "epoch": 14.901960784313726,
      "grad_norm": 1.2633925676345825,
      "learning_rate": 5.033273915626857e-05,
      "loss": 0.0281,
      "step": 8360
    },
    {
      "epoch": 14.919786096256685,
      "grad_norm": 0.8493174314498901,
      "learning_rate": 5.027332144979204e-05,
      "loss": 0.0266,
      "step": 8370
    },
    {
      "epoch": 14.937611408199643,
      "grad_norm": 0.9755113124847412,
      "learning_rate": 5.0213903743315517e-05,
      "loss": 0.0281,
      "step": 8380
    },
    {
      "epoch": 14.955436720142602,
      "grad_norm": 0.47674036026000977,
      "learning_rate": 5.015448603683898e-05,
      "loss": 0.0286,
      "step": 8390
    },
    {
      "epoch": 14.973262032085561,
      "grad_norm": 1.6652272939682007,
      "learning_rate": 5.0095068330362446e-05,
      "loss": 0.0292,
      "step": 8400
    },
    {
      "epoch": 14.99108734402852,
      "grad_norm": 0.49962669610977173,
      "learning_rate": 5.003565062388592e-05,
      "loss": 0.0289,
      "step": 8410
    },
    {
      "epoch": 15.00891265597148,
      "grad_norm": 1.108945369720459,
      "learning_rate": 4.997623291740939e-05,
      "loss": 0.0298,
      "step": 8420
    },
    {
      "epoch": 15.026737967914439,
      "grad_norm": 0.5826912522315979,
      "learning_rate": 4.991681521093286e-05,
      "loss": 0.0272,
      "step": 8430
    },
    {
      "epoch": 15.044563279857398,
      "grad_norm": 0.5264352560043335,
      "learning_rate": 4.985739750445633e-05,
      "loss": 0.0295,
      "step": 8440
    },
    {
      "epoch": 15.062388591800357,
      "grad_norm": 0.6855195760726929,
      "learning_rate": 4.97979797979798e-05,
      "loss": 0.0259,
      "step": 8450
    },
    {
      "epoch": 15.080213903743315,
      "grad_norm": 0.9179856181144714,
      "learning_rate": 4.973856209150327e-05,
      "loss": 0.0265,
      "step": 8460
    },
    {
      "epoch": 15.098039215686274,
      "grad_norm": 0.9984775185585022,
      "learning_rate": 4.967914438502674e-05,
      "loss": 0.0297,
      "step": 8470
    },
    {
      "epoch": 15.115864527629233,
      "grad_norm": 1.1434946060180664,
      "learning_rate": 4.961972667855021e-05,
      "loss": 0.027,
      "step": 8480
    },
    {
      "epoch": 15.133689839572192,
      "grad_norm": 0.5841410160064697,
      "learning_rate": 4.956030897207368e-05,
      "loss": 0.0294,
      "step": 8490
    },
    {
      "epoch": 15.151515151515152,
      "grad_norm": 0.7268491387367249,
      "learning_rate": 4.950089126559715e-05,
      "loss": 0.0284,
      "step": 8500
    },
    {
      "epoch": 15.169340463458111,
      "grad_norm": 0.9470980763435364,
      "learning_rate": 4.9441473559120625e-05,
      "loss": 0.0265,
      "step": 8510
    },
    {
      "epoch": 15.18716577540107,
      "grad_norm": 1.3524941205978394,
      "learning_rate": 4.9382055852644086e-05,
      "loss": 0.0267,
      "step": 8520
    },
    {
      "epoch": 15.204991087344029,
      "grad_norm": 0.5194624662399292,
      "learning_rate": 4.932263814616756e-05,
      "loss": 0.0282,
      "step": 8530
    },
    {
      "epoch": 15.222816399286987,
      "grad_norm": 0.7329608798027039,
      "learning_rate": 4.926322043969103e-05,
      "loss": 0.0277,
      "step": 8540
    },
    {
      "epoch": 15.240641711229946,
      "grad_norm": 0.4558476209640503,
      "learning_rate": 4.92038027332145e-05,
      "loss": 0.028,
      "step": 8550
    },
    {
      "epoch": 15.258467023172905,
      "grad_norm": 0.7256432771682739,
      "learning_rate": 4.914438502673797e-05,
      "loss": 0.0288,
      "step": 8560
    },
    {
      "epoch": 15.276292335115864,
      "grad_norm": 0.9126253128051758,
      "learning_rate": 4.908496732026144e-05,
      "loss": 0.0283,
      "step": 8570
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 0.4746100604534149,
      "learning_rate": 4.902554961378491e-05,
      "loss": 0.0288,
      "step": 8580
    },
    {
      "epoch": 15.311942959001783,
      "grad_norm": 0.8648207187652588,
      "learning_rate": 4.8966131907308384e-05,
      "loss": 0.0281,
      "step": 8590
    },
    {
      "epoch": 15.329768270944742,
      "grad_norm": 0.45347848534584045,
      "learning_rate": 4.8906714200831846e-05,
      "loss": 0.0274,
      "step": 8600
    },
    {
      "epoch": 15.3475935828877,
      "grad_norm": 0.8837750554084778,
      "learning_rate": 4.884729649435532e-05,
      "loss": 0.0302,
      "step": 8610
    },
    {
      "epoch": 15.36541889483066,
      "grad_norm": 0.4532925486564636,
      "learning_rate": 4.878787878787879e-05,
      "loss": 0.0262,
      "step": 8620
    },
    {
      "epoch": 15.383244206773618,
      "grad_norm": 0.7974076271057129,
      "learning_rate": 4.872846108140226e-05,
      "loss": 0.0272,
      "step": 8630
    },
    {
      "epoch": 15.401069518716577,
      "grad_norm": 0.9706580638885498,
      "learning_rate": 4.866904337492573e-05,
      "loss": 0.0281,
      "step": 8640
    },
    {
      "epoch": 15.418894830659536,
      "grad_norm": 0.4215793311595917,
      "learning_rate": 4.86096256684492e-05,
      "loss": 0.0264,
      "step": 8650
    },
    {
      "epoch": 15.436720142602496,
      "grad_norm": 2.597990036010742,
      "learning_rate": 4.855020796197267e-05,
      "loss": 0.0294,
      "step": 8660
    },
    {
      "epoch": 15.454545454545455,
      "grad_norm": 0.5209372043609619,
      "learning_rate": 4.849079025549614e-05,
      "loss": 0.0264,
      "step": 8670
    },
    {
      "epoch": 15.472370766488414,
      "grad_norm": 1.085742712020874,
      "learning_rate": 4.843137254901961e-05,
      "loss": 0.0274,
      "step": 8680
    },
    {
      "epoch": 15.490196078431373,
      "grad_norm": 0.8363256454467773,
      "learning_rate": 4.837195484254308e-05,
      "loss": 0.0289,
      "step": 8690
    },
    {
      "epoch": 15.508021390374331,
      "grad_norm": 0.5556769967079163,
      "learning_rate": 4.831253713606655e-05,
      "loss": 0.0263,
      "step": 8700
    },
    {
      "epoch": 15.52584670231729,
      "grad_norm": 1.141790509223938,
      "learning_rate": 4.8253119429590024e-05,
      "loss": 0.0271,
      "step": 8710
    },
    {
      "epoch": 15.543672014260249,
      "grad_norm": 0.43784627318382263,
      "learning_rate": 4.8193701723113486e-05,
      "loss": 0.0269,
      "step": 8720
    },
    {
      "epoch": 15.56149732620321,
      "grad_norm": 0.46520623564720154,
      "learning_rate": 4.813428401663696e-05,
      "loss": 0.0292,
      "step": 8730
    },
    {
      "epoch": 15.579322638146168,
      "grad_norm": 0.3615545332431793,
      "learning_rate": 4.807486631016043e-05,
      "loss": 0.0276,
      "step": 8740
    },
    {
      "epoch": 15.597147950089127,
      "grad_norm": 0.8275666236877441,
      "learning_rate": 4.80154486036839e-05,
      "loss": 0.0286,
      "step": 8750
    },
    {
      "epoch": 15.614973262032086,
      "grad_norm": 0.5631572008132935,
      "learning_rate": 4.795603089720737e-05,
      "loss": 0.0287,
      "step": 8760
    },
    {
      "epoch": 15.632798573975045,
      "grad_norm": 0.6943029165267944,
      "learning_rate": 4.789661319073084e-05,
      "loss": 0.0284,
      "step": 8770
    },
    {
      "epoch": 15.650623885918003,
      "grad_norm": 0.6975321173667908,
      "learning_rate": 4.783719548425431e-05,
      "loss": 0.027,
      "step": 8780
    },
    {
      "epoch": 15.668449197860962,
      "grad_norm": 0.5924826860427856,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.0268,
      "step": 8790
    },
    {
      "epoch": 15.686274509803921,
      "grad_norm": 0.2591579556465149,
      "learning_rate": 4.771836007130125e-05,
      "loss": 0.0258,
      "step": 8800
    },
    {
      "epoch": 15.70409982174688,
      "grad_norm": 0.5419004559516907,
      "learning_rate": 4.765894236482472e-05,
      "loss": 0.0284,
      "step": 8810
    },
    {
      "epoch": 15.72192513368984,
      "grad_norm": 0.47448596358299255,
      "learning_rate": 4.759952465834819e-05,
      "loss": 0.028,
      "step": 8820
    },
    {
      "epoch": 15.739750445632799,
      "grad_norm": 0.582840085029602,
      "learning_rate": 4.754010695187166e-05,
      "loss": 0.0289,
      "step": 8830
    },
    {
      "epoch": 15.757575757575758,
      "grad_norm": 0.7976351976394653,
      "learning_rate": 4.748068924539513e-05,
      "loss": 0.0266,
      "step": 8840
    },
    {
      "epoch": 15.775401069518717,
      "grad_norm": 0.7405211925506592,
      "learning_rate": 4.74212715389186e-05,
      "loss": 0.0261,
      "step": 8850
    },
    {
      "epoch": 15.793226381461675,
      "grad_norm": 0.5966054201126099,
      "learning_rate": 4.736185383244207e-05,
      "loss": 0.0261,
      "step": 8860
    },
    {
      "epoch": 15.811051693404634,
      "grad_norm": 1.3054747581481934,
      "learning_rate": 4.730243612596554e-05,
      "loss": 0.0266,
      "step": 8870
    },
    {
      "epoch": 15.828877005347593,
      "grad_norm": 1.416691780090332,
      "learning_rate": 4.724301841948901e-05,
      "loss": 0.0274,
      "step": 8880
    },
    {
      "epoch": 15.846702317290553,
      "grad_norm": 0.4134822189807892,
      "learning_rate": 4.718360071301248e-05,
      "loss": 0.0266,
      "step": 8890
    },
    {
      "epoch": 15.864527629233512,
      "grad_norm": 0.7790378332138062,
      "learning_rate": 4.712418300653595e-05,
      "loss": 0.0254,
      "step": 8900
    },
    {
      "epoch": 15.882352941176471,
      "grad_norm": 0.7815808057785034,
      "learning_rate": 4.7064765300059424e-05,
      "loss": 0.0275,
      "step": 8910
    },
    {
      "epoch": 15.90017825311943,
      "grad_norm": 0.7360155582427979,
      "learning_rate": 4.7005347593582885e-05,
      "loss": 0.0278,
      "step": 8920
    },
    {
      "epoch": 15.918003565062389,
      "grad_norm": 0.7635460495948792,
      "learning_rate": 4.694592988710636e-05,
      "loss": 0.028,
      "step": 8930
    },
    {
      "epoch": 15.935828877005347,
      "grad_norm": 2.3518502712249756,
      "learning_rate": 4.6886512180629836e-05,
      "loss": 0.0285,
      "step": 8940
    },
    {
      "epoch": 15.953654188948306,
      "grad_norm": 0.8757399320602417,
      "learning_rate": 4.68270944741533e-05,
      "loss": 0.0262,
      "step": 8950
    },
    {
      "epoch": 15.971479500891265,
      "grad_norm": 0.8699652552604675,
      "learning_rate": 4.676767676767677e-05,
      "loss": 0.0274,
      "step": 8960
    },
    {
      "epoch": 15.989304812834224,
      "grad_norm": 0.7808934450149536,
      "learning_rate": 4.670825906120024e-05,
      "loss": 0.0268,
      "step": 8970
    },
    {
      "epoch": 16.007130124777184,
      "grad_norm": 0.5840015411376953,
      "learning_rate": 4.664884135472371e-05,
      "loss": 0.0257,
      "step": 8980
    },
    {
      "epoch": 16.02495543672014,
      "grad_norm": 1.0427757501602173,
      "learning_rate": 4.6589423648247184e-05,
      "loss": 0.0267,
      "step": 8990
    },
    {
      "epoch": 16.0427807486631,
      "grad_norm": 1.4360402822494507,
      "learning_rate": 4.653000594177065e-05,
      "loss": 0.0272,
      "step": 9000
    },
    {
      "epoch": 16.060606060606062,
      "grad_norm": 0.6259732246398926,
      "learning_rate": 4.647058823529412e-05,
      "loss": 0.0276,
      "step": 9010
    },
    {
      "epoch": 16.07843137254902,
      "grad_norm": 0.9725059270858765,
      "learning_rate": 4.641117052881759e-05,
      "loss": 0.0279,
      "step": 9020
    },
    {
      "epoch": 16.09625668449198,
      "grad_norm": 2.0129358768463135,
      "learning_rate": 4.635175282234106e-05,
      "loss": 0.0274,
      "step": 9030
    },
    {
      "epoch": 16.114081996434937,
      "grad_norm": 0.7298811078071594,
      "learning_rate": 4.629233511586453e-05,
      "loss": 0.0272,
      "step": 9040
    },
    {
      "epoch": 16.131907308377897,
      "grad_norm": 0.7360751032829285,
      "learning_rate": 4.6232917409388e-05,
      "loss": 0.0283,
      "step": 9050
    },
    {
      "epoch": 16.149732620320854,
      "grad_norm": 0.5803556442260742,
      "learning_rate": 4.617349970291147e-05,
      "loss": 0.0288,
      "step": 9060
    },
    {
      "epoch": 16.167557932263815,
      "grad_norm": 0.7882634401321411,
      "learning_rate": 4.611408199643494e-05,
      "loss": 0.0271,
      "step": 9070
    },
    {
      "epoch": 16.185383244206772,
      "grad_norm": 0.7035282254219055,
      "learning_rate": 4.605466428995841e-05,
      "loss": 0.0268,
      "step": 9080
    },
    {
      "epoch": 16.203208556149733,
      "grad_norm": 0.8173103332519531,
      "learning_rate": 4.599524658348188e-05,
      "loss": 0.0275,
      "step": 9090
    },
    {
      "epoch": 16.221033868092693,
      "grad_norm": 0.4775998890399933,
      "learning_rate": 4.593582887700535e-05,
      "loss": 0.0272,
      "step": 9100
    },
    {
      "epoch": 16.23885918003565,
      "grad_norm": 0.5571954846382141,
      "learning_rate": 4.5876411170528824e-05,
      "loss": 0.027,
      "step": 9110
    },
    {
      "epoch": 16.25668449197861,
      "grad_norm": 0.9573922753334045,
      "learning_rate": 4.5816993464052285e-05,
      "loss": 0.0284,
      "step": 9120
    },
    {
      "epoch": 16.274509803921568,
      "grad_norm": 0.6944794654846191,
      "learning_rate": 4.575757575757576e-05,
      "loss": 0.0274,
      "step": 9130
    },
    {
      "epoch": 16.292335115864528,
      "grad_norm": 1.3749030828475952,
      "learning_rate": 4.5698158051099235e-05,
      "loss": 0.0292,
      "step": 9140
    },
    {
      "epoch": 16.310160427807485,
      "grad_norm": 0.43381693959236145,
      "learning_rate": 4.56387403446227e-05,
      "loss": 0.0282,
      "step": 9150
    },
    {
      "epoch": 16.327985739750446,
      "grad_norm": 0.7674769163131714,
      "learning_rate": 4.557932263814617e-05,
      "loss": 0.0278,
      "step": 9160
    },
    {
      "epoch": 16.345811051693406,
      "grad_norm": 0.6920937895774841,
      "learning_rate": 4.551990493166964e-05,
      "loss": 0.027,
      "step": 9170
    },
    {
      "epoch": 16.363636363636363,
      "grad_norm": 0.5835521817207336,
      "learning_rate": 4.546048722519311e-05,
      "loss": 0.0283,
      "step": 9180
    },
    {
      "epoch": 16.381461675579324,
      "grad_norm": 0.5826562643051147,
      "learning_rate": 4.5401069518716583e-05,
      "loss": 0.0263,
      "step": 9190
    },
    {
      "epoch": 16.39928698752228,
      "grad_norm": 0.23534925282001495,
      "learning_rate": 4.534165181224005e-05,
      "loss": 0.0249,
      "step": 9200
    },
    {
      "epoch": 16.41711229946524,
      "grad_norm": 0.4965856075286865,
      "learning_rate": 4.528223410576352e-05,
      "loss": 0.0273,
      "step": 9210
    },
    {
      "epoch": 16.4349376114082,
      "grad_norm": 0.45233917236328125,
      "learning_rate": 4.522281639928699e-05,
      "loss": 0.026,
      "step": 9220
    },
    {
      "epoch": 16.45276292335116,
      "grad_norm": 0.6074212193489075,
      "learning_rate": 4.516339869281046e-05,
      "loss": 0.0262,
      "step": 9230
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 0.9764536619186401,
      "learning_rate": 4.510398098633393e-05,
      "loss": 0.0271,
      "step": 9240
    },
    {
      "epoch": 16.488413547237077,
      "grad_norm": 0.6091023087501526,
      "learning_rate": 4.50445632798574e-05,
      "loss": 0.0262,
      "step": 9250
    },
    {
      "epoch": 16.506238859180037,
      "grad_norm": 0.724192202091217,
      "learning_rate": 4.498514557338087e-05,
      "loss": 0.0255,
      "step": 9260
    },
    {
      "epoch": 16.524064171122994,
      "grad_norm": 0.9869711399078369,
      "learning_rate": 4.4925727866904337e-05,
      "loss": 0.0288,
      "step": 9270
    },
    {
      "epoch": 16.541889483065955,
      "grad_norm": 0.6537941694259644,
      "learning_rate": 4.486631016042781e-05,
      "loss": 0.0264,
      "step": 9280
    },
    {
      "epoch": 16.55971479500891,
      "grad_norm": 0.5977752208709717,
      "learning_rate": 4.480689245395128e-05,
      "loss": 0.0278,
      "step": 9290
    },
    {
      "epoch": 16.577540106951872,
      "grad_norm": 0.3959306478500366,
      "learning_rate": 4.474747474747475e-05,
      "loss": 0.0256,
      "step": 9300
    },
    {
      "epoch": 16.59536541889483,
      "grad_norm": 0.37480103969573975,
      "learning_rate": 4.468805704099822e-05,
      "loss": 0.0262,
      "step": 9310
    },
    {
      "epoch": 16.61319073083779,
      "grad_norm": 0.7893669009208679,
      "learning_rate": 4.4628639334521685e-05,
      "loss": 0.0258,
      "step": 9320
    },
    {
      "epoch": 16.63101604278075,
      "grad_norm": 0.8498334288597107,
      "learning_rate": 4.456922162804516e-05,
      "loss": 0.0264,
      "step": 9330
    },
    {
      "epoch": 16.648841354723707,
      "grad_norm": 1.1165121793746948,
      "learning_rate": 4.450980392156863e-05,
      "loss": 0.0267,
      "step": 9340
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.7950716614723206,
      "learning_rate": 4.4450386215092096e-05,
      "loss": 0.0267,
      "step": 9350
    },
    {
      "epoch": 16.684491978609625,
      "grad_norm": 0.7872686982154846,
      "learning_rate": 4.439096850861557e-05,
      "loss": 0.0264,
      "step": 9360
    },
    {
      "epoch": 16.702317290552585,
      "grad_norm": 0.5678329467773438,
      "learning_rate": 4.433155080213904e-05,
      "loss": 0.0269,
      "step": 9370
    },
    {
      "epoch": 16.720142602495542,
      "grad_norm": 0.5947619080543518,
      "learning_rate": 4.427213309566251e-05,
      "loss": 0.0256,
      "step": 9380
    },
    {
      "epoch": 16.737967914438503,
      "grad_norm": 0.4932193160057068,
      "learning_rate": 4.4212715389185976e-05,
      "loss": 0.0262,
      "step": 9390
    },
    {
      "epoch": 16.75579322638146,
      "grad_norm": 0.5875203609466553,
      "learning_rate": 4.415329768270945e-05,
      "loss": 0.0274,
      "step": 9400
    },
    {
      "epoch": 16.77361853832442,
      "grad_norm": 0.3835238814353943,
      "learning_rate": 4.409387997623292e-05,
      "loss": 0.0282,
      "step": 9410
    },
    {
      "epoch": 16.79144385026738,
      "grad_norm": 0.559862494468689,
      "learning_rate": 4.403446226975639e-05,
      "loss": 0.0253,
      "step": 9420
    },
    {
      "epoch": 16.809269162210338,
      "grad_norm": 0.5974767208099365,
      "learning_rate": 4.397504456327986e-05,
      "loss": 0.0246,
      "step": 9430
    },
    {
      "epoch": 16.8270944741533,
      "grad_norm": 1.4184696674346924,
      "learning_rate": 4.3915626856803325e-05,
      "loss": 0.0264,
      "step": 9440
    },
    {
      "epoch": 16.844919786096256,
      "grad_norm": 0.5141745209693909,
      "learning_rate": 4.38562091503268e-05,
      "loss": 0.0265,
      "step": 9450
    },
    {
      "epoch": 16.862745098039216,
      "grad_norm": 0.7622422575950623,
      "learning_rate": 4.3796791443850275e-05,
      "loss": 0.0267,
      "step": 9460
    },
    {
      "epoch": 16.880570409982173,
      "grad_norm": 0.7738347053527832,
      "learning_rate": 4.3737373737373736e-05,
      "loss": 0.0264,
      "step": 9470
    },
    {
      "epoch": 16.898395721925134,
      "grad_norm": 0.8251941204071045,
      "learning_rate": 4.367795603089721e-05,
      "loss": 0.0273,
      "step": 9480
    },
    {
      "epoch": 16.916221033868094,
      "grad_norm": 0.612166702747345,
      "learning_rate": 4.361853832442068e-05,
      "loss": 0.0272,
      "step": 9490
    },
    {
      "epoch": 16.93404634581105,
      "grad_norm": 0.4498738646507263,
      "learning_rate": 4.355912061794415e-05,
      "loss": 0.0267,
      "step": 9500
    },
    {
      "epoch": 16.951871657754012,
      "grad_norm": 0.35009393095970154,
      "learning_rate": 4.349970291146762e-05,
      "loss": 0.0265,
      "step": 9510
    },
    {
      "epoch": 16.96969696969697,
      "grad_norm": 0.6412374973297119,
      "learning_rate": 4.344028520499109e-05,
      "loss": 0.0274,
      "step": 9520
    },
    {
      "epoch": 16.98752228163993,
      "grad_norm": 0.41046950221061707,
      "learning_rate": 4.338086749851456e-05,
      "loss": 0.0241,
      "step": 9530
    },
    {
      "epoch": 17.005347593582886,
      "grad_norm": 0.8473759293556213,
      "learning_rate": 4.332144979203803e-05,
      "loss": 0.0263,
      "step": 9540
    },
    {
      "epoch": 17.023172905525847,
      "grad_norm": 1.1305407285690308,
      "learning_rate": 4.3262032085561496e-05,
      "loss": 0.025,
      "step": 9550
    },
    {
      "epoch": 17.040998217468804,
      "grad_norm": 0.4744156002998352,
      "learning_rate": 4.320261437908497e-05,
      "loss": 0.0257,
      "step": 9560
    },
    {
      "epoch": 17.058823529411764,
      "grad_norm": 1.3614563941955566,
      "learning_rate": 4.314319667260844e-05,
      "loss": 0.0267,
      "step": 9570
    },
    {
      "epoch": 17.076648841354725,
      "grad_norm": 0.8867163062095642,
      "learning_rate": 4.308377896613191e-05,
      "loss": 0.0263,
      "step": 9580
    },
    {
      "epoch": 17.094474153297682,
      "grad_norm": 1.1024004220962524,
      "learning_rate": 4.3024361259655376e-05,
      "loss": 0.027,
      "step": 9590
    },
    {
      "epoch": 17.112299465240643,
      "grad_norm": 0.6770141124725342,
      "learning_rate": 4.296494355317885e-05,
      "loss": 0.0262,
      "step": 9600
    },
    {
      "epoch": 17.1301247771836,
      "grad_norm": 0.5123521089553833,
      "learning_rate": 4.290552584670232e-05,
      "loss": 0.0267,
      "step": 9610
    },
    {
      "epoch": 17.14795008912656,
      "grad_norm": 0.624774158000946,
      "learning_rate": 4.284610814022579e-05,
      "loss": 0.0251,
      "step": 9620
    },
    {
      "epoch": 17.165775401069517,
      "grad_norm": 0.8285225629806519,
      "learning_rate": 4.278669043374926e-05,
      "loss": 0.0252,
      "step": 9630
    },
    {
      "epoch": 17.183600713012478,
      "grad_norm": 0.486530065536499,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 0.0262,
      "step": 9640
    },
    {
      "epoch": 17.20142602495544,
      "grad_norm": 0.6277625560760498,
      "learning_rate": 4.26678550207962e-05,
      "loss": 0.0252,
      "step": 9650
    },
    {
      "epoch": 17.219251336898395,
      "grad_norm": 1.0635684728622437,
      "learning_rate": 4.2608437314319674e-05,
      "loss": 0.0262,
      "step": 9660
    },
    {
      "epoch": 17.237076648841356,
      "grad_norm": 0.46508005261421204,
      "learning_rate": 4.2549019607843136e-05,
      "loss": 0.026,
      "step": 9670
    },
    {
      "epoch": 17.254901960784313,
      "grad_norm": 0.7287541031837463,
      "learning_rate": 4.248960190136661e-05,
      "loss": 0.0259,
      "step": 9680
    },
    {
      "epoch": 17.272727272727273,
      "grad_norm": 1.0217127799987793,
      "learning_rate": 4.243018419489008e-05,
      "loss": 0.0248,
      "step": 9690
    },
    {
      "epoch": 17.29055258467023,
      "grad_norm": 1.015904188156128,
      "learning_rate": 4.237076648841355e-05,
      "loss": 0.026,
      "step": 9700
    },
    {
      "epoch": 17.30837789661319,
      "grad_norm": 0.7519025206565857,
      "learning_rate": 4.231134878193702e-05,
      "loss": 0.0262,
      "step": 9710
    },
    {
      "epoch": 17.32620320855615,
      "grad_norm": 0.6075946688652039,
      "learning_rate": 4.225193107546049e-05,
      "loss": 0.0295,
      "step": 9720
    },
    {
      "epoch": 17.34402852049911,
      "grad_norm": 0.900780975818634,
      "learning_rate": 4.219251336898396e-05,
      "loss": 0.0273,
      "step": 9730
    },
    {
      "epoch": 17.36185383244207,
      "grad_norm": 0.6112026572227478,
      "learning_rate": 4.213309566250743e-05,
      "loss": 0.0255,
      "step": 9740
    },
    {
      "epoch": 17.379679144385026,
      "grad_norm": 0.7037508487701416,
      "learning_rate": 4.20736779560309e-05,
      "loss": 0.0265,
      "step": 9750
    },
    {
      "epoch": 17.397504456327987,
      "grad_norm": 0.40877193212509155,
      "learning_rate": 4.201426024955437e-05,
      "loss": 0.0281,
      "step": 9760
    },
    {
      "epoch": 17.415329768270944,
      "grad_norm": 0.9733580946922302,
      "learning_rate": 4.195484254307784e-05,
      "loss": 0.0256,
      "step": 9770
    },
    {
      "epoch": 17.433155080213904,
      "grad_norm": 0.6133554577827454,
      "learning_rate": 4.189542483660131e-05,
      "loss": 0.025,
      "step": 9780
    },
    {
      "epoch": 17.45098039215686,
      "grad_norm": 0.6233395934104919,
      "learning_rate": 4.1836007130124776e-05,
      "loss": 0.0268,
      "step": 9790
    },
    {
      "epoch": 17.46880570409982,
      "grad_norm": 0.44923537969589233,
      "learning_rate": 4.177658942364825e-05,
      "loss": 0.0268,
      "step": 9800
    },
    {
      "epoch": 17.486631016042782,
      "grad_norm": 0.6039384007453918,
      "learning_rate": 4.171717171717172e-05,
      "loss": 0.0253,
      "step": 9810
    },
    {
      "epoch": 17.50445632798574,
      "grad_norm": 0.6088995337486267,
      "learning_rate": 4.165775401069519e-05,
      "loss": 0.0259,
      "step": 9820
    },
    {
      "epoch": 17.5222816399287,
      "grad_norm": 0.5176980495452881,
      "learning_rate": 4.159833630421866e-05,
      "loss": 0.0244,
      "step": 9830
    },
    {
      "epoch": 17.540106951871657,
      "grad_norm": 1.1974263191223145,
      "learning_rate": 4.1538918597742124e-05,
      "loss": 0.0244,
      "step": 9840
    },
    {
      "epoch": 17.557932263814617,
      "grad_norm": 1.3912607431411743,
      "learning_rate": 4.14795008912656e-05,
      "loss": 0.0265,
      "step": 9850
    },
    {
      "epoch": 17.575757575757574,
      "grad_norm": 0.6416959166526794,
      "learning_rate": 4.1420083184789074e-05,
      "loss": 0.0248,
      "step": 9860
    },
    {
      "epoch": 17.593582887700535,
      "grad_norm": 0.8430569171905518,
      "learning_rate": 4.1360665478312535e-05,
      "loss": 0.0258,
      "step": 9870
    },
    {
      "epoch": 17.611408199643495,
      "grad_norm": 0.651842474937439,
      "learning_rate": 4.130124777183601e-05,
      "loss": 0.0262,
      "step": 9880
    },
    {
      "epoch": 17.629233511586452,
      "grad_norm": 0.7249665856361389,
      "learning_rate": 4.124183006535948e-05,
      "loss": 0.0255,
      "step": 9890
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 1.3510794639587402,
      "learning_rate": 4.118241235888295e-05,
      "loss": 0.0269,
      "step": 9900
    },
    {
      "epoch": 17.66488413547237,
      "grad_norm": 0.7595944404602051,
      "learning_rate": 4.112299465240642e-05,
      "loss": 0.0259,
      "step": 9910
    },
    {
      "epoch": 17.68270944741533,
      "grad_norm": 0.852104663848877,
      "learning_rate": 4.106357694592989e-05,
      "loss": 0.0251,
      "step": 9920
    },
    {
      "epoch": 17.700534759358288,
      "grad_norm": 0.6115333437919617,
      "learning_rate": 4.100415923945336e-05,
      "loss": 0.0245,
      "step": 9930
    },
    {
      "epoch": 17.718360071301248,
      "grad_norm": 0.5991603136062622,
      "learning_rate": 4.094474153297683e-05,
      "loss": 0.0269,
      "step": 9940
    },
    {
      "epoch": 17.736185383244205,
      "grad_norm": 0.4367455840110779,
      "learning_rate": 4.08853238265003e-05,
      "loss": 0.0257,
      "step": 9950
    },
    {
      "epoch": 17.754010695187166,
      "grad_norm": 0.633345365524292,
      "learning_rate": 4.082590612002377e-05,
      "loss": 0.0263,
      "step": 9960
    },
    {
      "epoch": 17.771836007130126,
      "grad_norm": 0.4685659408569336,
      "learning_rate": 4.076648841354724e-05,
      "loss": 0.0264,
      "step": 9970
    },
    {
      "epoch": 17.789661319073083,
      "grad_norm": 0.439647376537323,
      "learning_rate": 4.070707070707071e-05,
      "loss": 0.0268,
      "step": 9980
    },
    {
      "epoch": 17.807486631016044,
      "grad_norm": 0.859722375869751,
      "learning_rate": 4.0647653000594175e-05,
      "loss": 0.0268,
      "step": 9990
    },
    {
      "epoch": 17.825311942959,
      "grad_norm": 1.3957692384719849,
      "learning_rate": 4.058823529411765e-05,
      "loss": 0.0277,
      "step": 10000
    },
    {
      "epoch": 17.84313725490196,
      "grad_norm": 0.9698938131332397,
      "learning_rate": 4.052881758764112e-05,
      "loss": 0.0249,
      "step": 10010
    },
    {
      "epoch": 17.86096256684492,
      "grad_norm": 0.46053820848464966,
      "learning_rate": 4.046939988116459e-05,
      "loss": 0.0253,
      "step": 10020
    },
    {
      "epoch": 17.87878787878788,
      "grad_norm": 0.41921091079711914,
      "learning_rate": 4.040998217468806e-05,
      "loss": 0.0255,
      "step": 10030
    },
    {
      "epoch": 17.89661319073084,
      "grad_norm": 0.6888728737831116,
      "learning_rate": 4.035056446821153e-05,
      "loss": 0.0254,
      "step": 10040
    },
    {
      "epoch": 17.914438502673796,
      "grad_norm": 0.44873085618019104,
      "learning_rate": 4.0291146761735e-05,
      "loss": 0.0251,
      "step": 10050
    },
    {
      "epoch": 17.932263814616757,
      "grad_norm": 0.5868633985519409,
      "learning_rate": 4.0231729055258474e-05,
      "loss": 0.0258,
      "step": 10060
    },
    {
      "epoch": 17.950089126559714,
      "grad_norm": 0.4470776915550232,
      "learning_rate": 4.0172311348781935e-05,
      "loss": 0.0253,
      "step": 10070
    },
    {
      "epoch": 17.967914438502675,
      "grad_norm": 1.231937050819397,
      "learning_rate": 4.011289364230541e-05,
      "loss": 0.026,
      "step": 10080
    },
    {
      "epoch": 17.98573975044563,
      "grad_norm": 0.9529017806053162,
      "learning_rate": 4.005347593582888e-05,
      "loss": 0.0254,
      "step": 10090
    },
    {
      "epoch": 18.003565062388592,
      "grad_norm": 0.6412417888641357,
      "learning_rate": 3.999405822935235e-05,
      "loss": 0.0268,
      "step": 10100
    },
    {
      "epoch": 18.02139037433155,
      "grad_norm": 0.38953956961631775,
      "learning_rate": 3.993464052287582e-05,
      "loss": 0.026,
      "step": 10110
    },
    {
      "epoch": 18.03921568627451,
      "grad_norm": 1.089420199394226,
      "learning_rate": 3.987522281639929e-05,
      "loss": 0.0271,
      "step": 10120
    },
    {
      "epoch": 18.05704099821747,
      "grad_norm": 0.5801612734794617,
      "learning_rate": 3.981580510992276e-05,
      "loss": 0.0257,
      "step": 10130
    },
    {
      "epoch": 18.074866310160427,
      "grad_norm": 0.7090698480606079,
      "learning_rate": 3.975638740344623e-05,
      "loss": 0.0251,
      "step": 10140
    },
    {
      "epoch": 18.092691622103388,
      "grad_norm": 1.1540173292160034,
      "learning_rate": 3.96969696969697e-05,
      "loss": 0.0248,
      "step": 10150
    },
    {
      "epoch": 18.110516934046345,
      "grad_norm": 0.7315216064453125,
      "learning_rate": 3.963755199049317e-05,
      "loss": 0.0262,
      "step": 10160
    },
    {
      "epoch": 18.128342245989305,
      "grad_norm": 0.3274047076702118,
      "learning_rate": 3.957813428401664e-05,
      "loss": 0.0249,
      "step": 10170
    },
    {
      "epoch": 18.146167557932262,
      "grad_norm": 0.6493367552757263,
      "learning_rate": 3.951871657754011e-05,
      "loss": 0.0256,
      "step": 10180
    },
    {
      "epoch": 18.163992869875223,
      "grad_norm": 1.0073095560073853,
      "learning_rate": 3.9459298871063575e-05,
      "loss": 0.0266,
      "step": 10190
    },
    {
      "epoch": 18.181818181818183,
      "grad_norm": 0.5578627586364746,
      "learning_rate": 3.939988116458705e-05,
      "loss": 0.0269,
      "step": 10200
    },
    {
      "epoch": 18.19964349376114,
      "grad_norm": 1.0820508003234863,
      "learning_rate": 3.934046345811052e-05,
      "loss": 0.0258,
      "step": 10210
    },
    {
      "epoch": 18.2174688057041,
      "grad_norm": 0.400304913520813,
      "learning_rate": 3.9281045751633986e-05,
      "loss": 0.0254,
      "step": 10220
    },
    {
      "epoch": 18.235294117647058,
      "grad_norm": 0.4683135449886322,
      "learning_rate": 3.922162804515746e-05,
      "loss": 0.0262,
      "step": 10230
    },
    {
      "epoch": 18.25311942959002,
      "grad_norm": 0.6346989274024963,
      "learning_rate": 3.916221033868093e-05,
      "loss": 0.0253,
      "step": 10240
    },
    {
      "epoch": 18.270944741532976,
      "grad_norm": 0.3289901316165924,
      "learning_rate": 3.91027926322044e-05,
      "loss": 0.0243,
      "step": 10250
    },
    {
      "epoch": 18.288770053475936,
      "grad_norm": 0.5161139965057373,
      "learning_rate": 3.904337492572787e-05,
      "loss": 0.0253,
      "step": 10260
    },
    {
      "epoch": 18.306595365418893,
      "grad_norm": 0.43081915378570557,
      "learning_rate": 3.8983957219251335e-05,
      "loss": 0.0249,
      "step": 10270
    },
    {
      "epoch": 18.324420677361854,
      "grad_norm": 0.5399149060249329,
      "learning_rate": 3.892453951277481e-05,
      "loss": 0.0261,
      "step": 10280
    },
    {
      "epoch": 18.342245989304814,
      "grad_norm": 0.3620047867298126,
      "learning_rate": 3.886512180629828e-05,
      "loss": 0.025,
      "step": 10290
    },
    {
      "epoch": 18.36007130124777,
      "grad_norm": 0.4183712601661682,
      "learning_rate": 3.8805704099821746e-05,
      "loss": 0.0246,
      "step": 10300
    },
    {
      "epoch": 18.37789661319073,
      "grad_norm": 0.4299546778202057,
      "learning_rate": 3.874628639334522e-05,
      "loss": 0.0239,
      "step": 10310
    },
    {
      "epoch": 18.39572192513369,
      "grad_norm": 0.9064761400222778,
      "learning_rate": 3.868686868686869e-05,
      "loss": 0.0261,
      "step": 10320
    },
    {
      "epoch": 18.41354723707665,
      "grad_norm": 0.7670426368713379,
      "learning_rate": 3.862745098039216e-05,
      "loss": 0.0257,
      "step": 10330
    },
    {
      "epoch": 18.431372549019606,
      "grad_norm": 1.4328285455703735,
      "learning_rate": 3.8568033273915626e-05,
      "loss": 0.0263,
      "step": 10340
    },
    {
      "epoch": 18.449197860962567,
      "grad_norm": 0.2878946363925934,
      "learning_rate": 3.85086155674391e-05,
      "loss": 0.0247,
      "step": 10350
    },
    {
      "epoch": 18.467023172905527,
      "grad_norm": 0.5022019147872925,
      "learning_rate": 3.844919786096257e-05,
      "loss": 0.0262,
      "step": 10360
    },
    {
      "epoch": 18.484848484848484,
      "grad_norm": 0.6321811079978943,
      "learning_rate": 3.838978015448604e-05,
      "loss": 0.025,
      "step": 10370
    },
    {
      "epoch": 18.502673796791445,
      "grad_norm": 0.4156877398490906,
      "learning_rate": 3.833036244800951e-05,
      "loss": 0.024,
      "step": 10380
    },
    {
      "epoch": 18.520499108734402,
      "grad_norm": 0.45135462284088135,
      "learning_rate": 3.8270944741532975e-05,
      "loss": 0.0259,
      "step": 10390
    },
    {
      "epoch": 18.538324420677363,
      "grad_norm": 0.49781978130340576,
      "learning_rate": 3.821152703505645e-05,
      "loss": 0.0253,
      "step": 10400
    },
    {
      "epoch": 18.55614973262032,
      "grad_norm": 0.46150392293930054,
      "learning_rate": 3.8152109328579925e-05,
      "loss": 0.0261,
      "step": 10410
    },
    {
      "epoch": 18.57397504456328,
      "grad_norm": 0.7400155663490295,
      "learning_rate": 3.8092691622103386e-05,
      "loss": 0.025,
      "step": 10420
    },
    {
      "epoch": 18.59180035650624,
      "grad_norm": 0.4766625463962555,
      "learning_rate": 3.803327391562686e-05,
      "loss": 0.0263,
      "step": 10430
    },
    {
      "epoch": 18.609625668449198,
      "grad_norm": 0.7204949855804443,
      "learning_rate": 3.797385620915033e-05,
      "loss": 0.0257,
      "step": 10440
    },
    {
      "epoch": 18.627450980392158,
      "grad_norm": 1.036949634552002,
      "learning_rate": 3.79144385026738e-05,
      "loss": 0.0253,
      "step": 10450
    },
    {
      "epoch": 18.645276292335115,
      "grad_norm": 0.5246556997299194,
      "learning_rate": 3.7855020796197266e-05,
      "loss": 0.0249,
      "step": 10460
    },
    {
      "epoch": 18.663101604278076,
      "grad_norm": 0.7674620747566223,
      "learning_rate": 3.779560308972074e-05,
      "loss": 0.0243,
      "step": 10470
    },
    {
      "epoch": 18.680926916221033,
      "grad_norm": 0.8085008859634399,
      "learning_rate": 3.773618538324421e-05,
      "loss": 0.0252,
      "step": 10480
    },
    {
      "epoch": 18.698752228163993,
      "grad_norm": 1.0411696434020996,
      "learning_rate": 3.767676767676768e-05,
      "loss": 0.0252,
      "step": 10490
    },
    {
      "epoch": 18.71657754010695,
      "grad_norm": 1.4428812265396118,
      "learning_rate": 3.7617349970291146e-05,
      "loss": 0.0261,
      "step": 10500
    },
    {
      "epoch": 18.73440285204991,
      "grad_norm": 0.5699519515037537,
      "learning_rate": 3.7557932263814614e-05,
      "loss": 0.026,
      "step": 10510
    },
    {
      "epoch": 18.75222816399287,
      "grad_norm": 0.5814452171325684,
      "learning_rate": 3.749851455733809e-05,
      "loss": 0.0259,
      "step": 10520
    },
    {
      "epoch": 18.77005347593583,
      "grad_norm": 0.8087081909179688,
      "learning_rate": 3.743909685086156e-05,
      "loss": 0.0251,
      "step": 10530
    },
    {
      "epoch": 18.78787878787879,
      "grad_norm": 0.6155584454536438,
      "learning_rate": 3.7379679144385026e-05,
      "loss": 0.0234,
      "step": 10540
    },
    {
      "epoch": 18.805704099821746,
      "grad_norm": 0.7580660581588745,
      "learning_rate": 3.73202614379085e-05,
      "loss": 0.0246,
      "step": 10550
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 0.5392400026321411,
      "learning_rate": 3.726084373143196e-05,
      "loss": 0.0247,
      "step": 10560
    },
    {
      "epoch": 18.841354723707664,
      "grad_norm": 0.6142159700393677,
      "learning_rate": 3.720142602495544e-05,
      "loss": 0.0261,
      "step": 10570
    },
    {
      "epoch": 18.859180035650624,
      "grad_norm": 0.4324393570423126,
      "learning_rate": 3.714200831847891e-05,
      "loss": 0.0247,
      "step": 10580
    },
    {
      "epoch": 18.87700534759358,
      "grad_norm": 0.2935577929019928,
      "learning_rate": 3.7082590612002374e-05,
      "loss": 0.0236,
      "step": 10590
    },
    {
      "epoch": 18.89483065953654,
      "grad_norm": 0.9301785826683044,
      "learning_rate": 3.702317290552585e-05,
      "loss": 0.0251,
      "step": 10600
    },
    {
      "epoch": 18.912655971479502,
      "grad_norm": 0.6577973961830139,
      "learning_rate": 3.696375519904932e-05,
      "loss": 0.0248,
      "step": 10610
    },
    {
      "epoch": 18.93048128342246,
      "grad_norm": 0.545606791973114,
      "learning_rate": 3.6904337492572786e-05,
      "loss": 0.0251,
      "step": 10620
    },
    {
      "epoch": 18.94830659536542,
      "grad_norm": 0.5175794363021851,
      "learning_rate": 3.684491978609626e-05,
      "loss": 0.0255,
      "step": 10630
    },
    {
      "epoch": 18.966131907308377,
      "grad_norm": 0.39776477217674255,
      "learning_rate": 3.678550207961973e-05,
      "loss": 0.0254,
      "step": 10640
    },
    {
      "epoch": 18.983957219251337,
      "grad_norm": 0.4000311493873596,
      "learning_rate": 3.67260843731432e-05,
      "loss": 0.0244,
      "step": 10650
    },
    {
      "epoch": 19.001782531194294,
      "grad_norm": 0.5133146643638611,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0258,
      "step": 10660
    },
    {
      "epoch": 19.019607843137255,
      "grad_norm": 0.9487096071243286,
      "learning_rate": 3.660724896019014e-05,
      "loss": 0.0256,
      "step": 10670
    },
    {
      "epoch": 19.037433155080215,
      "grad_norm": 1.1060683727264404,
      "learning_rate": 3.654783125371361e-05,
      "loss": 0.0237,
      "step": 10680
    },
    {
      "epoch": 19.055258467023172,
      "grad_norm": 0.5540270209312439,
      "learning_rate": 3.648841354723708e-05,
      "loss": 0.0249,
      "step": 10690
    },
    {
      "epoch": 19.073083778966133,
      "grad_norm": 0.6953055262565613,
      "learning_rate": 3.642899584076055e-05,
      "loss": 0.0238,
      "step": 10700
    },
    {
      "epoch": 19.09090909090909,
      "grad_norm": 0.5320122838020325,
      "learning_rate": 3.6369578134284014e-05,
      "loss": 0.0249,
      "step": 10710
    },
    {
      "epoch": 19.10873440285205,
      "grad_norm": 0.27160143852233887,
      "learning_rate": 3.631016042780749e-05,
      "loss": 0.0245,
      "step": 10720
    },
    {
      "epoch": 19.126559714795007,
      "grad_norm": 0.8817702531814575,
      "learning_rate": 3.625074272133096e-05,
      "loss": 0.0242,
      "step": 10730
    },
    {
      "epoch": 19.144385026737968,
      "grad_norm": 0.8441228270530701,
      "learning_rate": 3.6191325014854426e-05,
      "loss": 0.0245,
      "step": 10740
    },
    {
      "epoch": 19.16221033868093,
      "grad_norm": 0.6065970659255981,
      "learning_rate": 3.61319073083779e-05,
      "loss": 0.0246,
      "step": 10750
    },
    {
      "epoch": 19.180035650623886,
      "grad_norm": 1.101786732673645,
      "learning_rate": 3.607248960190137e-05,
      "loss": 0.0247,
      "step": 10760
    },
    {
      "epoch": 19.197860962566846,
      "grad_norm": 0.9176590442657471,
      "learning_rate": 3.601307189542484e-05,
      "loss": 0.025,
      "step": 10770
    },
    {
      "epoch": 19.215686274509803,
      "grad_norm": 0.855024516582489,
      "learning_rate": 3.595365418894831e-05,
      "loss": 0.0249,
      "step": 10780
    },
    {
      "epoch": 19.233511586452764,
      "grad_norm": 1.157368779182434,
      "learning_rate": 3.5894236482471774e-05,
      "loss": 0.0249,
      "step": 10790
    },
    {
      "epoch": 19.25133689839572,
      "grad_norm": 0.43548259139060974,
      "learning_rate": 3.583481877599525e-05,
      "loss": 0.0248,
      "step": 10800
    },
    {
      "epoch": 19.26916221033868,
      "grad_norm": 0.4999942481517792,
      "learning_rate": 3.577540106951872e-05,
      "loss": 0.0236,
      "step": 10810
    },
    {
      "epoch": 19.28698752228164,
      "grad_norm": 0.4432453513145447,
      "learning_rate": 3.5715983363042185e-05,
      "loss": 0.0242,
      "step": 10820
    },
    {
      "epoch": 19.3048128342246,
      "grad_norm": 0.4902016520500183,
      "learning_rate": 3.565656565656566e-05,
      "loss": 0.0246,
      "step": 10830
    },
    {
      "epoch": 19.32263814616756,
      "grad_norm": 0.8593481779098511,
      "learning_rate": 3.559714795008913e-05,
      "loss": 0.0251,
      "step": 10840
    },
    {
      "epoch": 19.340463458110516,
      "grad_norm": 0.6263498663902283,
      "learning_rate": 3.55377302436126e-05,
      "loss": 0.0237,
      "step": 10850
    },
    {
      "epoch": 19.358288770053477,
      "grad_norm": 0.417404443025589,
      "learning_rate": 3.5478312537136065e-05,
      "loss": 0.0236,
      "step": 10860
    },
    {
      "epoch": 19.376114081996434,
      "grad_norm": 0.6455036997795105,
      "learning_rate": 3.541889483065954e-05,
      "loss": 0.0238,
      "step": 10870
    },
    {
      "epoch": 19.393939393939394,
      "grad_norm": 0.5577247738838196,
      "learning_rate": 3.535947712418301e-05,
      "loss": 0.0243,
      "step": 10880
    },
    {
      "epoch": 19.41176470588235,
      "grad_norm": 0.3620148003101349,
      "learning_rate": 3.530005941770648e-05,
      "loss": 0.0238,
      "step": 10890
    },
    {
      "epoch": 19.429590017825312,
      "grad_norm": 0.7489635944366455,
      "learning_rate": 3.524064171122995e-05,
      "loss": 0.024,
      "step": 10900
    },
    {
      "epoch": 19.447415329768273,
      "grad_norm": 0.7554934024810791,
      "learning_rate": 3.5181224004753414e-05,
      "loss": 0.0247,
      "step": 10910
    },
    {
      "epoch": 19.46524064171123,
      "grad_norm": 0.8556230068206787,
      "learning_rate": 3.512180629827689e-05,
      "loss": 0.0233,
      "step": 10920
    },
    {
      "epoch": 19.48306595365419,
      "grad_norm": 0.9622141122817993,
      "learning_rate": 3.506238859180036e-05,
      "loss": 0.0246,
      "step": 10930
    },
    {
      "epoch": 19.500891265597147,
      "grad_norm": 0.7150009274482727,
      "learning_rate": 3.5002970885323825e-05,
      "loss": 0.0238,
      "step": 10940
    },
    {
      "epoch": 19.518716577540108,
      "grad_norm": 0.4972050189971924,
      "learning_rate": 3.49435531788473e-05,
      "loss": 0.025,
      "step": 10950
    },
    {
      "epoch": 19.536541889483065,
      "grad_norm": 0.5447474718093872,
      "learning_rate": 3.488413547237077e-05,
      "loss": 0.0256,
      "step": 10960
    },
    {
      "epoch": 19.554367201426025,
      "grad_norm": 0.5484593510627747,
      "learning_rate": 3.482471776589424e-05,
      "loss": 0.0251,
      "step": 10970
    },
    {
      "epoch": 19.572192513368982,
      "grad_norm": 0.7503499388694763,
      "learning_rate": 3.476530005941771e-05,
      "loss": 0.0248,
      "step": 10980
    },
    {
      "epoch": 19.590017825311943,
      "grad_norm": 0.5284498929977417,
      "learning_rate": 3.470588235294118e-05,
      "loss": 0.0239,
      "step": 10990
    },
    {
      "epoch": 19.607843137254903,
      "grad_norm": 0.601410984992981,
      "learning_rate": 3.464646464646465e-05,
      "loss": 0.0245,
      "step": 11000
    },
    {
      "epoch": 19.62566844919786,
      "grad_norm": 0.525174617767334,
      "learning_rate": 3.458704693998812e-05,
      "loss": 0.0243,
      "step": 11010
    },
    {
      "epoch": 19.64349376114082,
      "grad_norm": 0.28459471464157104,
      "learning_rate": 3.4527629233511585e-05,
      "loss": 0.0248,
      "step": 11020
    },
    {
      "epoch": 19.661319073083778,
      "grad_norm": 0.8211133480072021,
      "learning_rate": 3.446821152703506e-05,
      "loss": 0.0245,
      "step": 11030
    },
    {
      "epoch": 19.67914438502674,
      "grad_norm": 0.7167379856109619,
      "learning_rate": 3.440879382055853e-05,
      "loss": 0.0242,
      "step": 11040
    },
    {
      "epoch": 19.696969696969695,
      "grad_norm": 0.4741964638233185,
      "learning_rate": 3.4349376114082e-05,
      "loss": 0.0246,
      "step": 11050
    },
    {
      "epoch": 19.714795008912656,
      "grad_norm": 0.2572968304157257,
      "learning_rate": 3.4289958407605465e-05,
      "loss": 0.0253,
      "step": 11060
    },
    {
      "epoch": 19.732620320855617,
      "grad_norm": 0.41389694809913635,
      "learning_rate": 3.423054070112894e-05,
      "loss": 0.0239,
      "step": 11070
    },
    {
      "epoch": 19.750445632798574,
      "grad_norm": 0.5669828057289124,
      "learning_rate": 3.417112299465241e-05,
      "loss": 0.0246,
      "step": 11080
    },
    {
      "epoch": 19.768270944741534,
      "grad_norm": 0.5392531156539917,
      "learning_rate": 3.411170528817588e-05,
      "loss": 0.0241,
      "step": 11090
    },
    {
      "epoch": 19.78609625668449,
      "grad_norm": 0.6921371221542358,
      "learning_rate": 3.405228758169935e-05,
      "loss": 0.0252,
      "step": 11100
    },
    {
      "epoch": 19.80392156862745,
      "grad_norm": 0.5086336135864258,
      "learning_rate": 3.399286987522281e-05,
      "loss": 0.0242,
      "step": 11110
    },
    {
      "epoch": 19.82174688057041,
      "grad_norm": 0.8767445087432861,
      "learning_rate": 3.393345216874629e-05,
      "loss": 0.0248,
      "step": 11120
    },
    {
      "epoch": 19.83957219251337,
      "grad_norm": 0.9449567794799805,
      "learning_rate": 3.387403446226976e-05,
      "loss": 0.0249,
      "step": 11130
    },
    {
      "epoch": 19.85739750445633,
      "grad_norm": 0.672370970249176,
      "learning_rate": 3.3814616755793225e-05,
      "loss": 0.0263,
      "step": 11140
    },
    {
      "epoch": 19.875222816399287,
      "grad_norm": 0.7817581295967102,
      "learning_rate": 3.37551990493167e-05,
      "loss": 0.0244,
      "step": 11150
    },
    {
      "epoch": 19.893048128342247,
      "grad_norm": 0.39677220582962036,
      "learning_rate": 3.369578134284017e-05,
      "loss": 0.0244,
      "step": 11160
    },
    {
      "epoch": 19.910873440285204,
      "grad_norm": 0.7182410955429077,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 0.0242,
      "step": 11170
    },
    {
      "epoch": 19.928698752228165,
      "grad_norm": 0.6100794076919556,
      "learning_rate": 3.357694592988711e-05,
      "loss": 0.0235,
      "step": 11180
    },
    {
      "epoch": 19.946524064171122,
      "grad_norm": 1.096240758895874,
      "learning_rate": 3.351752822341058e-05,
      "loss": 0.024,
      "step": 11190
    },
    {
      "epoch": 19.964349376114082,
      "grad_norm": 1.2275818586349487,
      "learning_rate": 3.345811051693405e-05,
      "loss": 0.025,
      "step": 11200
    },
    {
      "epoch": 19.98217468805704,
      "grad_norm": 0.9070011973381042,
      "learning_rate": 3.3398692810457516e-05,
      "loss": 0.0252,
      "step": 11210
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.14865276217460632,
      "learning_rate": 3.3339275103980985e-05,
      "loss": 0.0241,
      "step": 11220
    },
    {
      "epoch": 20.01782531194296,
      "grad_norm": 0.5833861827850342,
      "learning_rate": 3.327985739750446e-05,
      "loss": 0.0249,
      "step": 11230
    },
    {
      "epoch": 20.035650623885918,
      "grad_norm": 0.5220836400985718,
      "learning_rate": 3.322043969102793e-05,
      "loss": 0.0234,
      "step": 11240
    },
    {
      "epoch": 20.053475935828878,
      "grad_norm": 0.90733802318573,
      "learning_rate": 3.3161021984551396e-05,
      "loss": 0.0232,
      "step": 11250
    },
    {
      "epoch": 20.071301247771835,
      "grad_norm": 0.7367641925811768,
      "learning_rate": 3.3101604278074865e-05,
      "loss": 0.0249,
      "step": 11260
    },
    {
      "epoch": 20.089126559714796,
      "grad_norm": 0.7059832811355591,
      "learning_rate": 3.304218657159834e-05,
      "loss": 0.0255,
      "step": 11270
    },
    {
      "epoch": 20.106951871657753,
      "grad_norm": 0.4552449882030487,
      "learning_rate": 3.298276886512181e-05,
      "loss": 0.0237,
      "step": 11280
    },
    {
      "epoch": 20.124777183600713,
      "grad_norm": 0.34094488620758057,
      "learning_rate": 3.2923351158645276e-05,
      "loss": 0.0231,
      "step": 11290
    },
    {
      "epoch": 20.142602495543674,
      "grad_norm": 0.41618239879608154,
      "learning_rate": 3.286393345216875e-05,
      "loss": 0.0234,
      "step": 11300
    },
    {
      "epoch": 20.16042780748663,
      "grad_norm": 0.6954166293144226,
      "learning_rate": 3.280451574569221e-05,
      "loss": 0.0253,
      "step": 11310
    },
    {
      "epoch": 20.17825311942959,
      "grad_norm": 0.60976243019104,
      "learning_rate": 3.274509803921569e-05,
      "loss": 0.0229,
      "step": 11320
    },
    {
      "epoch": 20.19607843137255,
      "grad_norm": 0.657727062702179,
      "learning_rate": 3.268568033273916e-05,
      "loss": 0.0244,
      "step": 11330
    },
    {
      "epoch": 20.21390374331551,
      "grad_norm": 0.48248806595802307,
      "learning_rate": 3.2626262626262624e-05,
      "loss": 0.0243,
      "step": 11340
    },
    {
      "epoch": 20.231729055258466,
      "grad_norm": 0.5426951050758362,
      "learning_rate": 3.25668449197861e-05,
      "loss": 0.0243,
      "step": 11350
    },
    {
      "epoch": 20.249554367201426,
      "grad_norm": 0.6543639302253723,
      "learning_rate": 3.250742721330957e-05,
      "loss": 0.0243,
      "step": 11360
    },
    {
      "epoch": 20.267379679144383,
      "grad_norm": 0.366038978099823,
      "learning_rate": 3.2448009506833036e-05,
      "loss": 0.024,
      "step": 11370
    },
    {
      "epoch": 20.285204991087344,
      "grad_norm": 0.49316221475601196,
      "learning_rate": 3.238859180035651e-05,
      "loss": 0.0244,
      "step": 11380
    },
    {
      "epoch": 20.303030303030305,
      "grad_norm": 0.539770245552063,
      "learning_rate": 3.232917409387998e-05,
      "loss": 0.0243,
      "step": 11390
    },
    {
      "epoch": 20.32085561497326,
      "grad_norm": 0.4982750713825226,
      "learning_rate": 3.226975638740345e-05,
      "loss": 0.0236,
      "step": 11400
    },
    {
      "epoch": 20.338680926916222,
      "grad_norm": 0.4692721366882324,
      "learning_rate": 3.2210338680926916e-05,
      "loss": 0.0237,
      "step": 11410
    },
    {
      "epoch": 20.35650623885918,
      "grad_norm": 0.46012550592422485,
      "learning_rate": 3.215092097445039e-05,
      "loss": 0.0241,
      "step": 11420
    },
    {
      "epoch": 20.37433155080214,
      "grad_norm": 0.8061242699623108,
      "learning_rate": 3.209150326797386e-05,
      "loss": 0.0243,
      "step": 11430
    },
    {
      "epoch": 20.392156862745097,
      "grad_norm": 0.9472182989120483,
      "learning_rate": 3.203208556149733e-05,
      "loss": 0.025,
      "step": 11440
    },
    {
      "epoch": 20.409982174688057,
      "grad_norm": 0.6703718900680542,
      "learning_rate": 3.1972667855020796e-05,
      "loss": 0.0251,
      "step": 11450
    },
    {
      "epoch": 20.427807486631018,
      "grad_norm": 0.46641725301742554,
      "learning_rate": 3.1913250148544264e-05,
      "loss": 0.0241,
      "step": 11460
    },
    {
      "epoch": 20.445632798573975,
      "grad_norm": 0.6943146586418152,
      "learning_rate": 3.185383244206774e-05,
      "loss": 0.0248,
      "step": 11470
    },
    {
      "epoch": 20.463458110516935,
      "grad_norm": 0.6786786913871765,
      "learning_rate": 3.179441473559121e-05,
      "loss": 0.025,
      "step": 11480
    },
    {
      "epoch": 20.481283422459892,
      "grad_norm": 0.5206389427185059,
      "learning_rate": 3.1734997029114676e-05,
      "loss": 0.0244,
      "step": 11490
    },
    {
      "epoch": 20.499108734402853,
      "grad_norm": 0.33861327171325684,
      "learning_rate": 3.167557932263815e-05,
      "loss": 0.024,
      "step": 11500
    },
    {
      "epoch": 20.51693404634581,
      "grad_norm": 0.6361384987831116,
      "learning_rate": 3.161616161616161e-05,
      "loss": 0.0243,
      "step": 11510
    },
    {
      "epoch": 20.53475935828877,
      "grad_norm": 0.5875409841537476,
      "learning_rate": 3.155674390968509e-05,
      "loss": 0.0245,
      "step": 11520
    },
    {
      "epoch": 20.552584670231727,
      "grad_norm": 0.49134561419487,
      "learning_rate": 3.149732620320856e-05,
      "loss": 0.024,
      "step": 11530
    },
    {
      "epoch": 20.570409982174688,
      "grad_norm": 0.6684751510620117,
      "learning_rate": 3.1437908496732024e-05,
      "loss": 0.0253,
      "step": 11540
    },
    {
      "epoch": 20.58823529411765,
      "grad_norm": 0.7209529876708984,
      "learning_rate": 3.13784907902555e-05,
      "loss": 0.0242,
      "step": 11550
    },
    {
      "epoch": 20.606060606060606,
      "grad_norm": 0.7639551162719727,
      "learning_rate": 3.131907308377897e-05,
      "loss": 0.0244,
      "step": 11560
    },
    {
      "epoch": 20.623885918003566,
      "grad_norm": 0.5065926313400269,
      "learning_rate": 3.1259655377302436e-05,
      "loss": 0.0237,
      "step": 11570
    },
    {
      "epoch": 20.641711229946523,
      "grad_norm": 0.45677629113197327,
      "learning_rate": 3.120023767082591e-05,
      "loss": 0.0246,
      "step": 11580
    },
    {
      "epoch": 20.659536541889484,
      "grad_norm": 0.5742484331130981,
      "learning_rate": 3.114081996434938e-05,
      "loss": 0.0235,
      "step": 11590
    },
    {
      "epoch": 20.67736185383244,
      "grad_norm": 0.31987160444259644,
      "learning_rate": 3.108140225787285e-05,
      "loss": 0.0239,
      "step": 11600
    },
    {
      "epoch": 20.6951871657754,
      "grad_norm": 0.5287771224975586,
      "learning_rate": 3.1021984551396316e-05,
      "loss": 0.0244,
      "step": 11610
    },
    {
      "epoch": 20.71301247771836,
      "grad_norm": 0.7912495732307434,
      "learning_rate": 3.096256684491979e-05,
      "loss": 0.0244,
      "step": 11620
    },
    {
      "epoch": 20.73083778966132,
      "grad_norm": 0.7017553448677063,
      "learning_rate": 3.090314913844326e-05,
      "loss": 0.0241,
      "step": 11630
    },
    {
      "epoch": 20.74866310160428,
      "grad_norm": 0.6233700513839722,
      "learning_rate": 3.084373143196673e-05,
      "loss": 0.0243,
      "step": 11640
    },
    {
      "epoch": 20.766488413547236,
      "grad_norm": 0.7712796330451965,
      "learning_rate": 3.07843137254902e-05,
      "loss": 0.0237,
      "step": 11650
    },
    {
      "epoch": 20.784313725490197,
      "grad_norm": 1.0291322469711304,
      "learning_rate": 3.0724896019013664e-05,
      "loss": 0.0247,
      "step": 11660
    },
    {
      "epoch": 20.802139037433154,
      "grad_norm": 0.417388379573822,
      "learning_rate": 3.066547831253714e-05,
      "loss": 0.023,
      "step": 11670
    },
    {
      "epoch": 20.819964349376114,
      "grad_norm": 1.2414124011993408,
      "learning_rate": 3.060606060606061e-05,
      "loss": 0.0247,
      "step": 11680
    },
    {
      "epoch": 20.83778966131907,
      "grad_norm": 0.523257315158844,
      "learning_rate": 3.0546642899584076e-05,
      "loss": 0.0231,
      "step": 11690
    },
    {
      "epoch": 20.855614973262032,
      "grad_norm": 0.4136062562465668,
      "learning_rate": 3.048722519310755e-05,
      "loss": 0.0255,
      "step": 11700
    },
    {
      "epoch": 20.873440285204993,
      "grad_norm": 0.8899218440055847,
      "learning_rate": 3.0427807486631016e-05,
      "loss": 0.0237,
      "step": 11710
    },
    {
      "epoch": 20.89126559714795,
      "grad_norm": 0.38889357447624207,
      "learning_rate": 3.0368389780154487e-05,
      "loss": 0.0248,
      "step": 11720
    },
    {
      "epoch": 20.90909090909091,
      "grad_norm": 0.2811662554740906,
      "learning_rate": 3.0308972073677955e-05,
      "loss": 0.0237,
      "step": 11730
    },
    {
      "epoch": 20.926916221033867,
      "grad_norm": 0.5193929672241211,
      "learning_rate": 3.0249554367201427e-05,
      "loss": 0.0251,
      "step": 11740
    },
    {
      "epoch": 20.944741532976828,
      "grad_norm": 0.5469709038734436,
      "learning_rate": 3.01901366607249e-05,
      "loss": 0.0238,
      "step": 11750
    },
    {
      "epoch": 20.962566844919785,
      "grad_norm": 0.5151451230049133,
      "learning_rate": 3.0130718954248367e-05,
      "loss": 0.024,
      "step": 11760
    },
    {
      "epoch": 20.980392156862745,
      "grad_norm": 1.0316411256790161,
      "learning_rate": 3.007130124777184e-05,
      "loss": 0.0237,
      "step": 11770
    },
    {
      "epoch": 20.998217468805706,
      "grad_norm": 0.49111583828926086,
      "learning_rate": 3.0011883541295304e-05,
      "loss": 0.0238,
      "step": 11780
    },
    {
      "epoch": 21.016042780748663,
      "grad_norm": 0.6134874224662781,
      "learning_rate": 2.9952465834818775e-05,
      "loss": 0.0237,
      "step": 11790
    },
    {
      "epoch": 21.033868092691623,
      "grad_norm": 0.5574674010276794,
      "learning_rate": 2.989304812834225e-05,
      "loss": 0.0233,
      "step": 11800
    },
    {
      "epoch": 21.05169340463458,
      "grad_norm": 0.40577101707458496,
      "learning_rate": 2.9833630421865715e-05,
      "loss": 0.0241,
      "step": 11810
    },
    {
      "epoch": 21.06951871657754,
      "grad_norm": 0.71265709400177,
      "learning_rate": 2.9774212715389187e-05,
      "loss": 0.0234,
      "step": 11820
    },
    {
      "epoch": 21.087344028520498,
      "grad_norm": 0.7410154342651367,
      "learning_rate": 2.9714795008912655e-05,
      "loss": 0.0241,
      "step": 11830
    },
    {
      "epoch": 21.10516934046346,
      "grad_norm": 0.3330962657928467,
      "learning_rate": 2.9655377302436127e-05,
      "loss": 0.0238,
      "step": 11840
    },
    {
      "epoch": 21.122994652406415,
      "grad_norm": 0.35305386781692505,
      "learning_rate": 2.95959595959596e-05,
      "loss": 0.0231,
      "step": 11850
    },
    {
      "epoch": 21.140819964349376,
      "grad_norm": 0.9584447145462036,
      "learning_rate": 2.9536541889483067e-05,
      "loss": 0.0234,
      "step": 11860
    },
    {
      "epoch": 21.158645276292336,
      "grad_norm": 1.5648648738861084,
      "learning_rate": 2.947712418300654e-05,
      "loss": 0.0239,
      "step": 11870
    },
    {
      "epoch": 21.176470588235293,
      "grad_norm": 0.4066864252090454,
      "learning_rate": 2.9417706476530004e-05,
      "loss": 0.025,
      "step": 11880
    },
    {
      "epoch": 21.194295900178254,
      "grad_norm": 0.3351278603076935,
      "learning_rate": 2.935828877005348e-05,
      "loss": 0.0238,
      "step": 11890
    },
    {
      "epoch": 21.21212121212121,
      "grad_norm": 0.3905567228794098,
      "learning_rate": 2.929887106357695e-05,
      "loss": 0.0232,
      "step": 11900
    },
    {
      "epoch": 21.22994652406417,
      "grad_norm": 0.6723757386207581,
      "learning_rate": 2.9239453357100415e-05,
      "loss": 0.0238,
      "step": 11910
    },
    {
      "epoch": 21.24777183600713,
      "grad_norm": 0.4703659415245056,
      "learning_rate": 2.9180035650623887e-05,
      "loss": 0.0227,
      "step": 11920
    },
    {
      "epoch": 21.26559714795009,
      "grad_norm": 0.8900642991065979,
      "learning_rate": 2.9120617944147355e-05,
      "loss": 0.0233,
      "step": 11930
    },
    {
      "epoch": 21.28342245989305,
      "grad_norm": 0.3638942837715149,
      "learning_rate": 2.9061200237670827e-05,
      "loss": 0.0233,
      "step": 11940
    },
    {
      "epoch": 21.301247771836007,
      "grad_norm": 0.38157618045806885,
      "learning_rate": 2.90017825311943e-05,
      "loss": 0.023,
      "step": 11950
    },
    {
      "epoch": 21.319073083778967,
      "grad_norm": 0.44104140996932983,
      "learning_rate": 2.8942364824717767e-05,
      "loss": 0.0236,
      "step": 11960
    },
    {
      "epoch": 21.336898395721924,
      "grad_norm": 0.4008534550666809,
      "learning_rate": 2.888294711824124e-05,
      "loss": 0.0239,
      "step": 11970
    },
    {
      "epoch": 21.354723707664885,
      "grad_norm": 0.8451187610626221,
      "learning_rate": 2.8823529411764703e-05,
      "loss": 0.0235,
      "step": 11980
    },
    {
      "epoch": 21.372549019607842,
      "grad_norm": 0.6494908928871155,
      "learning_rate": 2.876411170528818e-05,
      "loss": 0.0232,
      "step": 11990
    },
    {
      "epoch": 21.390374331550802,
      "grad_norm": 0.4767707884311676,
      "learning_rate": 2.870469399881165e-05,
      "loss": 0.0226,
      "step": 12000
    },
    {
      "epoch": 21.40819964349376,
      "grad_norm": 0.37295010685920715,
      "learning_rate": 2.8645276292335115e-05,
      "loss": 0.0243,
      "step": 12010
    },
    {
      "epoch": 21.42602495543672,
      "grad_norm": 0.47700411081314087,
      "learning_rate": 2.8585858585858587e-05,
      "loss": 0.0232,
      "step": 12020
    },
    {
      "epoch": 21.44385026737968,
      "grad_norm": 0.33531707525253296,
      "learning_rate": 2.8526440879382055e-05,
      "loss": 0.0238,
      "step": 12030
    },
    {
      "epoch": 21.461675579322637,
      "grad_norm": 0.4471885561943054,
      "learning_rate": 2.8467023172905527e-05,
      "loss": 0.0242,
      "step": 12040
    },
    {
      "epoch": 21.479500891265598,
      "grad_norm": 0.4926903545856476,
      "learning_rate": 2.8407605466429e-05,
      "loss": 0.0234,
      "step": 12050
    },
    {
      "epoch": 21.497326203208555,
      "grad_norm": 0.7534226179122925,
      "learning_rate": 2.8348187759952467e-05,
      "loss": 0.0236,
      "step": 12060
    },
    {
      "epoch": 21.515151515151516,
      "grad_norm": 0.4730272889137268,
      "learning_rate": 2.8288770053475938e-05,
      "loss": 0.0241,
      "step": 12070
    },
    {
      "epoch": 21.532976827094473,
      "grad_norm": 0.47976651787757874,
      "learning_rate": 2.8229352346999403e-05,
      "loss": 0.024,
      "step": 12080
    },
    {
      "epoch": 21.550802139037433,
      "grad_norm": 0.3848954439163208,
      "learning_rate": 2.8169934640522878e-05,
      "loss": 0.0236,
      "step": 12090
    },
    {
      "epoch": 21.568627450980394,
      "grad_norm": 0.6402214169502258,
      "learning_rate": 2.811051693404635e-05,
      "loss": 0.0238,
      "step": 12100
    },
    {
      "epoch": 21.58645276292335,
      "grad_norm": 0.630582332611084,
      "learning_rate": 2.8051099227569815e-05,
      "loss": 0.0246,
      "step": 12110
    },
    {
      "epoch": 21.60427807486631,
      "grad_norm": 0.3440782129764557,
      "learning_rate": 2.7991681521093286e-05,
      "loss": 0.0228,
      "step": 12120
    },
    {
      "epoch": 21.62210338680927,
      "grad_norm": 0.4898197650909424,
      "learning_rate": 2.7932263814616755e-05,
      "loss": 0.024,
      "step": 12130
    },
    {
      "epoch": 21.63992869875223,
      "grad_norm": 0.5024358034133911,
      "learning_rate": 2.7872846108140226e-05,
      "loss": 0.0235,
      "step": 12140
    },
    {
      "epoch": 21.657754010695186,
      "grad_norm": 0.5665372610092163,
      "learning_rate": 2.7813428401663698e-05,
      "loss": 0.0239,
      "step": 12150
    },
    {
      "epoch": 21.675579322638146,
      "grad_norm": 0.5905561447143555,
      "learning_rate": 2.7754010695187166e-05,
      "loss": 0.0236,
      "step": 12160
    },
    {
      "epoch": 21.693404634581107,
      "grad_norm": 0.46760034561157227,
      "learning_rate": 2.7694592988710638e-05,
      "loss": 0.0239,
      "step": 12170
    },
    {
      "epoch": 21.711229946524064,
      "grad_norm": 0.4398583769798279,
      "learning_rate": 2.7635175282234106e-05,
      "loss": 0.0235,
      "step": 12180
    },
    {
      "epoch": 21.729055258467024,
      "grad_norm": 0.4389411211013794,
      "learning_rate": 2.7575757575757578e-05,
      "loss": 0.0231,
      "step": 12190
    },
    {
      "epoch": 21.74688057040998,
      "grad_norm": 0.4264221787452698,
      "learning_rate": 2.751633986928105e-05,
      "loss": 0.0232,
      "step": 12200
    },
    {
      "epoch": 21.764705882352942,
      "grad_norm": 0.4730726480484009,
      "learning_rate": 2.7456922162804515e-05,
      "loss": 0.0242,
      "step": 12210
    },
    {
      "epoch": 21.7825311942959,
      "grad_norm": 0.5422578454017639,
      "learning_rate": 2.739750445632799e-05,
      "loss": 0.0237,
      "step": 12220
    },
    {
      "epoch": 21.80035650623886,
      "grad_norm": 0.5442512631416321,
      "learning_rate": 2.7338086749851455e-05,
      "loss": 0.023,
      "step": 12230
    },
    {
      "epoch": 21.818181818181817,
      "grad_norm": 0.5433948636054993,
      "learning_rate": 2.7278669043374926e-05,
      "loss": 0.0233,
      "step": 12240
    },
    {
      "epoch": 21.836007130124777,
      "grad_norm": 0.3733188509941101,
      "learning_rate": 2.7219251336898398e-05,
      "loss": 0.0222,
      "step": 12250
    },
    {
      "epoch": 21.853832442067738,
      "grad_norm": 0.9500532150268555,
      "learning_rate": 2.7159833630421866e-05,
      "loss": 0.0235,
      "step": 12260
    },
    {
      "epoch": 21.871657754010695,
      "grad_norm": 0.4835449159145355,
      "learning_rate": 2.7100415923945338e-05,
      "loss": 0.024,
      "step": 12270
    },
    {
      "epoch": 21.889483065953655,
      "grad_norm": 0.4447169303894043,
      "learning_rate": 2.7040998217468806e-05,
      "loss": 0.0229,
      "step": 12280
    },
    {
      "epoch": 21.907308377896612,
      "grad_norm": 0.37781283259391785,
      "learning_rate": 2.6981580510992278e-05,
      "loss": 0.0233,
      "step": 12290
    },
    {
      "epoch": 21.925133689839573,
      "grad_norm": 0.5774074196815491,
      "learning_rate": 2.692216280451575e-05,
      "loss": 0.0232,
      "step": 12300
    },
    {
      "epoch": 21.94295900178253,
      "grad_norm": 0.6115978956222534,
      "learning_rate": 2.6862745098039214e-05,
      "loss": 0.0237,
      "step": 12310
    },
    {
      "epoch": 21.96078431372549,
      "grad_norm": 0.5739773511886597,
      "learning_rate": 2.680332739156269e-05,
      "loss": 0.0234,
      "step": 12320
    },
    {
      "epoch": 21.97860962566845,
      "grad_norm": 0.4634396433830261,
      "learning_rate": 2.6743909685086154e-05,
      "loss": 0.0239,
      "step": 12330
    },
    {
      "epoch": 21.996434937611408,
      "grad_norm": 0.9899863600730896,
      "learning_rate": 2.6684491978609626e-05,
      "loss": 0.0232,
      "step": 12340
    },
    {
      "epoch": 22.01426024955437,
      "grad_norm": 0.5650147795677185,
      "learning_rate": 2.6625074272133098e-05,
      "loss": 0.0243,
      "step": 12350
    },
    {
      "epoch": 22.032085561497325,
      "grad_norm": 0.37857043743133545,
      "learning_rate": 2.6565656565656566e-05,
      "loss": 0.0232,
      "step": 12360
    },
    {
      "epoch": 22.049910873440286,
      "grad_norm": 0.37929075956344604,
      "learning_rate": 2.6506238859180038e-05,
      "loss": 0.0229,
      "step": 12370
    },
    {
      "epoch": 22.067736185383243,
      "grad_norm": 0.5651648640632629,
      "learning_rate": 2.6446821152703506e-05,
      "loss": 0.0239,
      "step": 12380
    },
    {
      "epoch": 22.085561497326204,
      "grad_norm": 0.647255539894104,
      "learning_rate": 2.6387403446226978e-05,
      "loss": 0.0229,
      "step": 12390
    },
    {
      "epoch": 22.10338680926916,
      "grad_norm": 0.46761733293533325,
      "learning_rate": 2.632798573975045e-05,
      "loss": 0.0237,
      "step": 12400
    },
    {
      "epoch": 22.12121212121212,
      "grad_norm": 0.9669004678726196,
      "learning_rate": 2.6268568033273914e-05,
      "loss": 0.023,
      "step": 12410
    },
    {
      "epoch": 22.13903743315508,
      "grad_norm": 0.4044590890407562,
      "learning_rate": 2.620915032679739e-05,
      "loss": 0.0237,
      "step": 12420
    },
    {
      "epoch": 22.15686274509804,
      "grad_norm": 0.39599090814590454,
      "learning_rate": 2.6149732620320854e-05,
      "loss": 0.0226,
      "step": 12430
    },
    {
      "epoch": 22.174688057041,
      "grad_norm": 0.3710133731365204,
      "learning_rate": 2.6090314913844326e-05,
      "loss": 0.0234,
      "step": 12440
    },
    {
      "epoch": 22.192513368983956,
      "grad_norm": 0.5659123659133911,
      "learning_rate": 2.6030897207367798e-05,
      "loss": 0.0232,
      "step": 12450
    },
    {
      "epoch": 22.210338680926917,
      "grad_norm": 0.4581465423107147,
      "learning_rate": 2.5971479500891266e-05,
      "loss": 0.023,
      "step": 12460
    },
    {
      "epoch": 22.228163992869874,
      "grad_norm": 0.3343440592288971,
      "learning_rate": 2.5912061794414738e-05,
      "loss": 0.0237,
      "step": 12470
    },
    {
      "epoch": 22.245989304812834,
      "grad_norm": 0.363312691450119,
      "learning_rate": 2.5852644087938206e-05,
      "loss": 0.0226,
      "step": 12480
    },
    {
      "epoch": 22.263814616755795,
      "grad_norm": 0.5375834107398987,
      "learning_rate": 2.5793226381461678e-05,
      "loss": 0.023,
      "step": 12490
    },
    {
      "epoch": 22.281639928698752,
      "grad_norm": 0.6062687635421753,
      "learning_rate": 2.573380867498515e-05,
      "loss": 0.0226,
      "step": 12500
    },
    {
      "epoch": 22.299465240641712,
      "grad_norm": 0.4761434495449066,
      "learning_rate": 2.5674390968508617e-05,
      "loss": 0.0229,
      "step": 12510
    },
    {
      "epoch": 22.31729055258467,
      "grad_norm": 0.4310111105442047,
      "learning_rate": 2.561497326203209e-05,
      "loss": 0.0239,
      "step": 12520
    },
    {
      "epoch": 22.33511586452763,
      "grad_norm": 0.7243724465370178,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.0232,
      "step": 12530
    },
    {
      "epoch": 22.352941176470587,
      "grad_norm": 0.6161816716194153,
      "learning_rate": 2.5496137849079026e-05,
      "loss": 0.0241,
      "step": 12540
    },
    {
      "epoch": 22.370766488413548,
      "grad_norm": 0.7432995438575745,
      "learning_rate": 2.54367201426025e-05,
      "loss": 0.0234,
      "step": 12550
    },
    {
      "epoch": 22.388591800356505,
      "grad_norm": 0.6116924285888672,
      "learning_rate": 2.5377302436125966e-05,
      "loss": 0.0242,
      "step": 12560
    },
    {
      "epoch": 22.406417112299465,
      "grad_norm": 0.4721500873565674,
      "learning_rate": 2.5317884729649437e-05,
      "loss": 0.0229,
      "step": 12570
    },
    {
      "epoch": 22.424242424242426,
      "grad_norm": 0.3265794813632965,
      "learning_rate": 2.5258467023172906e-05,
      "loss": 0.0242,
      "step": 12580
    },
    {
      "epoch": 22.442067736185383,
      "grad_norm": 0.5301672220230103,
      "learning_rate": 2.5199049316696377e-05,
      "loss": 0.024,
      "step": 12590
    },
    {
      "epoch": 22.459893048128343,
      "grad_norm": 0.4767335057258606,
      "learning_rate": 2.513963161021985e-05,
      "loss": 0.0236,
      "step": 12600
    },
    {
      "epoch": 22.4777183600713,
      "grad_norm": 0.5849556922912598,
      "learning_rate": 2.5080213903743317e-05,
      "loss": 0.0242,
      "step": 12610
    },
    {
      "epoch": 22.49554367201426,
      "grad_norm": 0.5562593936920166,
      "learning_rate": 2.502079619726679e-05,
      "loss": 0.0229,
      "step": 12620
    },
    {
      "epoch": 22.513368983957218,
      "grad_norm": 1.2961266040802002,
      "learning_rate": 2.4961378490790257e-05,
      "loss": 0.0237,
      "step": 12630
    },
    {
      "epoch": 22.53119429590018,
      "grad_norm": 0.4288860857486725,
      "learning_rate": 2.4901960784313726e-05,
      "loss": 0.0229,
      "step": 12640
    },
    {
      "epoch": 22.54901960784314,
      "grad_norm": 0.5167856812477112,
      "learning_rate": 2.4842543077837197e-05,
      "loss": 0.0236,
      "step": 12650
    },
    {
      "epoch": 22.566844919786096,
      "grad_norm": 0.5575776100158691,
      "learning_rate": 2.4783125371360666e-05,
      "loss": 0.023,
      "step": 12660
    },
    {
      "epoch": 22.584670231729056,
      "grad_norm": 0.9026427865028381,
      "learning_rate": 2.4723707664884134e-05,
      "loss": 0.0233,
      "step": 12670
    },
    {
      "epoch": 22.602495543672013,
      "grad_norm": 0.31730207800865173,
      "learning_rate": 2.466428995840761e-05,
      "loss": 0.023,
      "step": 12680
    },
    {
      "epoch": 22.620320855614974,
      "grad_norm": 0.4538510739803314,
      "learning_rate": 2.4604872251931077e-05,
      "loss": 0.0229,
      "step": 12690
    },
    {
      "epoch": 22.63814616755793,
      "grad_norm": 0.6266993880271912,
      "learning_rate": 2.4545454545454545e-05,
      "loss": 0.0228,
      "step": 12700
    },
    {
      "epoch": 22.65597147950089,
      "grad_norm": 0.866356372833252,
      "learning_rate": 2.4486036838978017e-05,
      "loss": 0.0231,
      "step": 12710
    },
    {
      "epoch": 22.67379679144385,
      "grad_norm": 0.4038206934928894,
      "learning_rate": 2.4426619132501485e-05,
      "loss": 0.0235,
      "step": 12720
    },
    {
      "epoch": 22.69162210338681,
      "grad_norm": 0.7931062579154968,
      "learning_rate": 2.4367201426024957e-05,
      "loss": 0.0229,
      "step": 12730
    },
    {
      "epoch": 22.70944741532977,
      "grad_norm": 0.46112751960754395,
      "learning_rate": 2.4307783719548425e-05,
      "loss": 0.0232,
      "step": 12740
    },
    {
      "epoch": 22.727272727272727,
      "grad_norm": 0.45280715823173523,
      "learning_rate": 2.4248366013071897e-05,
      "loss": 0.0229,
      "step": 12750
    },
    {
      "epoch": 22.745098039215687,
      "grad_norm": 0.8157853484153748,
      "learning_rate": 2.4188948306595365e-05,
      "loss": 0.0238,
      "step": 12760
    },
    {
      "epoch": 22.762923351158644,
      "grad_norm": 0.2830657660961151,
      "learning_rate": 2.4129530600118837e-05,
      "loss": 0.0229,
      "step": 12770
    },
    {
      "epoch": 22.780748663101605,
      "grad_norm": 0.31510329246520996,
      "learning_rate": 2.407011289364231e-05,
      "loss": 0.0236,
      "step": 12780
    },
    {
      "epoch": 22.79857397504456,
      "grad_norm": 0.2995613217353821,
      "learning_rate": 2.4010695187165777e-05,
      "loss": 0.022,
      "step": 12790
    },
    {
      "epoch": 22.816399286987522,
      "grad_norm": 0.5436661839485168,
      "learning_rate": 2.3951277480689245e-05,
      "loss": 0.023,
      "step": 12800
    },
    {
      "epoch": 22.834224598930483,
      "grad_norm": 0.28272581100463867,
      "learning_rate": 2.3891859774212717e-05,
      "loss": 0.0226,
      "step": 12810
    },
    {
      "epoch": 22.85204991087344,
      "grad_norm": 0.8533189296722412,
      "learning_rate": 2.3832442067736185e-05,
      "loss": 0.0233,
      "step": 12820
    },
    {
      "epoch": 22.8698752228164,
      "grad_norm": 0.6811000108718872,
      "learning_rate": 2.3773024361259657e-05,
      "loss": 0.0237,
      "step": 12830
    },
    {
      "epoch": 22.887700534759357,
      "grad_norm": 0.36174988746643066,
      "learning_rate": 2.371360665478313e-05,
      "loss": 0.0236,
      "step": 12840
    },
    {
      "epoch": 22.905525846702318,
      "grad_norm": 0.597264289855957,
      "learning_rate": 2.3654188948306597e-05,
      "loss": 0.0234,
      "step": 12850
    },
    {
      "epoch": 22.923351158645275,
      "grad_norm": 0.649675190448761,
      "learning_rate": 2.3594771241830065e-05,
      "loss": 0.0231,
      "step": 12860
    },
    {
      "epoch": 22.941176470588236,
      "grad_norm": 1.4142894744873047,
      "learning_rate": 2.3535353535353537e-05,
      "loss": 0.0237,
      "step": 12870
    },
    {
      "epoch": 22.959001782531196,
      "grad_norm": 0.8337433934211731,
      "learning_rate": 2.347593582887701e-05,
      "loss": 0.0235,
      "step": 12880
    },
    {
      "epoch": 22.976827094474153,
      "grad_norm": 0.2930191457271576,
      "learning_rate": 2.3416518122400477e-05,
      "loss": 0.0225,
      "step": 12890
    },
    {
      "epoch": 22.994652406417114,
      "grad_norm": 0.5710234045982361,
      "learning_rate": 2.3357100415923945e-05,
      "loss": 0.0232,
      "step": 12900
    },
    {
      "epoch": 23.01247771836007,
      "grad_norm": 0.7075754404067993,
      "learning_rate": 2.3297682709447417e-05,
      "loss": 0.0235,
      "step": 12910
    },
    {
      "epoch": 23.03030303030303,
      "grad_norm": 0.593524158000946,
      "learning_rate": 2.3238265002970885e-05,
      "loss": 0.0228,
      "step": 12920
    },
    {
      "epoch": 23.048128342245988,
      "grad_norm": 0.5390381217002869,
      "learning_rate": 2.3178847296494357e-05,
      "loss": 0.0219,
      "step": 12930
    },
    {
      "epoch": 23.06595365418895,
      "grad_norm": 0.37784522771835327,
      "learning_rate": 2.311942959001783e-05,
      "loss": 0.0231,
      "step": 12940
    },
    {
      "epoch": 23.083778966131906,
      "grad_norm": 0.30343136191368103,
      "learning_rate": 2.3060011883541297e-05,
      "loss": 0.0226,
      "step": 12950
    },
    {
      "epoch": 23.101604278074866,
      "grad_norm": 0.5216702222824097,
      "learning_rate": 2.3000594177064765e-05,
      "loss": 0.0239,
      "step": 12960
    },
    {
      "epoch": 23.119429590017827,
      "grad_norm": 0.322647362947464,
      "learning_rate": 2.2941176470588237e-05,
      "loss": 0.0236,
      "step": 12970
    },
    {
      "epoch": 23.137254901960784,
      "grad_norm": 0.7037017941474915,
      "learning_rate": 2.288175876411171e-05,
      "loss": 0.0237,
      "step": 12980
    },
    {
      "epoch": 23.155080213903744,
      "grad_norm": 0.7757887244224548,
      "learning_rate": 2.2822341057635177e-05,
      "loss": 0.0233,
      "step": 12990
    },
    {
      "epoch": 23.1729055258467,
      "grad_norm": 0.2520717978477478,
      "learning_rate": 2.2762923351158645e-05,
      "loss": 0.0232,
      "step": 13000
    },
    {
      "epoch": 23.190730837789662,
      "grad_norm": 0.42965713143348694,
      "learning_rate": 2.2703505644682117e-05,
      "loss": 0.0237,
      "step": 13010
    },
    {
      "epoch": 23.20855614973262,
      "grad_norm": 1.1682329177856445,
      "learning_rate": 2.2644087938205585e-05,
      "loss": 0.0225,
      "step": 13020
    },
    {
      "epoch": 23.22638146167558,
      "grad_norm": 0.3554762601852417,
      "learning_rate": 2.2584670231729057e-05,
      "loss": 0.0227,
      "step": 13030
    },
    {
      "epoch": 23.24420677361854,
      "grad_norm": 0.6135241389274597,
      "learning_rate": 2.2525252525252528e-05,
      "loss": 0.0227,
      "step": 13040
    },
    {
      "epoch": 23.262032085561497,
      "grad_norm": 0.4833352267742157,
      "learning_rate": 2.2465834818775997e-05,
      "loss": 0.0228,
      "step": 13050
    },
    {
      "epoch": 23.279857397504458,
      "grad_norm": 0.22992631793022156,
      "learning_rate": 2.2406417112299465e-05,
      "loss": 0.0229,
      "step": 13060
    },
    {
      "epoch": 23.297682709447415,
      "grad_norm": 0.6581125855445862,
      "learning_rate": 2.2346999405822936e-05,
      "loss": 0.0232,
      "step": 13070
    },
    {
      "epoch": 23.315508021390375,
      "grad_norm": 0.4693104922771454,
      "learning_rate": 2.2287581699346408e-05,
      "loss": 0.0231,
      "step": 13080
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 0.46358105540275574,
      "learning_rate": 2.2228163992869876e-05,
      "loss": 0.0228,
      "step": 13090
    },
    {
      "epoch": 23.351158645276293,
      "grad_norm": 0.6398531794548035,
      "learning_rate": 2.2168746286393348e-05,
      "loss": 0.0243,
      "step": 13100
    },
    {
      "epoch": 23.36898395721925,
      "grad_norm": 0.5726507902145386,
      "learning_rate": 2.2109328579916816e-05,
      "loss": 0.0225,
      "step": 13110
    },
    {
      "epoch": 23.38680926916221,
      "grad_norm": 0.6663509011268616,
      "learning_rate": 2.2049910873440285e-05,
      "loss": 0.0233,
      "step": 13120
    },
    {
      "epoch": 23.40463458110517,
      "grad_norm": 0.41913098096847534,
      "learning_rate": 2.1990493166963756e-05,
      "loss": 0.0235,
      "step": 13130
    },
    {
      "epoch": 23.422459893048128,
      "grad_norm": 0.4022656977176666,
      "learning_rate": 2.1931075460487228e-05,
      "loss": 0.0225,
      "step": 13140
    },
    {
      "epoch": 23.44028520499109,
      "grad_norm": 0.6153028607368469,
      "learning_rate": 2.1871657754010696e-05,
      "loss": 0.0226,
      "step": 13150
    },
    {
      "epoch": 23.458110516934045,
      "grad_norm": 0.351921021938324,
      "learning_rate": 2.1812240047534165e-05,
      "loss": 0.023,
      "step": 13160
    },
    {
      "epoch": 23.475935828877006,
      "grad_norm": 0.403559148311615,
      "learning_rate": 2.1752822341057636e-05,
      "loss": 0.0224,
      "step": 13170
    },
    {
      "epoch": 23.493761140819963,
      "grad_norm": 0.2872661352157593,
      "learning_rate": 2.1693404634581105e-05,
      "loss": 0.0228,
      "step": 13180
    },
    {
      "epoch": 23.511586452762923,
      "grad_norm": 0.30142492055892944,
      "learning_rate": 2.1633986928104576e-05,
      "loss": 0.0229,
      "step": 13190
    },
    {
      "epoch": 23.529411764705884,
      "grad_norm": 0.33023834228515625,
      "learning_rate": 2.1574569221628048e-05,
      "loss": 0.0229,
      "step": 13200
    },
    {
      "epoch": 23.54723707664884,
      "grad_norm": 0.4945816397666931,
      "learning_rate": 2.1515151515151516e-05,
      "loss": 0.0228,
      "step": 13210
    },
    {
      "epoch": 23.5650623885918,
      "grad_norm": 0.8494206666946411,
      "learning_rate": 2.1455733808674985e-05,
      "loss": 0.0226,
      "step": 13220
    },
    {
      "epoch": 23.58288770053476,
      "grad_norm": 0.4174247086048126,
      "learning_rate": 2.1396316102198456e-05,
      "loss": 0.0228,
      "step": 13230
    },
    {
      "epoch": 23.60071301247772,
      "grad_norm": 0.5991948246955872,
      "learning_rate": 2.1336898395721928e-05,
      "loss": 0.0229,
      "step": 13240
    },
    {
      "epoch": 23.618538324420676,
      "grad_norm": 0.8747203946113586,
      "learning_rate": 2.1277480689245396e-05,
      "loss": 0.0233,
      "step": 13250
    },
    {
      "epoch": 23.636363636363637,
      "grad_norm": 0.9966761469841003,
      "learning_rate": 2.1218062982768864e-05,
      "loss": 0.0247,
      "step": 13260
    },
    {
      "epoch": 23.654188948306594,
      "grad_norm": 0.43880003690719604,
      "learning_rate": 2.1158645276292336e-05,
      "loss": 0.0226,
      "step": 13270
    },
    {
      "epoch": 23.672014260249554,
      "grad_norm": 0.7134062647819519,
      "learning_rate": 2.1099227569815804e-05,
      "loss": 0.0232,
      "step": 13280
    },
    {
      "epoch": 23.689839572192515,
      "grad_norm": 0.4437749683856964,
      "learning_rate": 2.1039809863339276e-05,
      "loss": 0.0232,
      "step": 13290
    },
    {
      "epoch": 23.707664884135472,
      "grad_norm": 0.6379446983337402,
      "learning_rate": 2.0980392156862748e-05,
      "loss": 0.023,
      "step": 13300
    },
    {
      "epoch": 23.725490196078432,
      "grad_norm": 0.5637765526771545,
      "learning_rate": 2.0920974450386216e-05,
      "loss": 0.0238,
      "step": 13310
    },
    {
      "epoch": 23.74331550802139,
      "grad_norm": 0.45713165402412415,
      "learning_rate": 2.0861556743909684e-05,
      "loss": 0.0223,
      "step": 13320
    },
    {
      "epoch": 23.76114081996435,
      "grad_norm": 0.4322783052921295,
      "learning_rate": 2.0802139037433156e-05,
      "loss": 0.0225,
      "step": 13330
    },
    {
      "epoch": 23.778966131907307,
      "grad_norm": 0.7534627318382263,
      "learning_rate": 2.0742721330956628e-05,
      "loss": 0.0233,
      "step": 13340
    },
    {
      "epoch": 23.796791443850267,
      "grad_norm": 0.5950771570205688,
      "learning_rate": 2.0683303624480096e-05,
      "loss": 0.0233,
      "step": 13350
    },
    {
      "epoch": 23.814616755793228,
      "grad_norm": 0.729203999042511,
      "learning_rate": 2.0623885918003564e-05,
      "loss": 0.0237,
      "step": 13360
    },
    {
      "epoch": 23.832442067736185,
      "grad_norm": 0.48573341965675354,
      "learning_rate": 2.0564468211527036e-05,
      "loss": 0.0229,
      "step": 13370
    },
    {
      "epoch": 23.850267379679146,
      "grad_norm": 0.45371532440185547,
      "learning_rate": 2.0505050505050504e-05,
      "loss": 0.023,
      "step": 13380
    },
    {
      "epoch": 23.868092691622103,
      "grad_norm": 0.5434598326683044,
      "learning_rate": 2.0445632798573976e-05,
      "loss": 0.0224,
      "step": 13390
    },
    {
      "epoch": 23.885918003565063,
      "grad_norm": 0.40131455659866333,
      "learning_rate": 2.0386215092097448e-05,
      "loss": 0.0221,
      "step": 13400
    },
    {
      "epoch": 23.90374331550802,
      "grad_norm": 1.0455032587051392,
      "learning_rate": 2.0326797385620916e-05,
      "loss": 0.0237,
      "step": 13410
    },
    {
      "epoch": 23.92156862745098,
      "grad_norm": 0.6304248571395874,
      "learning_rate": 2.0267379679144384e-05,
      "loss": 0.023,
      "step": 13420
    },
    {
      "epoch": 23.939393939393938,
      "grad_norm": 0.8313176035881042,
      "learning_rate": 2.0207961972667856e-05,
      "loss": 0.0227,
      "step": 13430
    },
    {
      "epoch": 23.9572192513369,
      "grad_norm": 1.0301480293273926,
      "learning_rate": 2.0148544266191328e-05,
      "loss": 0.023,
      "step": 13440
    },
    {
      "epoch": 23.97504456327986,
      "grad_norm": 0.6757909655570984,
      "learning_rate": 2.0089126559714796e-05,
      "loss": 0.022,
      "step": 13450
    },
    {
      "epoch": 23.992869875222816,
      "grad_norm": 0.5960804224014282,
      "learning_rate": 2.0029708853238267e-05,
      "loss": 0.0236,
      "step": 13460
    },
    {
      "epoch": 24.010695187165776,
      "grad_norm": 0.445058137178421,
      "learning_rate": 1.9970291146761736e-05,
      "loss": 0.0228,
      "step": 13470
    },
    {
      "epoch": 24.028520499108733,
      "grad_norm": 0.5468147397041321,
      "learning_rate": 1.9910873440285204e-05,
      "loss": 0.023,
      "step": 13480
    },
    {
      "epoch": 24.046345811051694,
      "grad_norm": 0.7884350419044495,
      "learning_rate": 1.9851455733808676e-05,
      "loss": 0.0221,
      "step": 13490
    },
    {
      "epoch": 24.06417112299465,
      "grad_norm": 0.4920803904533386,
      "learning_rate": 1.9792038027332147e-05,
      "loss": 0.0221,
      "step": 13500
    },
    {
      "epoch": 24.08199643493761,
      "grad_norm": 1.003329873085022,
      "learning_rate": 1.9732620320855616e-05,
      "loss": 0.0225,
      "step": 13510
    },
    {
      "epoch": 24.099821746880572,
      "grad_norm": 0.42408987879753113,
      "learning_rate": 1.9673202614379084e-05,
      "loss": 0.0228,
      "step": 13520
    },
    {
      "epoch": 24.11764705882353,
      "grad_norm": 0.6706013083457947,
      "learning_rate": 1.9613784907902556e-05,
      "loss": 0.0224,
      "step": 13530
    },
    {
      "epoch": 24.13547237076649,
      "grad_norm": 0.56781005859375,
      "learning_rate": 1.9554367201426027e-05,
      "loss": 0.0241,
      "step": 13540
    },
    {
      "epoch": 24.153297682709447,
      "grad_norm": 0.5856183171272278,
      "learning_rate": 1.9494949494949496e-05,
      "loss": 0.0221,
      "step": 13550
    },
    {
      "epoch": 24.171122994652407,
      "grad_norm": 0.7116207480430603,
      "learning_rate": 1.9435531788472967e-05,
      "loss": 0.023,
      "step": 13560
    },
    {
      "epoch": 24.188948306595364,
      "grad_norm": 0.33307331800460815,
      "learning_rate": 1.9376114081996436e-05,
      "loss": 0.0218,
      "step": 13570
    },
    {
      "epoch": 24.206773618538325,
      "grad_norm": 0.6690893769264221,
      "learning_rate": 1.9316696375519904e-05,
      "loss": 0.0228,
      "step": 13580
    },
    {
      "epoch": 24.224598930481285,
      "grad_norm": 0.4956032335758209,
      "learning_rate": 1.9257278669043376e-05,
      "loss": 0.023,
      "step": 13590
    },
    {
      "epoch": 24.242424242424242,
      "grad_norm": 0.5469822287559509,
      "learning_rate": 1.9197860962566847e-05,
      "loss": 0.0228,
      "step": 13600
    },
    {
      "epoch": 24.260249554367203,
      "grad_norm": 0.37210237979888916,
      "learning_rate": 1.9138443256090316e-05,
      "loss": 0.023,
      "step": 13610
    },
    {
      "epoch": 24.27807486631016,
      "grad_norm": 0.6843628883361816,
      "learning_rate": 1.9079025549613784e-05,
      "loss": 0.0228,
      "step": 13620
    },
    {
      "epoch": 24.29590017825312,
      "grad_norm": 0.2452218234539032,
      "learning_rate": 1.9019607843137255e-05,
      "loss": 0.0226,
      "step": 13630
    },
    {
      "epoch": 24.313725490196077,
      "grad_norm": 0.26828494668006897,
      "learning_rate": 1.8960190136660727e-05,
      "loss": 0.0227,
      "step": 13640
    },
    {
      "epoch": 24.331550802139038,
      "grad_norm": 0.25784537196159363,
      "learning_rate": 1.8900772430184195e-05,
      "loss": 0.0223,
      "step": 13650
    },
    {
      "epoch": 24.349376114081995,
      "grad_norm": 0.40966179966926575,
      "learning_rate": 1.8841354723707667e-05,
      "loss": 0.0222,
      "step": 13660
    },
    {
      "epoch": 24.367201426024955,
      "grad_norm": 0.40806615352630615,
      "learning_rate": 1.8781937017231135e-05,
      "loss": 0.0223,
      "step": 13670
    },
    {
      "epoch": 24.385026737967916,
      "grad_norm": 0.4236334562301636,
      "learning_rate": 1.8722519310754604e-05,
      "loss": 0.0229,
      "step": 13680
    },
    {
      "epoch": 24.402852049910873,
      "grad_norm": 0.48253729939460754,
      "learning_rate": 1.8663101604278075e-05,
      "loss": 0.0222,
      "step": 13690
    },
    {
      "epoch": 24.420677361853834,
      "grad_norm": 0.705000638961792,
      "learning_rate": 1.8603683897801547e-05,
      "loss": 0.0223,
      "step": 13700
    },
    {
      "epoch": 24.43850267379679,
      "grad_norm": 0.5805022716522217,
      "learning_rate": 1.8544266191325015e-05,
      "loss": 0.0228,
      "step": 13710
    },
    {
      "epoch": 24.45632798573975,
      "grad_norm": 0.3652605712413788,
      "learning_rate": 1.8484848484848487e-05,
      "loss": 0.0223,
      "step": 13720
    },
    {
      "epoch": 24.474153297682708,
      "grad_norm": 0.8204428553581238,
      "learning_rate": 1.8425430778371955e-05,
      "loss": 0.0224,
      "step": 13730
    },
    {
      "epoch": 24.49197860962567,
      "grad_norm": 0.4142780005931854,
      "learning_rate": 1.8366013071895427e-05,
      "loss": 0.0224,
      "step": 13740
    },
    {
      "epoch": 24.509803921568626,
      "grad_norm": 0.4856688976287842,
      "learning_rate": 1.8306595365418895e-05,
      "loss": 0.0229,
      "step": 13750
    },
    {
      "epoch": 24.527629233511586,
      "grad_norm": 0.5481229424476624,
      "learning_rate": 1.8247177658942367e-05,
      "loss": 0.023,
      "step": 13760
    },
    {
      "epoch": 24.545454545454547,
      "grad_norm": 0.309293657541275,
      "learning_rate": 1.8187759952465835e-05,
      "loss": 0.0227,
      "step": 13770
    },
    {
      "epoch": 24.563279857397504,
      "grad_norm": 0.6855069994926453,
      "learning_rate": 1.8128342245989304e-05,
      "loss": 0.0227,
      "step": 13780
    },
    {
      "epoch": 24.581105169340464,
      "grad_norm": 1.4473984241485596,
      "learning_rate": 1.8068924539512775e-05,
      "loss": 0.0228,
      "step": 13790
    },
    {
      "epoch": 24.59893048128342,
      "grad_norm": 0.4296903908252716,
      "learning_rate": 1.8009506833036247e-05,
      "loss": 0.0224,
      "step": 13800
    },
    {
      "epoch": 24.616755793226382,
      "grad_norm": 0.7521941065788269,
      "learning_rate": 1.7950089126559715e-05,
      "loss": 0.0221,
      "step": 13810
    },
    {
      "epoch": 24.63458110516934,
      "grad_norm": 0.4597548246383667,
      "learning_rate": 1.7890671420083187e-05,
      "loss": 0.0228,
      "step": 13820
    },
    {
      "epoch": 24.6524064171123,
      "grad_norm": 0.5398657321929932,
      "learning_rate": 1.7831253713606655e-05,
      "loss": 0.0225,
      "step": 13830
    },
    {
      "epoch": 24.67023172905526,
      "grad_norm": 0.5215002298355103,
      "learning_rate": 1.7771836007130123e-05,
      "loss": 0.023,
      "step": 13840
    },
    {
      "epoch": 24.688057040998217,
      "grad_norm": 0.3087558150291443,
      "learning_rate": 1.7712418300653595e-05,
      "loss": 0.0231,
      "step": 13850
    },
    {
      "epoch": 24.705882352941178,
      "grad_norm": 1.073104739189148,
      "learning_rate": 1.7653000594177067e-05,
      "loss": 0.0223,
      "step": 13860
    },
    {
      "epoch": 24.723707664884135,
      "grad_norm": 0.8557291626930237,
      "learning_rate": 1.7593582887700535e-05,
      "loss": 0.0226,
      "step": 13870
    },
    {
      "epoch": 24.741532976827095,
      "grad_norm": 0.5013067126274109,
      "learning_rate": 1.7534165181224003e-05,
      "loss": 0.0231,
      "step": 13880
    },
    {
      "epoch": 24.759358288770052,
      "grad_norm": 0.48188912868499756,
      "learning_rate": 1.7474747474747475e-05,
      "loss": 0.0229,
      "step": 13890
    },
    {
      "epoch": 24.777183600713013,
      "grad_norm": 0.29568853974342346,
      "learning_rate": 1.7415329768270947e-05,
      "loss": 0.0231,
      "step": 13900
    },
    {
      "epoch": 24.795008912655973,
      "grad_norm": 0.5524558424949646,
      "learning_rate": 1.7355912061794415e-05,
      "loss": 0.0228,
      "step": 13910
    },
    {
      "epoch": 24.81283422459893,
      "grad_norm": 0.2665739357471466,
      "learning_rate": 1.7296494355317887e-05,
      "loss": 0.0228,
      "step": 13920
    },
    {
      "epoch": 24.83065953654189,
      "grad_norm": 0.7295188903808594,
      "learning_rate": 1.7237076648841355e-05,
      "loss": 0.0225,
      "step": 13930
    },
    {
      "epoch": 24.848484848484848,
      "grad_norm": 0.2998494803905487,
      "learning_rate": 1.7177658942364823e-05,
      "loss": 0.0221,
      "step": 13940
    },
    {
      "epoch": 24.86631016042781,
      "grad_norm": 0.5879579186439514,
      "learning_rate": 1.7118241235888295e-05,
      "loss": 0.0228,
      "step": 13950
    },
    {
      "epoch": 24.884135472370765,
      "grad_norm": 0.6001295447349548,
      "learning_rate": 1.7058823529411767e-05,
      "loss": 0.0219,
      "step": 13960
    },
    {
      "epoch": 24.901960784313726,
      "grad_norm": 0.566936731338501,
      "learning_rate": 1.6999405822935235e-05,
      "loss": 0.0224,
      "step": 13970
    },
    {
      "epoch": 24.919786096256683,
      "grad_norm": 0.4829488694667816,
      "learning_rate": 1.6939988116458707e-05,
      "loss": 0.0216,
      "step": 13980
    },
    {
      "epoch": 24.937611408199643,
      "grad_norm": 0.6367818117141724,
      "learning_rate": 1.6880570409982175e-05,
      "loss": 0.0225,
      "step": 13990
    },
    {
      "epoch": 24.955436720142604,
      "grad_norm": 0.3437322676181793,
      "learning_rate": 1.6821152703505647e-05,
      "loss": 0.0222,
      "step": 14000
    },
    {
      "epoch": 24.97326203208556,
      "grad_norm": 0.7854524254798889,
      "learning_rate": 1.6761734997029115e-05,
      "loss": 0.0223,
      "step": 14010
    },
    {
      "epoch": 24.99108734402852,
      "grad_norm": 0.5349087715148926,
      "learning_rate": 1.6702317290552586e-05,
      "loss": 0.0232,
      "step": 14020
    },
    {
      "epoch": 25.00891265597148,
      "grad_norm": 0.9063863158226013,
      "learning_rate": 1.6642899584076055e-05,
      "loss": 0.0234,
      "step": 14030
    },
    {
      "epoch": 25.02673796791444,
      "grad_norm": 0.49528610706329346,
      "learning_rate": 1.6583481877599523e-05,
      "loss": 0.0222,
      "step": 14040
    },
    {
      "epoch": 25.044563279857396,
      "grad_norm": 0.3252653181552887,
      "learning_rate": 1.6524064171122998e-05,
      "loss": 0.0229,
      "step": 14050
    },
    {
      "epoch": 25.062388591800357,
      "grad_norm": 0.5592960715293884,
      "learning_rate": 1.6464646464646466e-05,
      "loss": 0.0233,
      "step": 14060
    },
    {
      "epoch": 25.080213903743317,
      "grad_norm": 0.5922426581382751,
      "learning_rate": 1.6405228758169935e-05,
      "loss": 0.0231,
      "step": 14070
    },
    {
      "epoch": 25.098039215686274,
      "grad_norm": 0.6914004683494568,
      "learning_rate": 1.6345811051693406e-05,
      "loss": 0.0223,
      "step": 14080
    },
    {
      "epoch": 25.115864527629235,
      "grad_norm": 0.536574125289917,
      "learning_rate": 1.6286393345216875e-05,
      "loss": 0.0225,
      "step": 14090
    },
    {
      "epoch": 25.13368983957219,
      "grad_norm": 0.4101329743862152,
      "learning_rate": 1.6226975638740346e-05,
      "loss": 0.0217,
      "step": 14100
    },
    {
      "epoch": 25.151515151515152,
      "grad_norm": 0.5112344026565552,
      "learning_rate": 1.6167557932263815e-05,
      "loss": 0.022,
      "step": 14110
    },
    {
      "epoch": 25.16934046345811,
      "grad_norm": 0.43931642174720764,
      "learning_rate": 1.6108140225787286e-05,
      "loss": 0.0217,
      "step": 14120
    },
    {
      "epoch": 25.18716577540107,
      "grad_norm": 0.2825469970703125,
      "learning_rate": 1.6048722519310755e-05,
      "loss": 0.0219,
      "step": 14130
    },
    {
      "epoch": 25.204991087344027,
      "grad_norm": 0.5934768319129944,
      "learning_rate": 1.5989304812834223e-05,
      "loss": 0.0219,
      "step": 14140
    },
    {
      "epoch": 25.222816399286987,
      "grad_norm": 0.7071608304977417,
      "learning_rate": 1.5929887106357698e-05,
      "loss": 0.022,
      "step": 14150
    },
    {
      "epoch": 25.240641711229948,
      "grad_norm": 0.8783279657363892,
      "learning_rate": 1.5870469399881166e-05,
      "loss": 0.0223,
      "step": 14160
    },
    {
      "epoch": 25.258467023172905,
      "grad_norm": 0.5293560028076172,
      "learning_rate": 1.5811051693404635e-05,
      "loss": 0.0221,
      "step": 14170
    },
    {
      "epoch": 25.276292335115865,
      "grad_norm": 0.5738316178321838,
      "learning_rate": 1.5751633986928106e-05,
      "loss": 0.0222,
      "step": 14180
    },
    {
      "epoch": 25.294117647058822,
      "grad_norm": 0.3342885971069336,
      "learning_rate": 1.5692216280451574e-05,
      "loss": 0.0216,
      "step": 14190
    },
    {
      "epoch": 25.311942959001783,
      "grad_norm": 0.4017432928085327,
      "learning_rate": 1.5632798573975046e-05,
      "loss": 0.0226,
      "step": 14200
    },
    {
      "epoch": 25.32976827094474,
      "grad_norm": 0.40328365564346313,
      "learning_rate": 1.5573380867498514e-05,
      "loss": 0.0225,
      "step": 14210
    },
    {
      "epoch": 25.3475935828877,
      "grad_norm": 0.7030369639396667,
      "learning_rate": 1.5513963161021986e-05,
      "loss": 0.0219,
      "step": 14220
    },
    {
      "epoch": 25.36541889483066,
      "grad_norm": 0.48852846026420593,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.0225,
      "step": 14230
    },
    {
      "epoch": 25.383244206773618,
      "grad_norm": 0.9641711711883545,
      "learning_rate": 1.5395127748068923e-05,
      "loss": 0.0215,
      "step": 14240
    },
    {
      "epoch": 25.40106951871658,
      "grad_norm": 0.4044368267059326,
      "learning_rate": 1.5335710041592398e-05,
      "loss": 0.0226,
      "step": 14250
    },
    {
      "epoch": 25.418894830659536,
      "grad_norm": 0.4452405273914337,
      "learning_rate": 1.5276292335115866e-05,
      "loss": 0.022,
      "step": 14260
    },
    {
      "epoch": 25.436720142602496,
      "grad_norm": 0.5253939628601074,
      "learning_rate": 1.5216874628639336e-05,
      "loss": 0.0224,
      "step": 14270
    },
    {
      "epoch": 25.454545454545453,
      "grad_norm": 0.5200715661048889,
      "learning_rate": 1.5157456922162804e-05,
      "loss": 0.0219,
      "step": 14280
    },
    {
      "epoch": 25.472370766488414,
      "grad_norm": 0.31340306997299194,
      "learning_rate": 1.5098039215686274e-05,
      "loss": 0.0221,
      "step": 14290
    },
    {
      "epoch": 25.49019607843137,
      "grad_norm": 0.5240862369537354,
      "learning_rate": 1.5038621509209746e-05,
      "loss": 0.0224,
      "step": 14300
    },
    {
      "epoch": 25.50802139037433,
      "grad_norm": 0.5042916536331177,
      "learning_rate": 1.4979203802733216e-05,
      "loss": 0.0224,
      "step": 14310
    },
    {
      "epoch": 25.525846702317292,
      "grad_norm": 0.6067437529563904,
      "learning_rate": 1.4919786096256686e-05,
      "loss": 0.0223,
      "step": 14320
    },
    {
      "epoch": 25.54367201426025,
      "grad_norm": 0.7033108472824097,
      "learning_rate": 1.4860368389780154e-05,
      "loss": 0.0223,
      "step": 14330
    },
    {
      "epoch": 25.56149732620321,
      "grad_norm": 0.615355372428894,
      "learning_rate": 1.4800950683303624e-05,
      "loss": 0.0221,
      "step": 14340
    },
    {
      "epoch": 25.579322638146166,
      "grad_norm": 0.32856112718582153,
      "learning_rate": 1.4741532976827096e-05,
      "loss": 0.0222,
      "step": 14350
    },
    {
      "epoch": 25.597147950089127,
      "grad_norm": 0.36396074295043945,
      "learning_rate": 1.4682115270350566e-05,
      "loss": 0.0228,
      "step": 14360
    },
    {
      "epoch": 25.614973262032084,
      "grad_norm": 0.38156214356422424,
      "learning_rate": 1.4622697563874036e-05,
      "loss": 0.0228,
      "step": 14370
    },
    {
      "epoch": 25.632798573975045,
      "grad_norm": 0.527723491191864,
      "learning_rate": 1.4563279857397504e-05,
      "loss": 0.0216,
      "step": 14380
    },
    {
      "epoch": 25.650623885918005,
      "grad_norm": 0.4170253872871399,
      "learning_rate": 1.4503862150920974e-05,
      "loss": 0.0228,
      "step": 14390
    },
    {
      "epoch": 25.668449197860962,
      "grad_norm": 0.6589677929878235,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.023,
      "step": 14400
    },
    {
      "epoch": 25.686274509803923,
      "grad_norm": 0.434704065322876,
      "learning_rate": 1.4385026737967916e-05,
      "loss": 0.0225,
      "step": 14410
    },
    {
      "epoch": 25.70409982174688,
      "grad_norm": 0.23562966287136078,
      "learning_rate": 1.4325609031491386e-05,
      "loss": 0.0224,
      "step": 14420
    },
    {
      "epoch": 25.72192513368984,
      "grad_norm": 0.5719924569129944,
      "learning_rate": 1.4266191325014854e-05,
      "loss": 0.0223,
      "step": 14430
    },
    {
      "epoch": 25.739750445632797,
      "grad_norm": 0.35988348722457886,
      "learning_rate": 1.4206773618538324e-05,
      "loss": 0.0222,
      "step": 14440
    },
    {
      "epoch": 25.757575757575758,
      "grad_norm": 0.4041256606578827,
      "learning_rate": 1.4147355912061794e-05,
      "loss": 0.0227,
      "step": 14450
    },
    {
      "epoch": 25.775401069518715,
      "grad_norm": 0.31138095259666443,
      "learning_rate": 1.4087938205585266e-05,
      "loss": 0.0219,
      "step": 14460
    },
    {
      "epoch": 25.793226381461675,
      "grad_norm": 0.40820616483688354,
      "learning_rate": 1.4028520499108736e-05,
      "loss": 0.0223,
      "step": 14470
    },
    {
      "epoch": 25.811051693404636,
      "grad_norm": 0.378555029630661,
      "learning_rate": 1.3969102792632206e-05,
      "loss": 0.0219,
      "step": 14480
    },
    {
      "epoch": 25.828877005347593,
      "grad_norm": 0.42470669746398926,
      "learning_rate": 1.3909685086155674e-05,
      "loss": 0.0222,
      "step": 14490
    },
    {
      "epoch": 25.846702317290553,
      "grad_norm": 0.6967426538467407,
      "learning_rate": 1.3850267379679144e-05,
      "loss": 0.022,
      "step": 14500
    },
    {
      "epoch": 25.86452762923351,
      "grad_norm": 0.3282931447029114,
      "learning_rate": 1.3790849673202616e-05,
      "loss": 0.022,
      "step": 14510
    },
    {
      "epoch": 25.88235294117647,
      "grad_norm": 0.27829599380493164,
      "learning_rate": 1.3731431966726086e-05,
      "loss": 0.0223,
      "step": 14520
    },
    {
      "epoch": 25.900178253119428,
      "grad_norm": 0.42301926016807556,
      "learning_rate": 1.3672014260249556e-05,
      "loss": 0.0219,
      "step": 14530
    },
    {
      "epoch": 25.91800356506239,
      "grad_norm": 0.5311815738677979,
      "learning_rate": 1.3612596553773024e-05,
      "loss": 0.0216,
      "step": 14540
    },
    {
      "epoch": 25.93582887700535,
      "grad_norm": 0.28279367089271545,
      "learning_rate": 1.3553178847296494e-05,
      "loss": 0.0219,
      "step": 14550
    },
    {
      "epoch": 25.953654188948306,
      "grad_norm": 0.5383850336074829,
      "learning_rate": 1.3493761140819966e-05,
      "loss": 0.0223,
      "step": 14560
    },
    {
      "epoch": 25.971479500891267,
      "grad_norm": 0.4832371175289154,
      "learning_rate": 1.3434343434343436e-05,
      "loss": 0.0217,
      "step": 14570
    },
    {
      "epoch": 25.989304812834224,
      "grad_norm": 0.5463051199913025,
      "learning_rate": 1.3374925727866905e-05,
      "loss": 0.0222,
      "step": 14580
    },
    {
      "epoch": 26.007130124777184,
      "grad_norm": 0.47398748993873596,
      "learning_rate": 1.3315508021390374e-05,
      "loss": 0.0227,
      "step": 14590
    },
    {
      "epoch": 26.02495543672014,
      "grad_norm": 0.34258127212524414,
      "learning_rate": 1.3256090314913844e-05,
      "loss": 0.0216,
      "step": 14600
    },
    {
      "epoch": 26.0427807486631,
      "grad_norm": 0.4270142614841461,
      "learning_rate": 1.3196672608437315e-05,
      "loss": 0.0219,
      "step": 14610
    },
    {
      "epoch": 26.060606060606062,
      "grad_norm": 0.5849161744117737,
      "learning_rate": 1.3137254901960785e-05,
      "loss": 0.0228,
      "step": 14620
    },
    {
      "epoch": 26.07843137254902,
      "grad_norm": 0.5278428792953491,
      "learning_rate": 1.3077837195484255e-05,
      "loss": 0.022,
      "step": 14630
    },
    {
      "epoch": 26.09625668449198,
      "grad_norm": 0.5865882039070129,
      "learning_rate": 1.3018419489007724e-05,
      "loss": 0.0231,
      "step": 14640
    },
    {
      "epoch": 26.114081996434937,
      "grad_norm": 0.5935377478599548,
      "learning_rate": 1.2959001782531194e-05,
      "loss": 0.0226,
      "step": 14650
    },
    {
      "epoch": 26.131907308377897,
      "grad_norm": 0.5120928287506104,
      "learning_rate": 1.2899584076054665e-05,
      "loss": 0.022,
      "step": 14660
    },
    {
      "epoch": 26.149732620320854,
      "grad_norm": 0.6522652506828308,
      "learning_rate": 1.2840166369578135e-05,
      "loss": 0.0211,
      "step": 14670
    },
    {
      "epoch": 26.167557932263815,
      "grad_norm": 0.34947100281715393,
      "learning_rate": 1.2780748663101605e-05,
      "loss": 0.0215,
      "step": 14680
    },
    {
      "epoch": 26.185383244206772,
      "grad_norm": 0.33844465017318726,
      "learning_rate": 1.2721330956625074e-05,
      "loss": 0.0228,
      "step": 14690
    },
    {
      "epoch": 26.203208556149733,
      "grad_norm": 0.3963359594345093,
      "learning_rate": 1.2661913250148544e-05,
      "loss": 0.022,
      "step": 14700
    },
    {
      "epoch": 26.221033868092693,
      "grad_norm": 0.41937899589538574,
      "learning_rate": 1.2602495543672015e-05,
      "loss": 0.0216,
      "step": 14710
    },
    {
      "epoch": 26.23885918003565,
      "grad_norm": 0.6315585970878601,
      "learning_rate": 1.2543077837195485e-05,
      "loss": 0.0218,
      "step": 14720
    },
    {
      "epoch": 26.25668449197861,
      "grad_norm": 0.5298470258712769,
      "learning_rate": 1.2483660130718955e-05,
      "loss": 0.0224,
      "step": 14730
    },
    {
      "epoch": 26.274509803921568,
      "grad_norm": 0.42887282371520996,
      "learning_rate": 1.2424242424242424e-05,
      "loss": 0.022,
      "step": 14740
    },
    {
      "epoch": 26.292335115864528,
      "grad_norm": 0.4300912618637085,
      "learning_rate": 1.2364824717765895e-05,
      "loss": 0.0219,
      "step": 14750
    },
    {
      "epoch": 26.310160427807485,
      "grad_norm": 0.6096655130386353,
      "learning_rate": 1.2305407011289365e-05,
      "loss": 0.0219,
      "step": 14760
    },
    {
      "epoch": 26.327985739750446,
      "grad_norm": 0.6500317454338074,
      "learning_rate": 1.2245989304812835e-05,
      "loss": 0.0226,
      "step": 14770
    },
    {
      "epoch": 26.345811051693406,
      "grad_norm": 0.7458487153053284,
      "learning_rate": 1.2186571598336305e-05,
      "loss": 0.022,
      "step": 14780
    },
    {
      "epoch": 26.363636363636363,
      "grad_norm": 0.2886854410171509,
      "learning_rate": 1.2127153891859775e-05,
      "loss": 0.0222,
      "step": 14790
    },
    {
      "epoch": 26.381461675579324,
      "grad_norm": 0.6743295192718506,
      "learning_rate": 1.2067736185383245e-05,
      "loss": 0.0221,
      "step": 14800
    },
    {
      "epoch": 26.39928698752228,
      "grad_norm": 0.43867227435112,
      "learning_rate": 1.2008318478906715e-05,
      "loss": 0.0217,
      "step": 14810
    },
    {
      "epoch": 26.41711229946524,
      "grad_norm": 0.5269806385040283,
      "learning_rate": 1.1948900772430183e-05,
      "loss": 0.0219,
      "step": 14820
    },
    {
      "epoch": 26.4349376114082,
      "grad_norm": 0.2785399258136749,
      "learning_rate": 1.1889483065953655e-05,
      "loss": 0.0216,
      "step": 14830
    },
    {
      "epoch": 26.45276292335116,
      "grad_norm": 0.35012519359588623,
      "learning_rate": 1.1830065359477125e-05,
      "loss": 0.0226,
      "step": 14840
    },
    {
      "epoch": 26.470588235294116,
      "grad_norm": 0.5733040571212769,
      "learning_rate": 1.1770647653000595e-05,
      "loss": 0.0226,
      "step": 14850
    },
    {
      "epoch": 26.488413547237077,
      "grad_norm": 0.5442931652069092,
      "learning_rate": 1.1711229946524065e-05,
      "loss": 0.0224,
      "step": 14860
    },
    {
      "epoch": 26.506238859180037,
      "grad_norm": 0.5481072664260864,
      "learning_rate": 1.1651812240047533e-05,
      "loss": 0.0219,
      "step": 14870
    },
    {
      "epoch": 26.524064171122994,
      "grad_norm": 0.2597796618938446,
      "learning_rate": 1.1592394533571005e-05,
      "loss": 0.0219,
      "step": 14880
    },
    {
      "epoch": 26.541889483065955,
      "grad_norm": 0.3039034903049469,
      "learning_rate": 1.1532976827094475e-05,
      "loss": 0.0223,
      "step": 14890
    },
    {
      "epoch": 26.55971479500891,
      "grad_norm": 0.4255615472793579,
      "learning_rate": 1.1473559120617945e-05,
      "loss": 0.0218,
      "step": 14900
    },
    {
      "epoch": 26.577540106951872,
      "grad_norm": 0.30959945917129517,
      "learning_rate": 1.1414141414141415e-05,
      "loss": 0.0224,
      "step": 14910
    },
    {
      "epoch": 26.59536541889483,
      "grad_norm": 0.651282548904419,
      "learning_rate": 1.1354723707664885e-05,
      "loss": 0.0221,
      "step": 14920
    },
    {
      "epoch": 26.61319073083779,
      "grad_norm": 0.787594199180603,
      "learning_rate": 1.1295306001188355e-05,
      "loss": 0.0226,
      "step": 14930
    },
    {
      "epoch": 26.63101604278075,
      "grad_norm": 0.4366743862628937,
      "learning_rate": 1.1235888294711825e-05,
      "loss": 0.0225,
      "step": 14940
    },
    {
      "epoch": 26.648841354723707,
      "grad_norm": 1.0937777757644653,
      "learning_rate": 1.1176470588235295e-05,
      "loss": 0.0228,
      "step": 14950
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 0.7340276837348938,
      "learning_rate": 1.1117052881758765e-05,
      "loss": 0.0223,
      "step": 14960
    },
    {
      "epoch": 26.684491978609625,
      "grad_norm": 0.45133498311042786,
      "learning_rate": 1.1057635175282235e-05,
      "loss": 0.0231,
      "step": 14970
    },
    {
      "epoch": 26.702317290552585,
      "grad_norm": 0.35327890515327454,
      "learning_rate": 1.0998217468805705e-05,
      "loss": 0.0223,
      "step": 14980
    },
    {
      "epoch": 26.720142602495542,
      "grad_norm": 0.415360689163208,
      "learning_rate": 1.0938799762329175e-05,
      "loss": 0.0218,
      "step": 14990
    },
    {
      "epoch": 26.737967914438503,
      "grad_norm": 0.3643271327018738,
      "learning_rate": 1.0879382055852645e-05,
      "loss": 0.0219,
      "step": 15000
    },
    {
      "epoch": 26.75579322638146,
      "grad_norm": 0.4491073191165924,
      "learning_rate": 1.0819964349376115e-05,
      "loss": 0.022,
      "step": 15010
    },
    {
      "epoch": 26.77361853832442,
      "grad_norm": 0.36058199405670166,
      "learning_rate": 1.0760546642899585e-05,
      "loss": 0.0216,
      "step": 15020
    },
    {
      "epoch": 26.79144385026738,
      "grad_norm": 0.6139973998069763,
      "learning_rate": 1.0701128936423055e-05,
      "loss": 0.0211,
      "step": 15030
    },
    {
      "epoch": 26.809269162210338,
      "grad_norm": 0.6430187225341797,
      "learning_rate": 1.0641711229946525e-05,
      "loss": 0.0216,
      "step": 15040
    },
    {
      "epoch": 26.8270944741533,
      "grad_norm": 0.5550872683525085,
      "learning_rate": 1.0582293523469995e-05,
      "loss": 0.0218,
      "step": 15050
    },
    {
      "epoch": 26.844919786096256,
      "grad_norm": 0.5105137228965759,
      "learning_rate": 1.0522875816993465e-05,
      "loss": 0.0214,
      "step": 15060
    },
    {
      "epoch": 26.862745098039216,
      "grad_norm": 1.0924735069274902,
      "learning_rate": 1.0463458110516935e-05,
      "loss": 0.0214,
      "step": 15070
    },
    {
      "epoch": 26.880570409982173,
      "grad_norm": 0.3733151853084564,
      "learning_rate": 1.0404040404040405e-05,
      "loss": 0.0221,
      "step": 15080
    },
    {
      "epoch": 26.898395721925134,
      "grad_norm": 0.44628027081489563,
      "learning_rate": 1.0344622697563875e-05,
      "loss": 0.0214,
      "step": 15090
    },
    {
      "epoch": 26.916221033868094,
      "grad_norm": 0.7889026999473572,
      "learning_rate": 1.0285204991087345e-05,
      "loss": 0.0222,
      "step": 15100
    },
    {
      "epoch": 26.93404634581105,
      "grad_norm": 0.532977283000946,
      "learning_rate": 1.0225787284610815e-05,
      "loss": 0.0215,
      "step": 15110
    },
    {
      "epoch": 26.951871657754012,
      "grad_norm": 0.34031248092651367,
      "learning_rate": 1.0166369578134285e-05,
      "loss": 0.0224,
      "step": 15120
    },
    {
      "epoch": 26.96969696969697,
      "grad_norm": 0.4752245545387268,
      "learning_rate": 1.0106951871657755e-05,
      "loss": 0.0216,
      "step": 15130
    },
    {
      "epoch": 26.98752228163993,
      "grad_norm": 0.5331142544746399,
      "learning_rate": 1.0047534165181224e-05,
      "loss": 0.0215,
      "step": 15140
    },
    {
      "epoch": 27.005347593582886,
      "grad_norm": 0.3935561180114746,
      "learning_rate": 9.988116458704694e-06,
      "loss": 0.0212,
      "step": 15150
    },
    {
      "epoch": 27.023172905525847,
      "grad_norm": 0.2761416435241699,
      "learning_rate": 9.928698752228164e-06,
      "loss": 0.0217,
      "step": 15160
    },
    {
      "epoch": 27.040998217468804,
      "grad_norm": 0.643003523349762,
      "learning_rate": 9.869281045751634e-06,
      "loss": 0.0225,
      "step": 15170
    },
    {
      "epoch": 27.058823529411764,
      "grad_norm": 0.31428998708724976,
      "learning_rate": 9.809863339275104e-06,
      "loss": 0.0217,
      "step": 15180
    },
    {
      "epoch": 27.076648841354725,
      "grad_norm": 0.5596680641174316,
      "learning_rate": 9.750445632798574e-06,
      "loss": 0.022,
      "step": 15190
    },
    {
      "epoch": 27.094474153297682,
      "grad_norm": 0.7673013210296631,
      "learning_rate": 9.691027926322044e-06,
      "loss": 0.0226,
      "step": 15200
    },
    {
      "epoch": 27.112299465240643,
      "grad_norm": 0.697239100933075,
      "learning_rate": 9.631610219845514e-06,
      "loss": 0.0217,
      "step": 15210
    },
    {
      "epoch": 27.1301247771836,
      "grad_norm": 0.43285515904426575,
      "learning_rate": 9.572192513368984e-06,
      "loss": 0.0213,
      "step": 15220
    },
    {
      "epoch": 27.14795008912656,
      "grad_norm": 0.4435773491859436,
      "learning_rate": 9.512774806892454e-06,
      "loss": 0.0219,
      "step": 15230
    },
    {
      "epoch": 27.165775401069517,
      "grad_norm": 0.6129087805747986,
      "learning_rate": 9.453357100415924e-06,
      "loss": 0.0218,
      "step": 15240
    },
    {
      "epoch": 27.183600713012478,
      "grad_norm": 0.49719735980033875,
      "learning_rate": 9.393939393939394e-06,
      "loss": 0.0218,
      "step": 15250
    },
    {
      "epoch": 27.20142602495544,
      "grad_norm": 0.3980439603328705,
      "learning_rate": 9.334521687462864e-06,
      "loss": 0.0214,
      "step": 15260
    },
    {
      "epoch": 27.219251336898395,
      "grad_norm": 0.5092481374740601,
      "learning_rate": 9.275103980986334e-06,
      "loss": 0.0219,
      "step": 15270
    },
    {
      "epoch": 27.237076648841356,
      "grad_norm": 0.6071674227714539,
      "learning_rate": 9.215686274509804e-06,
      "loss": 0.023,
      "step": 15280
    },
    {
      "epoch": 27.254901960784313,
      "grad_norm": 0.28061002492904663,
      "learning_rate": 9.156268568033274e-06,
      "loss": 0.0217,
      "step": 15290
    },
    {
      "epoch": 27.272727272727273,
      "grad_norm": 0.2224428802728653,
      "learning_rate": 9.096850861556744e-06,
      "loss": 0.0217,
      "step": 15300
    },
    {
      "epoch": 27.29055258467023,
      "grad_norm": 0.501205325126648,
      "learning_rate": 9.037433155080214e-06,
      "loss": 0.0224,
      "step": 15310
    },
    {
      "epoch": 27.30837789661319,
      "grad_norm": 0.3019079267978668,
      "learning_rate": 8.978015448603684e-06,
      "loss": 0.0211,
      "step": 15320
    },
    {
      "epoch": 27.32620320855615,
      "grad_norm": 0.4703688621520996,
      "learning_rate": 8.918597742127154e-06,
      "loss": 0.0218,
      "step": 15330
    },
    {
      "epoch": 27.34402852049911,
      "grad_norm": 0.7428877949714661,
      "learning_rate": 8.859180035650624e-06,
      "loss": 0.0222,
      "step": 15340
    },
    {
      "epoch": 27.36185383244207,
      "grad_norm": 0.40817147493362427,
      "learning_rate": 8.799762329174094e-06,
      "loss": 0.0222,
      "step": 15350
    },
    {
      "epoch": 27.379679144385026,
      "grad_norm": 0.3383435010910034,
      "learning_rate": 8.740344622697564e-06,
      "loss": 0.0218,
      "step": 15360
    },
    {
      "epoch": 27.397504456327987,
      "grad_norm": 0.6179685592651367,
      "learning_rate": 8.680926916221034e-06,
      "loss": 0.0223,
      "step": 15370
    },
    {
      "epoch": 27.415329768270944,
      "grad_norm": 0.4440626800060272,
      "learning_rate": 8.621509209744506e-06,
      "loss": 0.0214,
      "step": 15380
    },
    {
      "epoch": 27.433155080213904,
      "grad_norm": 0.4639328420162201,
      "learning_rate": 8.562091503267974e-06,
      "loss": 0.0219,
      "step": 15390
    },
    {
      "epoch": 27.45098039215686,
      "grad_norm": 0.29890602827072144,
      "learning_rate": 8.502673796791444e-06,
      "loss": 0.022,
      "step": 15400
    },
    {
      "epoch": 27.46880570409982,
      "grad_norm": 0.41669079661369324,
      "learning_rate": 8.443256090314914e-06,
      "loss": 0.0219,
      "step": 15410
    },
    {
      "epoch": 27.486631016042782,
      "grad_norm": 0.41046667098999023,
      "learning_rate": 8.383838383838384e-06,
      "loss": 0.0214,
      "step": 15420
    },
    {
      "epoch": 27.50445632798574,
      "grad_norm": 1.199800729751587,
      "learning_rate": 8.324420677361854e-06,
      "loss": 0.0217,
      "step": 15430
    },
    {
      "epoch": 27.5222816399287,
      "grad_norm": 0.41248929500579834,
      "learning_rate": 8.265002970885324e-06,
      "loss": 0.0212,
      "step": 15440
    },
    {
      "epoch": 27.540106951871657,
      "grad_norm": 0.5731416940689087,
      "learning_rate": 8.205585264408794e-06,
      "loss": 0.0218,
      "step": 15450
    },
    {
      "epoch": 27.557932263814617,
      "grad_norm": 0.6272795796394348,
      "learning_rate": 8.146167557932264e-06,
      "loss": 0.0221,
      "step": 15460
    },
    {
      "epoch": 27.575757575757574,
      "grad_norm": 0.46731534600257874,
      "learning_rate": 8.086749851455734e-06,
      "loss": 0.0222,
      "step": 15470
    },
    {
      "epoch": 27.593582887700535,
      "grad_norm": 1.4317141771316528,
      "learning_rate": 8.027332144979204e-06,
      "loss": 0.0221,
      "step": 15480
    },
    {
      "epoch": 27.611408199643495,
      "grad_norm": 0.3623043894767761,
      "learning_rate": 7.967914438502674e-06,
      "loss": 0.0215,
      "step": 15490
    },
    {
      "epoch": 27.629233511586452,
      "grad_norm": 0.37852558493614197,
      "learning_rate": 7.908496732026144e-06,
      "loss": 0.0218,
      "step": 15500
    },
    {
      "epoch": 27.647058823529413,
      "grad_norm": 0.4062255024909973,
      "learning_rate": 7.849079025549614e-06,
      "loss": 0.0216,
      "step": 15510
    },
    {
      "epoch": 27.66488413547237,
      "grad_norm": 0.3807457685470581,
      "learning_rate": 7.789661319073084e-06,
      "loss": 0.0219,
      "step": 15520
    },
    {
      "epoch": 27.68270944741533,
      "grad_norm": 0.3460034132003784,
      "learning_rate": 7.730243612596554e-06,
      "loss": 0.0217,
      "step": 15530
    },
    {
      "epoch": 27.700534759358288,
      "grad_norm": 0.3892567455768585,
      "learning_rate": 7.670825906120024e-06,
      "loss": 0.022,
      "step": 15540
    },
    {
      "epoch": 27.718360071301248,
      "grad_norm": 0.27032217383384705,
      "learning_rate": 7.611408199643494e-06,
      "loss": 0.022,
      "step": 15550
    },
    {
      "epoch": 27.736185383244205,
      "grad_norm": 0.5875421166419983,
      "learning_rate": 7.551990493166965e-06,
      "loss": 0.0211,
      "step": 15560
    },
    {
      "epoch": 27.754010695187166,
      "grad_norm": 0.4126434922218323,
      "learning_rate": 7.492572786690434e-06,
      "loss": 0.0218,
      "step": 15570
    },
    {
      "epoch": 27.771836007130126,
      "grad_norm": 0.42721879482269287,
      "learning_rate": 7.433155080213904e-06,
      "loss": 0.0212,
      "step": 15580
    },
    {
      "epoch": 27.789661319073083,
      "grad_norm": 0.2473200410604477,
      "learning_rate": 7.3737373737373745e-06,
      "loss": 0.0219,
      "step": 15590
    },
    {
      "epoch": 27.807486631016044,
      "grad_norm": 0.2465621829032898,
      "learning_rate": 7.314319667260844e-06,
      "loss": 0.0213,
      "step": 15600
    },
    {
      "epoch": 27.825311942959,
      "grad_norm": 0.8808836936950684,
      "learning_rate": 7.2549019607843145e-06,
      "loss": 0.0222,
      "step": 15610
    },
    {
      "epoch": 27.84313725490196,
      "grad_norm": 0.3081563711166382,
      "learning_rate": 7.1954842543077845e-06,
      "loss": 0.0212,
      "step": 15620
    },
    {
      "epoch": 27.86096256684492,
      "grad_norm": 0.5108317136764526,
      "learning_rate": 7.136066547831254e-06,
      "loss": 0.0211,
      "step": 15630
    },
    {
      "epoch": 27.87878787878788,
      "grad_norm": 0.518297016620636,
      "learning_rate": 7.0766488413547244e-06,
      "loss": 0.0223,
      "step": 15640
    },
    {
      "epoch": 27.89661319073084,
      "grad_norm": 0.34448251128196716,
      "learning_rate": 7.017231134878194e-06,
      "loss": 0.022,
      "step": 15650
    },
    {
      "epoch": 27.914438502673796,
      "grad_norm": 0.4174068868160248,
      "learning_rate": 6.957813428401664e-06,
      "loss": 0.0215,
      "step": 15660
    },
    {
      "epoch": 27.932263814616757,
      "grad_norm": 0.3618292212486267,
      "learning_rate": 6.898395721925134e-06,
      "loss": 0.0217,
      "step": 15670
    },
    {
      "epoch": 27.950089126559714,
      "grad_norm": 0.20916424691677094,
      "learning_rate": 6.8389780154486035e-06,
      "loss": 0.0215,
      "step": 15680
    },
    {
      "epoch": 27.967914438502675,
      "grad_norm": 0.4883117079734802,
      "learning_rate": 6.779560308972074e-06,
      "loss": 0.0218,
      "step": 15690
    },
    {
      "epoch": 27.98573975044563,
      "grad_norm": 0.3719223141670227,
      "learning_rate": 6.7201426024955435e-06,
      "loss": 0.0215,
      "step": 15700
    },
    {
      "epoch": 28.003565062388592,
      "grad_norm": 0.4281618595123291,
      "learning_rate": 6.660724896019014e-06,
      "loss": 0.022,
      "step": 15710
    },
    {
      "epoch": 28.02139037433155,
      "grad_norm": 0.23633357882499695,
      "learning_rate": 6.601307189542484e-06,
      "loss": 0.0221,
      "step": 15720
    },
    {
      "epoch": 28.03921568627451,
      "grad_norm": 0.36356663703918457,
      "learning_rate": 6.5418894830659534e-06,
      "loss": 0.0212,
      "step": 15730
    },
    {
      "epoch": 28.05704099821747,
      "grad_norm": 0.3189558982849121,
      "learning_rate": 6.482471776589424e-06,
      "loss": 0.0219,
      "step": 15740
    },
    {
      "epoch": 28.074866310160427,
      "grad_norm": 0.6328113675117493,
      "learning_rate": 6.423054070112894e-06,
      "loss": 0.0222,
      "step": 15750
    },
    {
      "epoch": 28.092691622103388,
      "grad_norm": 0.49970743060112,
      "learning_rate": 6.363636363636363e-06,
      "loss": 0.0214,
      "step": 15760
    },
    {
      "epoch": 28.110516934046345,
      "grad_norm": 0.47075292468070984,
      "learning_rate": 6.304218657159834e-06,
      "loss": 0.0214,
      "step": 15770
    },
    {
      "epoch": 28.128342245989305,
      "grad_norm": 0.6919734477996826,
      "learning_rate": 6.244800950683304e-06,
      "loss": 0.0216,
      "step": 15780
    },
    {
      "epoch": 28.146167557932262,
      "grad_norm": 0.41647881269454956,
      "learning_rate": 6.185383244206773e-06,
      "loss": 0.0213,
      "step": 15790
    },
    {
      "epoch": 28.163992869875223,
      "grad_norm": 0.5586234331130981,
      "learning_rate": 6.125965537730244e-06,
      "loss": 0.0215,
      "step": 15800
    },
    {
      "epoch": 28.181818181818183,
      "grad_norm": 0.24268750846385956,
      "learning_rate": 6.066547831253714e-06,
      "loss": 0.0217,
      "step": 15810
    },
    {
      "epoch": 28.19964349376114,
      "grad_norm": 0.3117263615131378,
      "learning_rate": 6.007130124777184e-06,
      "loss": 0.0227,
      "step": 15820
    },
    {
      "epoch": 28.2174688057041,
      "grad_norm": 0.6430842280387878,
      "learning_rate": 5.947712418300653e-06,
      "loss": 0.0224,
      "step": 15830
    },
    {
      "epoch": 28.235294117647058,
      "grad_norm": 0.292048841714859,
      "learning_rate": 5.888294711824124e-06,
      "loss": 0.0213,
      "step": 15840
    },
    {
      "epoch": 28.25311942959002,
      "grad_norm": 1.436435341835022,
      "learning_rate": 5.828877005347594e-06,
      "loss": 0.0219,
      "step": 15850
    },
    {
      "epoch": 28.270944741532976,
      "grad_norm": 0.5918617844581604,
      "learning_rate": 5.769459298871064e-06,
      "loss": 0.022,
      "step": 15860
    },
    {
      "epoch": 28.288770053475936,
      "grad_norm": 0.6546164155006409,
      "learning_rate": 5.710041592394534e-06,
      "loss": 0.0214,
      "step": 15870
    },
    {
      "epoch": 28.306595365418893,
      "grad_norm": 0.49687880277633667,
      "learning_rate": 5.650623885918003e-06,
      "loss": 0.0218,
      "step": 15880
    },
    {
      "epoch": 28.324420677361854,
      "grad_norm": 0.5974608063697815,
      "learning_rate": 5.591206179441474e-06,
      "loss": 0.0218,
      "step": 15890
    },
    {
      "epoch": 28.342245989304814,
      "grad_norm": 0.8623648285865784,
      "learning_rate": 5.531788472964944e-06,
      "loss": 0.0216,
      "step": 15900
    },
    {
      "epoch": 28.36007130124777,
      "grad_norm": 0.29774585366249084,
      "learning_rate": 5.472370766488414e-06,
      "loss": 0.0214,
      "step": 15910
    },
    {
      "epoch": 28.37789661319073,
      "grad_norm": 0.5317196249961853,
      "learning_rate": 5.412953060011884e-06,
      "loss": 0.0218,
      "step": 15920
    },
    {
      "epoch": 28.39572192513369,
      "grad_norm": 0.24216195940971375,
      "learning_rate": 5.353535353535354e-06,
      "loss": 0.0219,
      "step": 15930
    },
    {
      "epoch": 28.41354723707665,
      "grad_norm": 0.8424111604690552,
      "learning_rate": 5.294117647058824e-06,
      "loss": 0.0209,
      "step": 15940
    },
    {
      "epoch": 28.431372549019606,
      "grad_norm": 0.3482751250267029,
      "learning_rate": 5.234699940582294e-06,
      "loss": 0.0217,
      "step": 15950
    },
    {
      "epoch": 28.449197860962567,
      "grad_norm": 0.5279257297515869,
      "learning_rate": 5.175282234105764e-06,
      "loss": 0.022,
      "step": 15960
    },
    {
      "epoch": 28.467023172905527,
      "grad_norm": 0.4863806962966919,
      "learning_rate": 5.115864527629233e-06,
      "loss": 0.0219,
      "step": 15970
    },
    {
      "epoch": 28.484848484848484,
      "grad_norm": 0.6575510501861572,
      "learning_rate": 5.056446821152704e-06,
      "loss": 0.0218,
      "step": 15980
    },
    {
      "epoch": 28.502673796791445,
      "grad_norm": 0.5401616096496582,
      "learning_rate": 4.997029114676174e-06,
      "loss": 0.0222,
      "step": 15990
    },
    {
      "epoch": 28.520499108734402,
      "grad_norm": 0.525390088558197,
      "learning_rate": 4.937611408199644e-06,
      "loss": 0.0213,
      "step": 16000
    },
    {
      "epoch": 28.538324420677363,
      "grad_norm": 0.5011616349220276,
      "learning_rate": 4.878193701723114e-06,
      "loss": 0.0219,
      "step": 16010
    },
    {
      "epoch": 28.55614973262032,
      "grad_norm": 0.2744906544685364,
      "learning_rate": 4.818775995246584e-06,
      "loss": 0.0215,
      "step": 16020
    },
    {
      "epoch": 28.57397504456328,
      "grad_norm": 0.7421084642410278,
      "learning_rate": 4.759358288770054e-06,
      "loss": 0.0215,
      "step": 16030
    },
    {
      "epoch": 28.59180035650624,
      "grad_norm": 0.36819911003112793,
      "learning_rate": 4.699940582293524e-06,
      "loss": 0.0215,
      "step": 16040
    },
    {
      "epoch": 28.609625668449198,
      "grad_norm": 0.2849644720554352,
      "learning_rate": 4.640522875816994e-06,
      "loss": 0.0208,
      "step": 16050
    },
    {
      "epoch": 28.627450980392158,
      "grad_norm": 0.654538094997406,
      "learning_rate": 4.581105169340464e-06,
      "loss": 0.0209,
      "step": 16060
    },
    {
      "epoch": 28.645276292335115,
      "grad_norm": 0.3057691156864166,
      "learning_rate": 4.521687462863934e-06,
      "loss": 0.0219,
      "step": 16070
    },
    {
      "epoch": 28.663101604278076,
      "grad_norm": 0.4420374929904938,
      "learning_rate": 4.462269756387404e-06,
      "loss": 0.022,
      "step": 16080
    },
    {
      "epoch": 28.680926916221033,
      "grad_norm": 0.5201065540313721,
      "learning_rate": 4.402852049910874e-06,
      "loss": 0.0219,
      "step": 16090
    },
    {
      "epoch": 28.698752228163993,
      "grad_norm": 0.34450939297676086,
      "learning_rate": 4.343434343434344e-06,
      "loss": 0.0212,
      "step": 16100
    },
    {
      "epoch": 28.71657754010695,
      "grad_norm": 0.27223992347717285,
      "learning_rate": 4.284016636957814e-06,
      "loss": 0.022,
      "step": 16110
    },
    {
      "epoch": 28.73440285204991,
      "grad_norm": 0.27604207396507263,
      "learning_rate": 4.224598930481284e-06,
      "loss": 0.0208,
      "step": 16120
    },
    {
      "epoch": 28.75222816399287,
      "grad_norm": 0.38411933183670044,
      "learning_rate": 4.1651812240047536e-06,
      "loss": 0.0219,
      "step": 16130
    },
    {
      "epoch": 28.77005347593583,
      "grad_norm": 0.37881967425346375,
      "learning_rate": 4.1057635175282236e-06,
      "loss": 0.0217,
      "step": 16140
    },
    {
      "epoch": 28.78787878787879,
      "grad_norm": 0.2848922610282898,
      "learning_rate": 4.0463458110516935e-06,
      "loss": 0.0216,
      "step": 16150
    },
    {
      "epoch": 28.805704099821746,
      "grad_norm": 0.4213026762008667,
      "learning_rate": 3.9869281045751635e-06,
      "loss": 0.0213,
      "step": 16160
    },
    {
      "epoch": 28.823529411764707,
      "grad_norm": 0.22939284145832062,
      "learning_rate": 3.9275103980986335e-06,
      "loss": 0.0213,
      "step": 16170
    },
    {
      "epoch": 28.841354723707664,
      "grad_norm": 0.4084823429584503,
      "learning_rate": 3.8680926916221035e-06,
      "loss": 0.0214,
      "step": 16180
    },
    {
      "epoch": 28.859180035650624,
      "grad_norm": 0.6608166098594666,
      "learning_rate": 3.808674985145574e-06,
      "loss": 0.0216,
      "step": 16190
    },
    {
      "epoch": 28.87700534759358,
      "grad_norm": 0.4459187686443329,
      "learning_rate": 3.749257278669044e-06,
      "loss": 0.0217,
      "step": 16200
    },
    {
      "epoch": 28.89483065953654,
      "grad_norm": 0.4114609658718109,
      "learning_rate": 3.6898395721925134e-06,
      "loss": 0.0218,
      "step": 16210
    },
    {
      "epoch": 28.912655971479502,
      "grad_norm": 0.3566928505897522,
      "learning_rate": 3.6304218657159834e-06,
      "loss": 0.0214,
      "step": 16220
    },
    {
      "epoch": 28.93048128342246,
      "grad_norm": 0.5033572316169739,
      "learning_rate": 3.5710041592394534e-06,
      "loss": 0.021,
      "step": 16230
    },
    {
      "epoch": 28.94830659536542,
      "grad_norm": 0.5317918658256531,
      "learning_rate": 3.511586452762924e-06,
      "loss": 0.0216,
      "step": 16240
    },
    {
      "epoch": 28.966131907308377,
      "grad_norm": 0.3955402970314026,
      "learning_rate": 3.4521687462863934e-06,
      "loss": 0.0215,
      "step": 16250
    },
    {
      "epoch": 28.983957219251337,
      "grad_norm": 0.7258318066596985,
      "learning_rate": 3.3927510398098633e-06,
      "loss": 0.0216,
      "step": 16260
    },
    {
      "epoch": 29.001782531194294,
      "grad_norm": 0.3208463788032532,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0232,
      "step": 16270
    },
    {
      "epoch": 29.019607843137255,
      "grad_norm": 0.39453479647636414,
      "learning_rate": 3.2739156268568037e-06,
      "loss": 0.0211,
      "step": 16280
    },
    {
      "epoch": 29.037433155080215,
      "grad_norm": 0.35431867837905884,
      "learning_rate": 3.2144979203802737e-06,
      "loss": 0.0216,
      "step": 16290
    },
    {
      "epoch": 29.055258467023172,
      "grad_norm": 0.28703323006629944,
      "learning_rate": 3.1550802139037433e-06,
      "loss": 0.0217,
      "step": 16300
    },
    {
      "epoch": 29.073083778966133,
      "grad_norm": 0.26101064682006836,
      "learning_rate": 3.0956625074272133e-06,
      "loss": 0.0211,
      "step": 16310
    },
    {
      "epoch": 29.09090909090909,
      "grad_norm": 0.4217248260974884,
      "learning_rate": 3.0362448009506837e-06,
      "loss": 0.0218,
      "step": 16320
    },
    {
      "epoch": 29.10873440285205,
      "grad_norm": 0.6147971153259277,
      "learning_rate": 2.9768270944741536e-06,
      "loss": 0.022,
      "step": 16330
    },
    {
      "epoch": 29.126559714795007,
      "grad_norm": 0.3169318437576294,
      "learning_rate": 2.917409387997623e-06,
      "loss": 0.0215,
      "step": 16340
    },
    {
      "epoch": 29.144385026737968,
      "grad_norm": 0.3078182339668274,
      "learning_rate": 2.8579916815210936e-06,
      "loss": 0.0216,
      "step": 16350
    },
    {
      "epoch": 29.16221033868093,
      "grad_norm": 0.2862947881221771,
      "learning_rate": 2.798573975044563e-06,
      "loss": 0.0213,
      "step": 16360
    },
    {
      "epoch": 29.180035650623886,
      "grad_norm": 0.41099968552589417,
      "learning_rate": 2.7391562685680336e-06,
      "loss": 0.021,
      "step": 16370
    },
    {
      "epoch": 29.197860962566846,
      "grad_norm": 0.27192258834838867,
      "learning_rate": 2.679738562091503e-06,
      "loss": 0.0215,
      "step": 16380
    },
    {
      "epoch": 29.215686274509803,
      "grad_norm": 0.35578683018684387,
      "learning_rate": 2.6203208556149735e-06,
      "loss": 0.0213,
      "step": 16390
    },
    {
      "epoch": 29.233511586452764,
      "grad_norm": 0.3851529359817505,
      "learning_rate": 2.5609031491384435e-06,
      "loss": 0.0214,
      "step": 16400
    },
    {
      "epoch": 29.25133689839572,
      "grad_norm": 0.969925045967102,
      "learning_rate": 2.5014854426619135e-06,
      "loss": 0.0212,
      "step": 16410
    },
    {
      "epoch": 29.26916221033868,
      "grad_norm": 0.2244168519973755,
      "learning_rate": 2.4420677361853835e-06,
      "loss": 0.0212,
      "step": 16420
    },
    {
      "epoch": 29.28698752228164,
      "grad_norm": 0.4020702540874481,
      "learning_rate": 2.382650029708853e-06,
      "loss": 0.0209,
      "step": 16430
    },
    {
      "epoch": 29.3048128342246,
      "grad_norm": 0.48335936665534973,
      "learning_rate": 2.3232323232323234e-06,
      "loss": 0.0211,
      "step": 16440
    },
    {
      "epoch": 29.32263814616756,
      "grad_norm": 0.36048588156700134,
      "learning_rate": 2.263814616755793e-06,
      "loss": 0.0214,
      "step": 16450
    },
    {
      "epoch": 29.340463458110516,
      "grad_norm": 0.5299460887908936,
      "learning_rate": 2.2043969102792634e-06,
      "loss": 0.0215,
      "step": 16460
    },
    {
      "epoch": 29.358288770053477,
      "grad_norm": 0.23879072070121765,
      "learning_rate": 2.1449792038027334e-06,
      "loss": 0.0216,
      "step": 16470
    },
    {
      "epoch": 29.376114081996434,
      "grad_norm": 1.0059630870819092,
      "learning_rate": 2.0855614973262034e-06,
      "loss": 0.022,
      "step": 16480
    },
    {
      "epoch": 29.393939393939394,
      "grad_norm": 0.5758603811264038,
      "learning_rate": 2.0261437908496734e-06,
      "loss": 0.0222,
      "step": 16490
    },
    {
      "epoch": 29.41176470588235,
      "grad_norm": 0.5189214944839478,
      "learning_rate": 1.9667260843731433e-06,
      "loss": 0.022,
      "step": 16500
    },
    {
      "epoch": 29.429590017825312,
      "grad_norm": 0.4750119149684906,
      "learning_rate": 1.9073083778966133e-06,
      "loss": 0.0216,
      "step": 16510
    },
    {
      "epoch": 29.447415329768273,
      "grad_norm": 0.22602826356887817,
      "learning_rate": 1.847890671420083e-06,
      "loss": 0.0217,
      "step": 16520
    },
    {
      "epoch": 29.46524064171123,
      "grad_norm": 0.38320159912109375,
      "learning_rate": 1.7884729649435533e-06,
      "loss": 0.0218,
      "step": 16530
    },
    {
      "epoch": 29.48306595365419,
      "grad_norm": 0.3429180085659027,
      "learning_rate": 1.7290552584670235e-06,
      "loss": 0.0206,
      "step": 16540
    },
    {
      "epoch": 29.500891265597147,
      "grad_norm": 0.31114447116851807,
      "learning_rate": 1.6696375519904932e-06,
      "loss": 0.0212,
      "step": 16550
    },
    {
      "epoch": 29.518716577540108,
      "grad_norm": 0.5594106912612915,
      "learning_rate": 1.6102198455139632e-06,
      "loss": 0.021,
      "step": 16560
    },
    {
      "epoch": 29.536541889483065,
      "grad_norm": 0.42216020822525024,
      "learning_rate": 1.5508021390374332e-06,
      "loss": 0.0212,
      "step": 16570
    },
    {
      "epoch": 29.554367201426025,
      "grad_norm": 0.8682333827018738,
      "learning_rate": 1.4913844325609032e-06,
      "loss": 0.022,
      "step": 16580
    },
    {
      "epoch": 29.572192513368982,
      "grad_norm": 0.6585402488708496,
      "learning_rate": 1.4319667260843732e-06,
      "loss": 0.0209,
      "step": 16590
    },
    {
      "epoch": 29.590017825311943,
      "grad_norm": 0.5096673965454102,
      "learning_rate": 1.3725490196078432e-06,
      "loss": 0.0217,
      "step": 16600
    },
    {
      "epoch": 29.607843137254903,
      "grad_norm": 0.38196274638175964,
      "learning_rate": 1.3131313131313131e-06,
      "loss": 0.0212,
      "step": 16610
    },
    {
      "epoch": 29.62566844919786,
      "grad_norm": 0.3474057912826538,
      "learning_rate": 1.2537136066547831e-06,
      "loss": 0.0215,
      "step": 16620
    },
    {
      "epoch": 29.64349376114082,
      "grad_norm": 0.3339730203151703,
      "learning_rate": 1.1942959001782533e-06,
      "loss": 0.022,
      "step": 16630
    },
    {
      "epoch": 29.661319073083778,
      "grad_norm": 0.4415520429611206,
      "learning_rate": 1.1348781937017233e-06,
      "loss": 0.0216,
      "step": 16640
    },
    {
      "epoch": 29.67914438502674,
      "grad_norm": 0.350189208984375,
      "learning_rate": 1.0754604872251933e-06,
      "loss": 0.0218,
      "step": 16650
    },
    {
      "epoch": 29.696969696969695,
      "grad_norm": 0.31720826029777527,
      "learning_rate": 1.016042780748663e-06,
      "loss": 0.0213,
      "step": 16660
    },
    {
      "epoch": 29.714795008912656,
      "grad_norm": 0.3843054175376892,
      "learning_rate": 9.56625074272133e-07,
      "loss": 0.0215,
      "step": 16670
    },
    {
      "epoch": 29.732620320855617,
      "grad_norm": 0.3814277648925781,
      "learning_rate": 8.972073677956031e-07,
      "loss": 0.0211,
      "step": 16680
    },
    {
      "epoch": 29.750445632798574,
      "grad_norm": 0.28199633955955505,
      "learning_rate": 8.37789661319073e-07,
      "loss": 0.0213,
      "step": 16690
    },
    {
      "epoch": 29.768270944741534,
      "grad_norm": 0.3753061294555664,
      "learning_rate": 7.783719548425431e-07,
      "loss": 0.0212,
      "step": 16700
    },
    {
      "epoch": 29.78609625668449,
      "grad_norm": 0.2882380187511444,
      "learning_rate": 7.189542483660131e-07,
      "loss": 0.0208,
      "step": 16710
    },
    {
      "epoch": 29.80392156862745,
      "grad_norm": 0.26999083161354065,
      "learning_rate": 6.595365418894832e-07,
      "loss": 0.0208,
      "step": 16720
    },
    {
      "epoch": 29.82174688057041,
      "grad_norm": 0.36525043845176697,
      "learning_rate": 6.001188354129531e-07,
      "loss": 0.0213,
      "step": 16730
    },
    {
      "epoch": 29.83957219251337,
      "grad_norm": 0.5544937252998352,
      "learning_rate": 5.40701128936423e-07,
      "loss": 0.0213,
      "step": 16740
    },
    {
      "epoch": 29.85739750445633,
      "grad_norm": 0.8727097511291504,
      "learning_rate": 4.812834224598931e-07,
      "loss": 0.0217,
      "step": 16750
    },
    {
      "epoch": 29.875222816399287,
      "grad_norm": 0.7905725240707397,
      "learning_rate": 4.218657159833631e-07,
      "loss": 0.0212,
      "step": 16760
    },
    {
      "epoch": 29.893048128342247,
      "grad_norm": 0.36315762996673584,
      "learning_rate": 3.62448009506833e-07,
      "loss": 0.0206,
      "step": 16770
    },
    {
      "epoch": 29.910873440285204,
      "grad_norm": 0.37826043367385864,
      "learning_rate": 3.0303030303030305e-07,
      "loss": 0.0216,
      "step": 16780
    },
    {
      "epoch": 29.928698752228165,
      "grad_norm": 0.4256019592285156,
      "learning_rate": 2.4361259655377303e-07,
      "loss": 0.0209,
      "step": 16790
    },
    {
      "epoch": 29.946524064171122,
      "grad_norm": 0.6812392473220825,
      "learning_rate": 1.84194890077243e-07,
      "loss": 0.0219,
      "step": 16800
    },
    {
      "epoch": 29.964349376114082,
      "grad_norm": 0.5171731114387512,
      "learning_rate": 1.2477718360071302e-07,
      "loss": 0.0215,
      "step": 16810
    },
    {
      "epoch": 29.98217468805704,
      "grad_norm": 0.3746340274810791,
      "learning_rate": 6.5359477124183e-08,
      "loss": 0.0206,
      "step": 16820
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.6995524168014526,
      "learning_rate": 5.941770647653001e-09,
      "loss": 0.0221,
      "step": 16830
    }
  ],
  "logging_steps": 10,
  "max_steps": 16830,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 302513959008000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
